{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3071741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T14:39:59.097691Z",
     "iopub.status.busy": "2024-07-20T14:39:59.097371Z",
     "iopub.status.idle": "2024-07-20T14:40:27.592435Z",
     "shell.execute_reply": "2024-07-20T14:40:27.591392Z"
    },
    "papermill": {
     "duration": 28.502302,
     "end_time": "2024-07-20T14:40:27.594685",
     "exception": false,
     "start_time": "2024-07-20T14:39:59.092383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:16<00:00, 10162624.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-100-python.tar.gz to data\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([10])\n",
      "Using cuda device\n",
      "NN(\n",
      "  (conv2d): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(1024, 2048, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(2048, 4096, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU()\n",
      "    (31): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (32): Conv2d(4096, 8192, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (33): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (34): ReLU()\n",
      "    (35): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linearstack): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=100, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision as vision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "datasettrain = vision.datasets.CIFAR100(\"data\",True,vision.transforms.ToTensor(),download=True)\n",
    "\n",
    "datasettest = vision.datasets.CIFAR100(\"data\",False,vision.transforms.ToTensor(),download=True)\n",
    "datagen = torch.utils.data.DataLoader(datasettrain,10,True)\n",
    "datatestgen = torch.utils.data.DataLoader(datasettest,10,True)\n",
    "for X,y in datagen:\n",
    "    print(X[0].shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "# temp = torch.utils.data.DataLoader(datasettrain,999999,True)\n",
    "# for x,y in temp:\n",
    "#     print(np.unique(y).shape)\n",
    "#     print(y.shape)\n",
    "#     break\n",
    "\n",
    "#(100,)\n",
    "#torch.Size([50000])\n",
    "\n",
    "# nn.functional.one_hot(y,100).shape\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d = nn.Sequential(\n",
    "            nn.Conv2d(3,32,2,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32,64,2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(64,128,2,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(128,256,2,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(256,512,2,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(512,1024,2,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(1024,2048,2,padding=1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(2048,4096,2,padding=1),\n",
    "            nn.BatchNorm2d(4096),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(4096,(4096*2),2,padding=1),\n",
    "            nn.BatchNorm2d((4096*2)),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            torch.nn.MaxPool2d(2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linearstack = nn.Sequential(\n",
    "            nn.Linear(4096*2,100),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv2d(x)\n",
    "        flat = self.flatten(x)\n",
    "        logits = self.linearstack(flat)\n",
    "        return logits\n",
    "model = NN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a879d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T14:40:27.617868Z",
     "iopub.status.busy": "2024-07-20T14:40:27.617009Z",
     "iopub.status.idle": "2024-07-20T14:40:28.213217Z",
     "shell.execute_reply": "2024-07-20T14:40:28.212283Z"
    },
    "papermill": {
     "duration": 0.609645,
     "end_time": "2024-07-20T14:40:28.215361",
     "exception": false,
     "start_time": "2024-07-20T14:40:27.605716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch, (X, y) in enumerate(datagen):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        break\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9937169f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T14:40:28.237188Z",
     "iopub.status.busy": "2024-07-20T14:40:28.236856Z",
     "iopub.status.idle": "2024-07-20T14:40:28.244635Z",
     "shell.execute_reply": "2024-07-20T14:40:28.243764Z"
    },
    "papermill": {
     "duration": 0.020854,
     "end_time": "2024-07-20T14:40:28.246518",
     "exception": false,
     "start_time": "2024-07-20T14:40:28.225664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c243e60f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T14:40:28.268238Z",
     "iopub.status.busy": "2024-07-20T14:40:28.267877Z",
     "iopub.status.idle": "2024-07-20T14:40:28.274615Z",
     "shell.execute_reply": "2024-07-20T14:40:28.273833Z"
    },
    "papermill": {
     "duration": 0.01988,
     "end_time": "2024-07-20T14:40:28.276494",
     "exception": false,
     "start_time": "2024-07-20T14:40:28.256614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7dcb6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T14:40:28.297870Z",
     "iopub.status.busy": "2024-07-20T14:40:28.297569Z",
     "iopub.status.idle": "2024-07-20T22:56:34.667441Z",
     "shell.execute_reply": "2024-07-20T22:56:34.666472Z"
    },
    "papermill": {
     "duration": 29766.383099,
     "end_time": "2024-07-20T22:56:34.669691",
     "exception": false,
     "start_time": "2024-07-20T14:40:28.286592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.621253  [   10/50000]\n",
      "loss: 4.651838  [ 1010/50000]\n",
      "loss: 4.589988  [ 2010/50000]\n",
      "loss: 4.529504  [ 3010/50000]\n",
      "loss: 4.427194  [ 4010/50000]\n",
      "loss: 4.646763  [ 5010/50000]\n",
      "loss: 4.487611  [ 6010/50000]\n",
      "loss: 4.311981  [ 7010/50000]\n",
      "loss: 4.386660  [ 8010/50000]\n",
      "loss: 4.487893  [ 9010/50000]\n",
      "loss: 4.304029  [10010/50000]\n",
      "loss: 4.410135  [11010/50000]\n",
      "loss: 4.298252  [12010/50000]\n",
      "loss: 4.429020  [13010/50000]\n",
      "loss: 4.358908  [14010/50000]\n",
      "loss: 4.288771  [15010/50000]\n",
      "loss: 4.279444  [16010/50000]\n",
      "loss: 4.253261  [17010/50000]\n",
      "loss: 4.244896  [18010/50000]\n",
      "loss: 4.251626  [19010/50000]\n",
      "loss: 4.387408  [20010/50000]\n",
      "loss: 4.238271  [21010/50000]\n",
      "loss: 4.245253  [22010/50000]\n",
      "loss: 4.369299  [23010/50000]\n",
      "loss: 4.339543  [24010/50000]\n",
      "loss: 4.256835  [25010/50000]\n",
      "loss: 4.452882  [26010/50000]\n",
      "loss: 4.279565  [27010/50000]\n",
      "loss: 4.317083  [28010/50000]\n",
      "loss: 4.315490  [29010/50000]\n",
      "loss: 4.279051  [30010/50000]\n",
      "loss: 4.249997  [31010/50000]\n",
      "loss: 4.243247  [32010/50000]\n",
      "loss: 4.237985  [33010/50000]\n",
      "loss: 4.238981  [34010/50000]\n",
      "loss: 4.181779  [35010/50000]\n",
      "loss: 4.310710  [36010/50000]\n",
      "loss: 4.113629  [37010/50000]\n",
      "loss: 4.337052  [38010/50000]\n",
      "loss: 4.098884  [39010/50000]\n",
      "loss: 4.234495  [40010/50000]\n",
      "loss: 4.131232  [41010/50000]\n",
      "loss: 4.284308  [42010/50000]\n",
      "loss: 4.398485  [43010/50000]\n",
      "loss: 4.204539  [44010/50000]\n",
      "loss: 4.236204  [45010/50000]\n",
      "loss: 4.235355  [46010/50000]\n",
      "loss: 4.164601  [47010/50000]\n",
      "loss: 4.170949  [48010/50000]\n",
      "loss: 4.228830  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 13.2%, Avg loss: 4.199133 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.220216  [   10/50000]\n",
      "loss: 4.237671  [ 1010/50000]\n",
      "loss: 4.069754  [ 2010/50000]\n",
      "loss: 4.259929  [ 3010/50000]\n",
      "loss: 4.379348  [ 4010/50000]\n",
      "loss: 4.354856  [ 5010/50000]\n",
      "loss: 4.307355  [ 6010/50000]\n",
      "loss: 4.010702  [ 7010/50000]\n",
      "loss: 4.270345  [ 8010/50000]\n",
      "loss: 4.040374  [ 9010/50000]\n",
      "loss: 4.225808  [10010/50000]\n",
      "loss: 4.160283  [11010/50000]\n",
      "loss: 4.144507  [12010/50000]\n",
      "loss: 4.115129  [13010/50000]\n",
      "loss: 4.256135  [14010/50000]\n",
      "loss: 4.313050  [15010/50000]\n",
      "loss: 4.218330  [16010/50000]\n",
      "loss: 4.321236  [17010/50000]\n",
      "loss: 4.042680  [18010/50000]\n",
      "loss: 4.117615  [19010/50000]\n",
      "loss: 4.202529  [20010/50000]\n",
      "loss: 4.091989  [21010/50000]\n",
      "loss: 4.196624  [22010/50000]\n",
      "loss: 4.116789  [23010/50000]\n",
      "loss: 4.301843  [24010/50000]\n",
      "loss: 4.139858  [25010/50000]\n",
      "loss: 4.222360  [26010/50000]\n",
      "loss: 4.207895  [27010/50000]\n",
      "loss: 4.155187  [28010/50000]\n",
      "loss: 4.347388  [29010/50000]\n",
      "loss: 4.315158  [30010/50000]\n",
      "loss: 4.187606  [31010/50000]\n",
      "loss: 4.032798  [32010/50000]\n",
      "loss: 4.133630  [33010/50000]\n",
      "loss: 4.400199  [34010/50000]\n",
      "loss: 4.287654  [35010/50000]\n",
      "loss: 4.147627  [36010/50000]\n",
      "loss: 4.103598  [37010/50000]\n",
      "loss: 4.166563  [38010/50000]\n",
      "loss: 4.365713  [39010/50000]\n",
      "loss: 4.048686  [40010/50000]\n",
      "loss: 4.276185  [41010/50000]\n",
      "loss: 3.999620  [42010/50000]\n",
      "loss: 4.118839  [43010/50000]\n",
      "loss: 4.021479  [44010/50000]\n",
      "loss: 4.065106  [45010/50000]\n",
      "loss: 4.239759  [46010/50000]\n",
      "loss: 4.182208  [47010/50000]\n",
      "loss: 4.074883  [48010/50000]\n",
      "loss: 4.123443  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 17.5%, Avg loss: 4.127714 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.074623  [   10/50000]\n",
      "loss: 4.121665  [ 1010/50000]\n",
      "loss: 4.139683  [ 2010/50000]\n",
      "loss: 4.167776  [ 3010/50000]\n",
      "loss: 4.205513  [ 4010/50000]\n",
      "loss: 4.122282  [ 5010/50000]\n",
      "loss: 4.119006  [ 6010/50000]\n",
      "loss: 4.215079  [ 7010/50000]\n",
      "loss: 4.346939  [ 8010/50000]\n",
      "loss: 3.946291  [ 9010/50000]\n",
      "loss: 4.007213  [10010/50000]\n",
      "loss: 4.288846  [11010/50000]\n",
      "loss: 3.974260  [12010/50000]\n",
      "loss: 4.081580  [13010/50000]\n",
      "loss: 3.924918  [14010/50000]\n",
      "loss: 4.188427  [15010/50000]\n",
      "loss: 4.125743  [16010/50000]\n",
      "loss: 3.937848  [17010/50000]\n",
      "loss: 4.176167  [18010/50000]\n",
      "loss: 3.971220  [19010/50000]\n",
      "loss: 4.113215  [20010/50000]\n",
      "loss: 4.213314  [21010/50000]\n",
      "loss: 4.042390  [22010/50000]\n",
      "loss: 4.318382  [23010/50000]\n",
      "loss: 3.967884  [24010/50000]\n",
      "loss: 4.200213  [25010/50000]\n",
      "loss: 4.094783  [26010/50000]\n",
      "loss: 4.294919  [27010/50000]\n",
      "loss: 4.002050  [28010/50000]\n",
      "loss: 4.033304  [29010/50000]\n",
      "loss: 4.267454  [30010/50000]\n",
      "loss: 4.308424  [31010/50000]\n",
      "loss: 4.117577  [32010/50000]\n",
      "loss: 4.086041  [33010/50000]\n",
      "loss: 4.049834  [34010/50000]\n",
      "loss: 4.066262  [35010/50000]\n",
      "loss: 4.050281  [36010/50000]\n",
      "loss: 4.083345  [37010/50000]\n",
      "loss: 4.200464  [38010/50000]\n",
      "loss: 4.095798  [39010/50000]\n",
      "loss: 4.210644  [40010/50000]\n",
      "loss: 4.008276  [41010/50000]\n",
      "loss: 4.242970  [42010/50000]\n",
      "loss: 4.083822  [43010/50000]\n",
      "loss: 4.023360  [44010/50000]\n",
      "loss: 4.023905  [45010/50000]\n",
      "loss: 4.171939  [46010/50000]\n",
      "loss: 4.205509  [47010/50000]\n",
      "loss: 3.987031  [48010/50000]\n",
      "loss: 4.177720  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 21.2%, Avg loss: 4.089385 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.010023  [   10/50000]\n",
      "loss: 4.096435  [ 1010/50000]\n",
      "loss: 4.024576  [ 2010/50000]\n",
      "loss: 4.034348  [ 3010/50000]\n",
      "loss: 4.167491  [ 4010/50000]\n",
      "loss: 4.061681  [ 5010/50000]\n",
      "loss: 4.298834  [ 6010/50000]\n",
      "loss: 4.115084  [ 7010/50000]\n",
      "loss: 4.017134  [ 8010/50000]\n",
      "loss: 3.893647  [ 9010/50000]\n",
      "loss: 4.080074  [10010/50000]\n",
      "loss: 4.025342  [11010/50000]\n",
      "loss: 4.106509  [12010/50000]\n",
      "loss: 4.121205  [13010/50000]\n",
      "loss: 4.182364  [14010/50000]\n",
      "loss: 4.132472  [15010/50000]\n",
      "loss: 3.896207  [16010/50000]\n",
      "loss: 4.159370  [17010/50000]\n",
      "loss: 3.965304  [18010/50000]\n",
      "loss: 3.950746  [19010/50000]\n",
      "loss: 4.119932  [20010/50000]\n",
      "loss: 4.074893  [21010/50000]\n",
      "loss: 4.021004  [22010/50000]\n",
      "loss: 4.030361  [23010/50000]\n",
      "loss: 3.913560  [24010/50000]\n",
      "loss: 3.975812  [25010/50000]\n",
      "loss: 3.906889  [26010/50000]\n",
      "loss: 4.033222  [27010/50000]\n",
      "loss: 3.905597  [28010/50000]\n",
      "loss: 4.104592  [29010/50000]\n",
      "loss: 4.192677  [30010/50000]\n",
      "loss: 4.023171  [31010/50000]\n",
      "loss: 4.257401  [32010/50000]\n",
      "loss: 4.055312  [33010/50000]\n",
      "loss: 3.974433  [34010/50000]\n",
      "loss: 4.128511  [35010/50000]\n",
      "loss: 4.203583  [36010/50000]\n",
      "loss: 4.149477  [37010/50000]\n",
      "loss: 4.166306  [38010/50000]\n",
      "loss: 4.034501  [39010/50000]\n",
      "loss: 4.101408  [40010/50000]\n",
      "loss: 4.121684  [41010/50000]\n",
      "loss: 3.964132  [42010/50000]\n",
      "loss: 4.201310  [43010/50000]\n",
      "loss: 4.068569  [44010/50000]\n",
      "loss: 4.127687  [45010/50000]\n",
      "loss: 4.105100  [46010/50000]\n",
      "loss: 4.062785  [47010/50000]\n",
      "loss: 4.125611  [48010/50000]\n",
      "loss: 3.966330  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 22.3%, Avg loss: 4.059655 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.004323  [   10/50000]\n",
      "loss: 4.002720  [ 1010/50000]\n",
      "loss: 4.017144  [ 2010/50000]\n",
      "loss: 4.188203  [ 3010/50000]\n",
      "loss: 4.148004  [ 4010/50000]\n",
      "loss: 3.981523  [ 5010/50000]\n",
      "loss: 4.196845  [ 6010/50000]\n",
      "loss: 4.071107  [ 7010/50000]\n",
      "loss: 3.943324  [ 8010/50000]\n",
      "loss: 4.355836  [ 9010/50000]\n",
      "loss: 4.119398  [10010/50000]\n",
      "loss: 3.961732  [11010/50000]\n",
      "loss: 4.048574  [12010/50000]\n",
      "loss: 4.082448  [13010/50000]\n",
      "loss: 4.241410  [14010/50000]\n",
      "loss: 4.142514  [15010/50000]\n",
      "loss: 4.011378  [16010/50000]\n",
      "loss: 4.059515  [17010/50000]\n",
      "loss: 3.984410  [18010/50000]\n",
      "loss: 3.972929  [19010/50000]\n",
      "loss: 4.072760  [20010/50000]\n",
      "loss: 4.145053  [21010/50000]\n",
      "loss: 4.054468  [22010/50000]\n",
      "loss: 4.067256  [23010/50000]\n",
      "loss: 4.085281  [24010/50000]\n",
      "loss: 4.139147  [25010/50000]\n",
      "loss: 4.151704  [26010/50000]\n",
      "loss: 4.307504  [27010/50000]\n",
      "loss: 4.248193  [28010/50000]\n",
      "loss: 3.920471  [29010/50000]\n",
      "loss: 4.203845  [30010/50000]\n",
      "loss: 4.033803  [31010/50000]\n",
      "loss: 3.966316  [32010/50000]\n",
      "loss: 4.011787  [33010/50000]\n",
      "loss: 4.038636  [34010/50000]\n",
      "loss: 4.067076  [35010/50000]\n",
      "loss: 4.080716  [36010/50000]\n",
      "loss: 4.111351  [37010/50000]\n",
      "loss: 4.101489  [38010/50000]\n",
      "loss: 4.070446  [39010/50000]\n",
      "loss: 4.190394  [40010/50000]\n",
      "loss: 3.919444  [41010/50000]\n",
      "loss: 4.223153  [42010/50000]\n",
      "loss: 3.993827  [43010/50000]\n",
      "loss: 4.011704  [44010/50000]\n",
      "loss: 3.949956  [45010/50000]\n",
      "loss: 4.203553  [46010/50000]\n",
      "loss: 4.238486  [47010/50000]\n",
      "loss: 3.976959  [48010/50000]\n",
      "loss: 4.292140  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 23.3%, Avg loss: 4.044842 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.913457  [   10/50000]\n",
      "loss: 4.058184  [ 1010/50000]\n",
      "loss: 4.191368  [ 2010/50000]\n",
      "loss: 3.890488  [ 3010/50000]\n",
      "loss: 4.152614  [ 4010/50000]\n",
      "loss: 3.962682  [ 5010/50000]\n",
      "loss: 4.275351  [ 6010/50000]\n",
      "loss: 4.211675  [ 7010/50000]\n",
      "loss: 4.134489  [ 8010/50000]\n",
      "loss: 3.873943  [ 9010/50000]\n",
      "loss: 4.188230  [10010/50000]\n",
      "loss: 4.050444  [11010/50000]\n",
      "loss: 4.115654  [12010/50000]\n",
      "loss: 4.045714  [13010/50000]\n",
      "loss: 4.177804  [14010/50000]\n",
      "loss: 4.102838  [15010/50000]\n",
      "loss: 3.944295  [16010/50000]\n",
      "loss: 4.000959  [17010/50000]\n",
      "loss: 4.111764  [18010/50000]\n",
      "loss: 4.100446  [19010/50000]\n",
      "loss: 3.903590  [20010/50000]\n",
      "loss: 4.025060  [21010/50000]\n",
      "loss: 3.900945  [22010/50000]\n",
      "loss: 3.904181  [23010/50000]\n",
      "loss: 4.087502  [24010/50000]\n",
      "loss: 3.965690  [25010/50000]\n",
      "loss: 3.980910  [26010/50000]\n",
      "loss: 4.069587  [27010/50000]\n",
      "loss: 3.897504  [28010/50000]\n",
      "loss: 4.057338  [29010/50000]\n",
      "loss: 3.924181  [30010/50000]\n",
      "loss: 3.993062  [31010/50000]\n",
      "loss: 4.014865  [32010/50000]\n",
      "loss: 4.071575  [33010/50000]\n",
      "loss: 4.197478  [34010/50000]\n",
      "loss: 4.053834  [35010/50000]\n",
      "loss: 4.037948  [36010/50000]\n",
      "loss: 3.928722  [37010/50000]\n",
      "loss: 3.879709  [38010/50000]\n",
      "loss: 3.991898  [39010/50000]\n",
      "loss: 3.943121  [40010/50000]\n",
      "loss: 3.939379  [41010/50000]\n",
      "loss: 3.933347  [42010/50000]\n",
      "loss: 4.097423  [43010/50000]\n",
      "loss: 4.051447  [44010/50000]\n",
      "loss: 3.982448  [45010/50000]\n",
      "loss: 3.976419  [46010/50000]\n",
      "loss: 3.926360  [47010/50000]\n",
      "loss: 4.079310  [48010/50000]\n",
      "loss: 3.904042  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 26.0%, Avg loss: 4.025298 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.079624  [   10/50000]\n",
      "loss: 3.961705  [ 1010/50000]\n",
      "loss: 4.337288  [ 2010/50000]\n",
      "loss: 4.128375  [ 3010/50000]\n",
      "loss: 4.067748  [ 4010/50000]\n",
      "loss: 4.012257  [ 5010/50000]\n",
      "loss: 4.222304  [ 6010/50000]\n",
      "loss: 4.064396  [ 7010/50000]\n",
      "loss: 4.012228  [ 8010/50000]\n",
      "loss: 3.881499  [ 9010/50000]\n",
      "loss: 3.956650  [10010/50000]\n",
      "loss: 4.029099  [11010/50000]\n",
      "loss: 3.961655  [12010/50000]\n",
      "loss: 4.119151  [13010/50000]\n",
      "loss: 4.069167  [14010/50000]\n",
      "loss: 3.962904  [15010/50000]\n",
      "loss: 3.997677  [16010/50000]\n",
      "loss: 3.862092  [17010/50000]\n",
      "loss: 4.126195  [18010/50000]\n",
      "loss: 4.125063  [19010/50000]\n",
      "loss: 3.890043  [20010/50000]\n",
      "loss: 3.950152  [21010/50000]\n",
      "loss: 4.028498  [22010/50000]\n",
      "loss: 4.238038  [23010/50000]\n",
      "loss: 4.039435  [24010/50000]\n",
      "loss: 4.008226  [25010/50000]\n",
      "loss: 4.059663  [26010/50000]\n",
      "loss: 4.059112  [27010/50000]\n",
      "loss: 3.980266  [28010/50000]\n",
      "loss: 3.937864  [29010/50000]\n",
      "loss: 4.230420  [30010/50000]\n",
      "loss: 4.046608  [31010/50000]\n",
      "loss: 3.964780  [32010/50000]\n",
      "loss: 3.861984  [33010/50000]\n",
      "loss: 4.142704  [34010/50000]\n",
      "loss: 3.891417  [35010/50000]\n",
      "loss: 3.940135  [36010/50000]\n",
      "loss: 3.997792  [37010/50000]\n",
      "loss: 3.944387  [38010/50000]\n",
      "loss: 4.084105  [39010/50000]\n",
      "loss: 4.127387  [40010/50000]\n",
      "loss: 3.882140  [41010/50000]\n",
      "loss: 4.116892  [42010/50000]\n",
      "loss: 4.008916  [43010/50000]\n",
      "loss: 4.046256  [44010/50000]\n",
      "loss: 4.058187  [45010/50000]\n",
      "loss: 3.908925  [46010/50000]\n",
      "loss: 4.120354  [47010/50000]\n",
      "loss: 3.972436  [48010/50000]\n",
      "loss: 3.988395  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 26.7%, Avg loss: 4.012178 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.150961  [   10/50000]\n",
      "loss: 3.873477  [ 1010/50000]\n",
      "loss: 4.110576  [ 2010/50000]\n",
      "loss: 3.906075  [ 3010/50000]\n",
      "loss: 4.021638  [ 4010/50000]\n",
      "loss: 3.921015  [ 5010/50000]\n",
      "loss: 3.923590  [ 6010/50000]\n",
      "loss: 3.977082  [ 7010/50000]\n",
      "loss: 3.837394  [ 8010/50000]\n",
      "loss: 4.031217  [ 9010/50000]\n",
      "loss: 3.948856  [10010/50000]\n",
      "loss: 3.863410  [11010/50000]\n",
      "loss: 3.938046  [12010/50000]\n",
      "loss: 4.237368  [13010/50000]\n",
      "loss: 4.192002  [14010/50000]\n",
      "loss: 4.012661  [15010/50000]\n",
      "loss: 3.971792  [16010/50000]\n",
      "loss: 3.986018  [17010/50000]\n",
      "loss: 4.209474  [18010/50000]\n",
      "loss: 4.082407  [19010/50000]\n",
      "loss: 3.958736  [20010/50000]\n",
      "loss: 4.011421  [21010/50000]\n",
      "loss: 3.922324  [22010/50000]\n",
      "loss: 3.999413  [23010/50000]\n",
      "loss: 4.064141  [24010/50000]\n",
      "loss: 4.047113  [25010/50000]\n",
      "loss: 4.033003  [26010/50000]\n",
      "loss: 4.064476  [27010/50000]\n",
      "loss: 4.136928  [28010/50000]\n",
      "loss: 3.977982  [29010/50000]\n",
      "loss: 4.031995  [30010/50000]\n",
      "loss: 3.937288  [31010/50000]\n",
      "loss: 3.992459  [32010/50000]\n",
      "loss: 3.954843  [33010/50000]\n",
      "loss: 3.948515  [34010/50000]\n",
      "loss: 3.867499  [35010/50000]\n",
      "loss: 3.928878  [36010/50000]\n",
      "loss: 3.859575  [37010/50000]\n",
      "loss: 3.906737  [38010/50000]\n",
      "loss: 4.024790  [39010/50000]\n",
      "loss: 4.097353  [40010/50000]\n",
      "loss: 4.190676  [41010/50000]\n",
      "loss: 3.944531  [42010/50000]\n",
      "loss: 3.926759  [43010/50000]\n",
      "loss: 3.939041  [44010/50000]\n",
      "loss: 3.871120  [45010/50000]\n",
      "loss: 3.946740  [46010/50000]\n",
      "loss: 3.869172  [47010/50000]\n",
      "loss: 3.886929  [48010/50000]\n",
      "loss: 3.996016  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 27.9%, Avg loss: 3.999906 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 3.930890  [   10/50000]\n",
      "loss: 3.902566  [ 1010/50000]\n",
      "loss: 3.827737  [ 2010/50000]\n",
      "loss: 3.963399  [ 3010/50000]\n",
      "loss: 3.869410  [ 4010/50000]\n",
      "loss: 4.074739  [ 5010/50000]\n",
      "loss: 3.980730  [ 6010/50000]\n",
      "loss: 3.998837  [ 7010/50000]\n",
      "loss: 4.018287  [ 8010/50000]\n",
      "loss: 3.991943  [ 9010/50000]\n",
      "loss: 3.908334  [10010/50000]\n",
      "loss: 4.093587  [11010/50000]\n",
      "loss: 4.020974  [12010/50000]\n",
      "loss: 3.879150  [13010/50000]\n",
      "loss: 4.024900  [14010/50000]\n",
      "loss: 3.949018  [15010/50000]\n",
      "loss: 4.221875  [16010/50000]\n",
      "loss: 3.993279  [17010/50000]\n",
      "loss: 3.997300  [18010/50000]\n",
      "loss: 3.913846  [19010/50000]\n",
      "loss: 4.099423  [20010/50000]\n",
      "loss: 4.161337  [21010/50000]\n",
      "loss: 4.143184  [22010/50000]\n",
      "loss: 3.859452  [23010/50000]\n",
      "loss: 4.009669  [24010/50000]\n",
      "loss: 3.932588  [25010/50000]\n",
      "loss: 3.955596  [26010/50000]\n",
      "loss: 4.004079  [27010/50000]\n",
      "loss: 3.983163  [28010/50000]\n",
      "loss: 4.208821  [29010/50000]\n",
      "loss: 3.891810  [30010/50000]\n",
      "loss: 4.152514  [31010/50000]\n",
      "loss: 4.039960  [32010/50000]\n",
      "loss: 3.971190  [33010/50000]\n",
      "loss: 3.953191  [34010/50000]\n",
      "loss: 4.127971  [35010/50000]\n",
      "loss: 4.140578  [36010/50000]\n",
      "loss: 4.121904  [37010/50000]\n",
      "loss: 3.989346  [38010/50000]\n",
      "loss: 4.103801  [39010/50000]\n",
      "loss: 4.048489  [40010/50000]\n",
      "loss: 3.812933  [41010/50000]\n",
      "loss: 3.949765  [42010/50000]\n",
      "loss: 3.938508  [43010/50000]\n",
      "loss: 3.954357  [44010/50000]\n",
      "loss: 4.077370  [45010/50000]\n",
      "loss: 3.851865  [46010/50000]\n",
      "loss: 3.938880  [47010/50000]\n",
      "loss: 4.084514  [48010/50000]\n",
      "loss: 3.884658  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 28.0%, Avg loss: 3.993693 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 3.923562  [   10/50000]\n",
      "loss: 4.062522  [ 1010/50000]\n",
      "loss: 4.036551  [ 2010/50000]\n",
      "loss: 4.072134  [ 3010/50000]\n",
      "loss: 4.041105  [ 4010/50000]\n",
      "loss: 4.062617  [ 5010/50000]\n",
      "loss: 4.055209  [ 6010/50000]\n",
      "loss: 3.909996  [ 7010/50000]\n",
      "loss: 4.028795  [ 8010/50000]\n",
      "loss: 3.988811  [ 9010/50000]\n",
      "loss: 3.829742  [10010/50000]\n",
      "loss: 4.026816  [11010/50000]\n",
      "loss: 3.964481  [12010/50000]\n",
      "loss: 4.005474  [13010/50000]\n",
      "loss: 3.936962  [14010/50000]\n",
      "loss: 3.904159  [15010/50000]\n",
      "loss: 3.882545  [16010/50000]\n",
      "loss: 4.071008  [17010/50000]\n",
      "loss: 3.965054  [18010/50000]\n",
      "loss: 3.960769  [19010/50000]\n",
      "loss: 3.900282  [20010/50000]\n",
      "loss: 3.928993  [21010/50000]\n",
      "loss: 4.029243  [22010/50000]\n",
      "loss: 3.802390  [23010/50000]\n",
      "loss: 3.852719  [24010/50000]\n",
      "loss: 3.938052  [25010/50000]\n",
      "loss: 4.084313  [26010/50000]\n",
      "loss: 4.112428  [27010/50000]\n",
      "loss: 3.882202  [28010/50000]\n",
      "loss: 3.814051  [29010/50000]\n",
      "loss: 3.854057  [30010/50000]\n",
      "loss: 3.921594  [31010/50000]\n",
      "loss: 4.150052  [32010/50000]\n",
      "loss: 3.821247  [33010/50000]\n",
      "loss: 3.997450  [34010/50000]\n",
      "loss: 3.825336  [35010/50000]\n",
      "loss: 4.057484  [36010/50000]\n",
      "loss: 4.043664  [37010/50000]\n",
      "loss: 3.980143  [38010/50000]\n",
      "loss: 3.989208  [39010/50000]\n",
      "loss: 4.002631  [40010/50000]\n",
      "loss: 3.818005  [41010/50000]\n",
      "loss: 4.085766  [42010/50000]\n",
      "loss: 4.004992  [43010/50000]\n",
      "loss: 4.014293  [44010/50000]\n",
      "loss: 3.850061  [45010/50000]\n",
      "loss: 3.949334  [46010/50000]\n",
      "loss: 4.056518  [47010/50000]\n",
      "loss: 3.983276  [48010/50000]\n",
      "loss: 3.886173  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 27.9%, Avg loss: 4.002084 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 4.045663  [   10/50000]\n",
      "loss: 3.906377  [ 1010/50000]\n",
      "loss: 3.925975  [ 2010/50000]\n",
      "loss: 4.179914  [ 3010/50000]\n",
      "loss: 3.913500  [ 4010/50000]\n",
      "loss: 3.906082  [ 5010/50000]\n",
      "loss: 3.832534  [ 6010/50000]\n",
      "loss: 3.955530  [ 7010/50000]\n",
      "loss: 3.805642  [ 8010/50000]\n",
      "loss: 3.891838  [ 9010/50000]\n",
      "loss: 3.940105  [10010/50000]\n",
      "loss: 3.982992  [11010/50000]\n",
      "loss: 4.042851  [12010/50000]\n",
      "loss: 3.835534  [13010/50000]\n",
      "loss: 3.954776  [14010/50000]\n",
      "loss: 3.934540  [15010/50000]\n",
      "loss: 4.067482  [16010/50000]\n",
      "loss: 4.013625  [17010/50000]\n",
      "loss: 4.005255  [18010/50000]\n",
      "loss: 3.902734  [19010/50000]\n",
      "loss: 3.887680  [20010/50000]\n",
      "loss: 4.078795  [21010/50000]\n",
      "loss: 3.876324  [22010/50000]\n",
      "loss: 3.923144  [23010/50000]\n",
      "loss: 4.060527  [24010/50000]\n",
      "loss: 3.880018  [25010/50000]\n",
      "loss: 4.075704  [26010/50000]\n",
      "loss: 3.870345  [27010/50000]\n",
      "loss: 3.903277  [28010/50000]\n",
      "loss: 4.001077  [29010/50000]\n",
      "loss: 3.980633  [30010/50000]\n",
      "loss: 3.960257  [31010/50000]\n",
      "loss: 3.847974  [32010/50000]\n",
      "loss: 3.858810  [33010/50000]\n",
      "loss: 3.978710  [34010/50000]\n",
      "loss: 4.144269  [35010/50000]\n",
      "loss: 3.907324  [36010/50000]\n",
      "loss: 3.852685  [37010/50000]\n",
      "loss: 3.897962  [38010/50000]\n",
      "loss: 3.901708  [39010/50000]\n",
      "loss: 4.002154  [40010/50000]\n",
      "loss: 3.808141  [41010/50000]\n",
      "loss: 4.001802  [42010/50000]\n",
      "loss: 3.850626  [43010/50000]\n",
      "loss: 3.841052  [44010/50000]\n",
      "loss: 3.846796  [45010/50000]\n",
      "loss: 4.042190  [46010/50000]\n",
      "loss: 4.035684  [47010/50000]\n",
      "loss: 3.891578  [48010/50000]\n",
      "loss: 3.856686  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 30.4%, Avg loss: 3.981441 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 3.887482  [   10/50000]\n",
      "loss: 4.000593  [ 1010/50000]\n",
      "loss: 4.103997  [ 2010/50000]\n",
      "loss: 3.927944  [ 3010/50000]\n",
      "loss: 3.820204  [ 4010/50000]\n",
      "loss: 3.867510  [ 5010/50000]\n",
      "loss: 3.821572  [ 6010/50000]\n",
      "loss: 3.951503  [ 7010/50000]\n",
      "loss: 4.008198  [ 8010/50000]\n",
      "loss: 4.008516  [ 9010/50000]\n",
      "loss: 4.023356  [10010/50000]\n",
      "loss: 3.917755  [11010/50000]\n",
      "loss: 3.873877  [12010/50000]\n",
      "loss: 3.852291  [13010/50000]\n",
      "loss: 4.017669  [14010/50000]\n",
      "loss: 4.012513  [15010/50000]\n",
      "loss: 4.137292  [16010/50000]\n",
      "loss: 4.018077  [17010/50000]\n",
      "loss: 3.874835  [18010/50000]\n",
      "loss: 3.936413  [19010/50000]\n",
      "loss: 3.941947  [20010/50000]\n",
      "loss: 3.952224  [21010/50000]\n",
      "loss: 4.118403  [22010/50000]\n",
      "loss: 3.833087  [23010/50000]\n",
      "loss: 4.110214  [24010/50000]\n",
      "loss: 3.972991  [25010/50000]\n",
      "loss: 3.925388  [26010/50000]\n",
      "loss: 4.154850  [27010/50000]\n",
      "loss: 3.888470  [28010/50000]\n",
      "loss: 4.004884  [29010/50000]\n",
      "loss: 3.964978  [30010/50000]\n",
      "loss: 3.911963  [31010/50000]\n",
      "loss: 3.935588  [32010/50000]\n",
      "loss: 3.828085  [33010/50000]\n",
      "loss: 3.884040  [34010/50000]\n",
      "loss: 4.228688  [35010/50000]\n",
      "loss: 3.889103  [36010/50000]\n",
      "loss: 3.942297  [37010/50000]\n",
      "loss: 3.830092  [38010/50000]\n",
      "loss: 3.790638  [39010/50000]\n",
      "loss: 4.147025  [40010/50000]\n",
      "loss: 4.057355  [41010/50000]\n",
      "loss: 3.875984  [42010/50000]\n",
      "loss: 3.953838  [43010/50000]\n",
      "loss: 3.798543  [44010/50000]\n",
      "loss: 4.016950  [45010/50000]\n",
      "loss: 3.966040  [46010/50000]\n",
      "loss: 3.994492  [47010/50000]\n",
      "loss: 4.049834  [48010/50000]\n",
      "loss: 4.163593  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 25.8%, Avg loss: 4.021109 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 3.915591  [   10/50000]\n",
      "loss: 4.099127  [ 1010/50000]\n",
      "loss: 3.909082  [ 2010/50000]\n",
      "loss: 4.189669  [ 3010/50000]\n",
      "loss: 3.943471  [ 4010/50000]\n",
      "loss: 3.929493  [ 5010/50000]\n",
      "loss: 3.922213  [ 6010/50000]\n",
      "loss: 3.867183  [ 7010/50000]\n",
      "loss: 3.835856  [ 8010/50000]\n",
      "loss: 3.877350  [ 9010/50000]\n",
      "loss: 3.873756  [10010/50000]\n",
      "loss: 4.017670  [11010/50000]\n",
      "loss: 4.077920  [12010/50000]\n",
      "loss: 3.879297  [13010/50000]\n",
      "loss: 3.977610  [14010/50000]\n",
      "loss: 3.825805  [15010/50000]\n",
      "loss: 4.008492  [16010/50000]\n",
      "loss: 3.910369  [17010/50000]\n",
      "loss: 4.132190  [18010/50000]\n",
      "loss: 3.880297  [19010/50000]\n",
      "loss: 3.806935  [20010/50000]\n",
      "loss: 3.899807  [21010/50000]\n",
      "loss: 3.926477  [22010/50000]\n",
      "loss: 4.169602  [23010/50000]\n",
      "loss: 3.906776  [24010/50000]\n",
      "loss: 3.991708  [25010/50000]\n",
      "loss: 3.805841  [26010/50000]\n",
      "loss: 4.138085  [27010/50000]\n",
      "loss: 3.855911  [28010/50000]\n",
      "loss: 3.841637  [29010/50000]\n",
      "loss: 3.885224  [30010/50000]\n",
      "loss: 3.810274  [31010/50000]\n",
      "loss: 3.834303  [32010/50000]\n",
      "loss: 3.793664  [33010/50000]\n",
      "loss: 4.026155  [34010/50000]\n",
      "loss: 4.086856  [35010/50000]\n",
      "loss: 3.815065  [36010/50000]\n",
      "loss: 3.904125  [37010/50000]\n",
      "loss: 3.958101  [38010/50000]\n",
      "loss: 3.891979  [39010/50000]\n",
      "loss: 4.161394  [40010/50000]\n",
      "loss: 3.937715  [41010/50000]\n",
      "loss: 3.806068  [42010/50000]\n",
      "loss: 4.031344  [43010/50000]\n",
      "loss: 3.977753  [44010/50000]\n",
      "loss: 3.934159  [45010/50000]\n",
      "loss: 4.011735  [46010/50000]\n",
      "loss: 3.788891  [47010/50000]\n",
      "loss: 4.076432  [48010/50000]\n",
      "loss: 3.837354  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.5%, Avg loss: 3.967469 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 3.969140  [   10/50000]\n",
      "loss: 4.036401  [ 1010/50000]\n",
      "loss: 3.937880  [ 2010/50000]\n",
      "loss: 3.917261  [ 3010/50000]\n",
      "loss: 3.841416  [ 4010/50000]\n",
      "loss: 4.015109  [ 5010/50000]\n",
      "loss: 3.909976  [ 6010/50000]\n",
      "loss: 3.955620  [ 7010/50000]\n",
      "loss: 4.039201  [ 8010/50000]\n",
      "loss: 3.814424  [ 9010/50000]\n",
      "loss: 4.050527  [10010/50000]\n",
      "loss: 3.851167  [11010/50000]\n",
      "loss: 3.832223  [12010/50000]\n",
      "loss: 3.986697  [13010/50000]\n",
      "loss: 3.941833  [14010/50000]\n",
      "loss: 4.044282  [15010/50000]\n",
      "loss: 3.903075  [16010/50000]\n",
      "loss: 3.813095  [17010/50000]\n",
      "loss: 3.909061  [18010/50000]\n",
      "loss: 3.821896  [19010/50000]\n",
      "loss: 3.887033  [20010/50000]\n",
      "loss: 3.893558  [21010/50000]\n",
      "loss: 3.796712  [22010/50000]\n",
      "loss: 3.973336  [23010/50000]\n",
      "loss: 3.814512  [24010/50000]\n",
      "loss: 3.984327  [25010/50000]\n",
      "loss: 4.064399  [26010/50000]\n",
      "loss: 3.951728  [27010/50000]\n",
      "loss: 4.046197  [28010/50000]\n",
      "loss: 4.033989  [29010/50000]\n",
      "loss: 3.883360  [30010/50000]\n",
      "loss: 3.988374  [31010/50000]\n",
      "loss: 3.885063  [32010/50000]\n",
      "loss: 3.884258  [33010/50000]\n",
      "loss: 3.939047  [34010/50000]\n",
      "loss: 3.795589  [35010/50000]\n",
      "loss: 3.999845  [36010/50000]\n",
      "loss: 3.910939  [37010/50000]\n",
      "loss: 4.073189  [38010/50000]\n",
      "loss: 3.818607  [39010/50000]\n",
      "loss: 3.859733  [40010/50000]\n",
      "loss: 3.983100  [41010/50000]\n",
      "loss: 3.944404  [42010/50000]\n",
      "loss: 3.943061  [43010/50000]\n",
      "loss: 3.801053  [44010/50000]\n",
      "loss: 3.913310  [45010/50000]\n",
      "loss: 3.900664  [46010/50000]\n",
      "loss: 3.985871  [47010/50000]\n",
      "loss: 3.904138  [48010/50000]\n",
      "loss: 4.166325  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 3.966509 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 4.066506  [   10/50000]\n",
      "loss: 4.048609  [ 1010/50000]\n",
      "loss: 3.984755  [ 2010/50000]\n",
      "loss: 3.929258  [ 3010/50000]\n",
      "loss: 3.951735  [ 4010/50000]\n",
      "loss: 3.895938  [ 5010/50000]\n",
      "loss: 3.807036  [ 6010/50000]\n",
      "loss: 3.996005  [ 7010/50000]\n",
      "loss: 3.899747  [ 8010/50000]\n",
      "loss: 3.861512  [ 9010/50000]\n",
      "loss: 3.822050  [10010/50000]\n",
      "loss: 3.840704  [11010/50000]\n",
      "loss: 3.842374  [12010/50000]\n",
      "loss: 3.912131  [13010/50000]\n",
      "loss: 4.134517  [14010/50000]\n",
      "loss: 3.914259  [15010/50000]\n",
      "loss: 3.810318  [16010/50000]\n",
      "loss: 4.010112  [17010/50000]\n",
      "loss: 3.915147  [18010/50000]\n",
      "loss: 3.955621  [19010/50000]\n",
      "loss: 3.805412  [20010/50000]\n",
      "loss: 3.947462  [21010/50000]\n",
      "loss: 3.860638  [22010/50000]\n",
      "loss: 4.175999  [23010/50000]\n",
      "loss: 3.846716  [24010/50000]\n",
      "loss: 3.845879  [25010/50000]\n",
      "loss: 3.817998  [26010/50000]\n",
      "loss: 3.835674  [27010/50000]\n",
      "loss: 4.003289  [28010/50000]\n",
      "loss: 3.941144  [29010/50000]\n",
      "loss: 4.065549  [30010/50000]\n",
      "loss: 3.880649  [31010/50000]\n",
      "loss: 3.931381  [32010/50000]\n",
      "loss: 3.828417  [33010/50000]\n",
      "loss: 3.798625  [34010/50000]\n",
      "loss: 3.886021  [35010/50000]\n",
      "loss: 3.839085  [36010/50000]\n",
      "loss: 3.947177  [37010/50000]\n",
      "loss: 3.938944  [38010/50000]\n",
      "loss: 3.935246  [39010/50000]\n",
      "loss: 4.025127  [40010/50000]\n",
      "loss: 3.846192  [41010/50000]\n",
      "loss: 3.947445  [42010/50000]\n",
      "loss: 3.803466  [43010/50000]\n",
      "loss: 3.993350  [44010/50000]\n",
      "loss: 3.965466  [45010/50000]\n",
      "loss: 3.847349  [46010/50000]\n",
      "loss: 3.914154  [47010/50000]\n",
      "loss: 3.851333  [48010/50000]\n",
      "loss: 3.958331  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 3.971924 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 3.917118  [   10/50000]\n",
      "loss: 3.921911  [ 1010/50000]\n",
      "loss: 3.805574  [ 2010/50000]\n",
      "loss: 3.986609  [ 3010/50000]\n",
      "loss: 3.880934  [ 4010/50000]\n",
      "loss: 3.996982  [ 5010/50000]\n",
      "loss: 3.872830  [ 6010/50000]\n",
      "loss: 3.892267  [ 7010/50000]\n",
      "loss: 3.918951  [ 8010/50000]\n",
      "loss: 3.904566  [ 9010/50000]\n",
      "loss: 3.872838  [10010/50000]\n",
      "loss: 4.013420  [11010/50000]\n",
      "loss: 3.856548  [12010/50000]\n",
      "loss: 4.053644  [13010/50000]\n",
      "loss: 3.983062  [14010/50000]\n",
      "loss: 3.985926  [15010/50000]\n",
      "loss: 3.888124  [16010/50000]\n",
      "loss: 3.958110  [17010/50000]\n",
      "loss: 3.871352  [18010/50000]\n",
      "loss: 3.924428  [19010/50000]\n",
      "loss: 3.770463  [20010/50000]\n",
      "loss: 3.879136  [21010/50000]\n",
      "loss: 3.902797  [22010/50000]\n",
      "loss: 3.992960  [23010/50000]\n",
      "loss: 3.943228  [24010/50000]\n",
      "loss: 3.823687  [25010/50000]\n",
      "loss: 4.221500  [26010/50000]\n",
      "loss: 3.800041  [27010/50000]\n",
      "loss: 3.923740  [28010/50000]\n",
      "loss: 3.851103  [29010/50000]\n",
      "loss: 3.898629  [30010/50000]\n",
      "loss: 3.954275  [31010/50000]\n",
      "loss: 3.924632  [32010/50000]\n",
      "loss: 3.932061  [33010/50000]\n",
      "loss: 4.001992  [34010/50000]\n",
      "loss: 4.039360  [35010/50000]\n",
      "loss: 3.885155  [36010/50000]\n",
      "loss: 4.044615  [37010/50000]\n",
      "loss: 3.886200  [38010/50000]\n",
      "loss: 3.947269  [39010/50000]\n",
      "loss: 4.020178  [40010/50000]\n",
      "loss: 3.801099  [41010/50000]\n",
      "loss: 3.953053  [42010/50000]\n",
      "loss: 3.876750  [43010/50000]\n",
      "loss: 3.883228  [44010/50000]\n",
      "loss: 3.882148  [45010/50000]\n",
      "loss: 3.986820  [46010/50000]\n",
      "loss: 3.882294  [47010/50000]\n",
      "loss: 3.988445  [48010/50000]\n",
      "loss: 3.905924  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.2%, Avg loss: 3.957540 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 4.062943  [   10/50000]\n",
      "loss: 3.904499  [ 1010/50000]\n",
      "loss: 3.902318  [ 2010/50000]\n",
      "loss: 4.039802  [ 3010/50000]\n",
      "loss: 3.918481  [ 4010/50000]\n",
      "loss: 3.815287  [ 5010/50000]\n",
      "loss: 3.957805  [ 6010/50000]\n",
      "loss: 3.931674  [ 7010/50000]\n",
      "loss: 3.840033  [ 8010/50000]\n",
      "loss: 3.813891  [ 9010/50000]\n",
      "loss: 3.987777  [10010/50000]\n",
      "loss: 3.807017  [11010/50000]\n",
      "loss: 3.881051  [12010/50000]\n",
      "loss: 3.774672  [13010/50000]\n",
      "loss: 3.993254  [14010/50000]\n",
      "loss: 3.827651  [15010/50000]\n",
      "loss: 4.080582  [16010/50000]\n",
      "loss: 3.917014  [17010/50000]\n",
      "loss: 3.962432  [18010/50000]\n",
      "loss: 3.940808  [19010/50000]\n",
      "loss: 3.912055  [20010/50000]\n",
      "loss: 3.968653  [21010/50000]\n",
      "loss: 3.929535  [22010/50000]\n",
      "loss: 3.874809  [23010/50000]\n",
      "loss: 3.821077  [24010/50000]\n",
      "loss: 4.030839  [25010/50000]\n",
      "loss: 3.821898  [26010/50000]\n",
      "loss: 3.879299  [27010/50000]\n",
      "loss: 3.763031  [28010/50000]\n",
      "loss: 3.882079  [29010/50000]\n",
      "loss: 3.929345  [30010/50000]\n",
      "loss: 3.885362  [31010/50000]\n",
      "loss: 3.897982  [32010/50000]\n",
      "loss: 3.786751  [33010/50000]\n",
      "loss: 3.979144  [34010/50000]\n",
      "loss: 3.921398  [35010/50000]\n",
      "loss: 3.861443  [36010/50000]\n",
      "loss: 3.908739  [37010/50000]\n",
      "loss: 3.894674  [38010/50000]\n",
      "loss: 4.032304  [39010/50000]\n",
      "loss: 4.067365  [40010/50000]\n",
      "loss: 3.779207  [41010/50000]\n",
      "loss: 4.038940  [42010/50000]\n",
      "loss: 3.900998  [43010/50000]\n",
      "loss: 3.825409  [44010/50000]\n",
      "loss: 3.983504  [45010/50000]\n",
      "loss: 3.879673  [46010/50000]\n",
      "loss: 3.814477  [47010/50000]\n",
      "loss: 3.808084  [48010/50000]\n",
      "loss: 3.784011  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 3.954057 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 3.803986  [   10/50000]\n",
      "loss: 3.941276  [ 1010/50000]\n",
      "loss: 3.793184  [ 2010/50000]\n",
      "loss: 3.913682  [ 3010/50000]\n",
      "loss: 4.001798  [ 4010/50000]\n",
      "loss: 3.776180  [ 5010/50000]\n",
      "loss: 3.854691  [ 6010/50000]\n",
      "loss: 3.875897  [ 7010/50000]\n",
      "loss: 3.989640  [ 8010/50000]\n",
      "loss: 3.850177  [ 9010/50000]\n",
      "loss: 3.780265  [10010/50000]\n",
      "loss: 3.894425  [11010/50000]\n",
      "loss: 3.882874  [12010/50000]\n",
      "loss: 3.852412  [13010/50000]\n",
      "loss: 3.940128  [14010/50000]\n",
      "loss: 3.976810  [15010/50000]\n",
      "loss: 3.828870  [16010/50000]\n",
      "loss: 3.899920  [17010/50000]\n",
      "loss: 3.859998  [18010/50000]\n",
      "loss: 3.825918  [19010/50000]\n",
      "loss: 3.810899  [20010/50000]\n",
      "loss: 3.922037  [21010/50000]\n",
      "loss: 3.783168  [22010/50000]\n",
      "loss: 3.832049  [23010/50000]\n",
      "loss: 3.767740  [24010/50000]\n",
      "loss: 3.875146  [25010/50000]\n",
      "loss: 4.004569  [26010/50000]\n",
      "loss: 3.845581  [27010/50000]\n",
      "loss: 3.874097  [28010/50000]\n",
      "loss: 4.065827  [29010/50000]\n",
      "loss: 3.971155  [30010/50000]\n",
      "loss: 3.922810  [31010/50000]\n",
      "loss: 4.075133  [32010/50000]\n",
      "loss: 3.776383  [33010/50000]\n",
      "loss: 3.865840  [34010/50000]\n",
      "loss: 3.946081  [35010/50000]\n",
      "loss: 3.938543  [36010/50000]\n",
      "loss: 3.929462  [37010/50000]\n",
      "loss: 3.825612  [38010/50000]\n",
      "loss: 3.863782  [39010/50000]\n",
      "loss: 3.814981  [40010/50000]\n",
      "loss: 3.905036  [41010/50000]\n",
      "loss: 3.913781  [42010/50000]\n",
      "loss: 3.792502  [43010/50000]\n",
      "loss: 3.804284  [44010/50000]\n",
      "loss: 4.009901  [45010/50000]\n",
      "loss: 4.161545  [46010/50000]\n",
      "loss: 3.976885  [47010/50000]\n",
      "loss: 3.832328  [48010/50000]\n",
      "loss: 3.774459  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 3.958685 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 3.802164  [   10/50000]\n",
      "loss: 3.843611  [ 1010/50000]\n",
      "loss: 4.018412  [ 2010/50000]\n",
      "loss: 3.827709  [ 3010/50000]\n",
      "loss: 4.038973  [ 4010/50000]\n",
      "loss: 3.896825  [ 5010/50000]\n",
      "loss: 3.907434  [ 6010/50000]\n",
      "loss: 3.910459  [ 7010/50000]\n",
      "loss: 3.855605  [ 8010/50000]\n",
      "loss: 4.016501  [ 9010/50000]\n",
      "loss: 3.979739  [10010/50000]\n",
      "loss: 3.852528  [11010/50000]\n",
      "loss: 3.850934  [12010/50000]\n",
      "loss: 3.967898  [13010/50000]\n",
      "loss: 3.990416  [14010/50000]\n",
      "loss: 3.814948  [15010/50000]\n",
      "loss: 3.917011  [16010/50000]\n",
      "loss: 3.900133  [17010/50000]\n",
      "loss: 3.800963  [18010/50000]\n",
      "loss: 3.988217  [19010/50000]\n",
      "loss: 3.863358  [20010/50000]\n",
      "loss: 3.777738  [21010/50000]\n",
      "loss: 3.771556  [22010/50000]\n",
      "loss: 3.888563  [23010/50000]\n",
      "loss: 3.955511  [24010/50000]\n",
      "loss: 3.941514  [25010/50000]\n",
      "loss: 3.947036  [26010/50000]\n",
      "loss: 3.985460  [27010/50000]\n",
      "loss: 3.855230  [28010/50000]\n",
      "loss: 3.898885  [29010/50000]\n",
      "loss: 3.773503  [30010/50000]\n",
      "loss: 4.097486  [31010/50000]\n",
      "loss: 3.915859  [32010/50000]\n",
      "loss: 3.925697  [33010/50000]\n",
      "loss: 3.802467  [34010/50000]\n",
      "loss: 4.136197  [35010/50000]\n",
      "loss: 3.786787  [36010/50000]\n",
      "loss: 4.012943  [37010/50000]\n",
      "loss: 3.901616  [38010/50000]\n",
      "loss: 3.811349  [39010/50000]\n",
      "loss: 3.903682  [40010/50000]\n",
      "loss: 3.846714  [41010/50000]\n",
      "loss: 3.821239  [42010/50000]\n",
      "loss: 3.953395  [43010/50000]\n",
      "loss: 3.764423  [44010/50000]\n",
      "loss: 3.904449  [45010/50000]\n",
      "loss: 3.826642  [46010/50000]\n",
      "loss: 3.889246  [47010/50000]\n",
      "loss: 3.917958  [48010/50000]\n",
      "loss: 3.778836  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 3.948944 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 3.964667  [   10/50000]\n",
      "loss: 3.744100  [ 1010/50000]\n",
      "loss: 3.813086  [ 2010/50000]\n",
      "loss: 3.896393  [ 3010/50000]\n",
      "loss: 3.791310  [ 4010/50000]\n",
      "loss: 4.191977  [ 5010/50000]\n",
      "loss: 3.802512  [ 6010/50000]\n",
      "loss: 3.767432  [ 7010/50000]\n",
      "loss: 3.887124  [ 8010/50000]\n",
      "loss: 3.857791  [ 9010/50000]\n",
      "loss: 3.843527  [10010/50000]\n",
      "loss: 3.781489  [11010/50000]\n",
      "loss: 3.765105  [12010/50000]\n",
      "loss: 3.923749  [13010/50000]\n",
      "loss: 3.826043  [14010/50000]\n",
      "loss: 3.942070  [15010/50000]\n",
      "loss: 3.815125  [16010/50000]\n",
      "loss: 3.845137  [17010/50000]\n",
      "loss: 3.884528  [18010/50000]\n",
      "loss: 3.840878  [19010/50000]\n",
      "loss: 3.871329  [20010/50000]\n",
      "loss: 4.090802  [21010/50000]\n",
      "loss: 3.881679  [22010/50000]\n",
      "loss: 3.890183  [23010/50000]\n",
      "loss: 3.815738  [24010/50000]\n",
      "loss: 3.919355  [25010/50000]\n",
      "loss: 3.921233  [26010/50000]\n",
      "loss: 3.818857  [27010/50000]\n",
      "loss: 3.982520  [28010/50000]\n",
      "loss: 3.876903  [29010/50000]\n",
      "loss: 3.829001  [30010/50000]\n",
      "loss: 3.935008  [31010/50000]\n",
      "loss: 3.913337  [32010/50000]\n",
      "loss: 4.059659  [33010/50000]\n",
      "loss: 3.899342  [34010/50000]\n",
      "loss: 3.907441  [35010/50000]\n",
      "loss: 3.818488  [36010/50000]\n",
      "loss: 3.876021  [37010/50000]\n",
      "loss: 3.796277  [38010/50000]\n",
      "loss: 3.959551  [39010/50000]\n",
      "loss: 3.868090  [40010/50000]\n",
      "loss: 3.919655  [41010/50000]\n",
      "loss: 3.903066  [42010/50000]\n",
      "loss: 4.070066  [43010/50000]\n",
      "loss: 4.104415  [44010/50000]\n",
      "loss: 3.884253  [45010/50000]\n",
      "loss: 3.785748  [46010/50000]\n",
      "loss: 4.076831  [47010/50000]\n",
      "loss: 3.876441  [48010/50000]\n",
      "loss: 3.925359  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.0%, Avg loss: 3.947243 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 3.796938  [   10/50000]\n",
      "loss: 3.865688  [ 1010/50000]\n",
      "loss: 3.760967  [ 2010/50000]\n",
      "loss: 3.814414  [ 3010/50000]\n",
      "loss: 3.872545  [ 4010/50000]\n",
      "loss: 3.950599  [ 5010/50000]\n",
      "loss: 3.870999  [ 6010/50000]\n",
      "loss: 3.773586  [ 7010/50000]\n",
      "loss: 3.908295  [ 8010/50000]\n",
      "loss: 3.840270  [ 9010/50000]\n",
      "loss: 3.888861  [10010/50000]\n",
      "loss: 4.040783  [11010/50000]\n",
      "loss: 3.830151  [12010/50000]\n",
      "loss: 3.878177  [13010/50000]\n",
      "loss: 3.777608  [14010/50000]\n",
      "loss: 3.857280  [15010/50000]\n",
      "loss: 3.889872  [16010/50000]\n",
      "loss: 3.858516  [17010/50000]\n",
      "loss: 3.921752  [18010/50000]\n",
      "loss: 4.101012  [19010/50000]\n",
      "loss: 3.853890  [20010/50000]\n",
      "loss: 3.771477  [21010/50000]\n",
      "loss: 3.903188  [22010/50000]\n",
      "loss: 3.762175  [23010/50000]\n",
      "loss: 3.873379  [24010/50000]\n",
      "loss: 3.855473  [25010/50000]\n",
      "loss: 3.818914  [26010/50000]\n",
      "loss: 3.779448  [27010/50000]\n",
      "loss: 4.003257  [28010/50000]\n",
      "loss: 3.937846  [29010/50000]\n",
      "loss: 3.982583  [30010/50000]\n",
      "loss: 3.786149  [31010/50000]\n",
      "loss: 3.781811  [32010/50000]\n",
      "loss: 4.025869  [33010/50000]\n",
      "loss: 3.779346  [34010/50000]\n",
      "loss: 3.855111  [35010/50000]\n",
      "loss: 3.953389  [36010/50000]\n",
      "loss: 3.909991  [37010/50000]\n",
      "loss: 3.993968  [38010/50000]\n",
      "loss: 3.883088  [39010/50000]\n",
      "loss: 4.025785  [40010/50000]\n",
      "loss: 3.920526  [41010/50000]\n",
      "loss: 3.761978  [42010/50000]\n",
      "loss: 4.017279  [43010/50000]\n",
      "loss: 3.809389  [44010/50000]\n",
      "loss: 3.795896  [45010/50000]\n",
      "loss: 3.812459  [46010/50000]\n",
      "loss: 3.786982  [47010/50000]\n",
      "loss: 3.827853  [48010/50000]\n",
      "loss: 3.833807  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 3.955481 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 3.803847  [   10/50000]\n",
      "loss: 3.864622  [ 1010/50000]\n",
      "loss: 3.824338  [ 2010/50000]\n",
      "loss: 3.794098  [ 3010/50000]\n",
      "loss: 3.761267  [ 4010/50000]\n",
      "loss: 3.809555  [ 5010/50000]\n",
      "loss: 3.863961  [ 6010/50000]\n",
      "loss: 3.853572  [ 7010/50000]\n",
      "loss: 3.930191  [ 8010/50000]\n",
      "loss: 3.769073  [ 9010/50000]\n",
      "loss: 3.868734  [10010/50000]\n",
      "loss: 3.857437  [11010/50000]\n",
      "loss: 3.947294  [12010/50000]\n",
      "loss: 3.821578  [13010/50000]\n",
      "loss: 3.979235  [14010/50000]\n",
      "loss: 3.846850  [15010/50000]\n",
      "loss: 3.891400  [16010/50000]\n",
      "loss: 3.858303  [17010/50000]\n",
      "loss: 3.771964  [18010/50000]\n",
      "loss: 3.892178  [19010/50000]\n",
      "loss: 3.815531  [20010/50000]\n",
      "loss: 3.848221  [21010/50000]\n",
      "loss: 3.790684  [22010/50000]\n",
      "loss: 3.779953  [23010/50000]\n",
      "loss: 3.854064  [24010/50000]\n",
      "loss: 3.846564  [25010/50000]\n",
      "loss: 3.827698  [26010/50000]\n",
      "loss: 4.002391  [27010/50000]\n",
      "loss: 3.993434  [28010/50000]\n",
      "loss: 3.971109  [29010/50000]\n",
      "loss: 3.863321  [30010/50000]\n",
      "loss: 3.849858  [31010/50000]\n",
      "loss: 3.854851  [32010/50000]\n",
      "loss: 3.768576  [33010/50000]\n",
      "loss: 3.770713  [34010/50000]\n",
      "loss: 3.988739  [35010/50000]\n",
      "loss: 3.903421  [36010/50000]\n",
      "loss: 4.032520  [37010/50000]\n",
      "loss: 3.799219  [38010/50000]\n",
      "loss: 3.852680  [39010/50000]\n",
      "loss: 3.773456  [40010/50000]\n",
      "loss: 3.786060  [41010/50000]\n",
      "loss: 4.043268  [42010/50000]\n",
      "loss: 3.866996  [43010/50000]\n",
      "loss: 3.916178  [44010/50000]\n",
      "loss: 3.979588  [45010/50000]\n",
      "loss: 3.938641  [46010/50000]\n",
      "loss: 3.829961  [47010/50000]\n",
      "loss: 3.934851  [48010/50000]\n",
      "loss: 3.852032  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.3%, Avg loss: 3.950583 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 3.845402  [   10/50000]\n",
      "loss: 3.942162  [ 1010/50000]\n",
      "loss: 3.752002  [ 2010/50000]\n",
      "loss: 3.845975  [ 3010/50000]\n",
      "loss: 3.811404  [ 4010/50000]\n",
      "loss: 3.761099  [ 5010/50000]\n",
      "loss: 3.761065  [ 6010/50000]\n",
      "loss: 3.775646  [ 7010/50000]\n",
      "loss: 3.799906  [ 8010/50000]\n",
      "loss: 3.855141  [ 9010/50000]\n",
      "loss: 3.780813  [10010/50000]\n",
      "loss: 3.916711  [11010/50000]\n",
      "loss: 3.917204  [12010/50000]\n",
      "loss: 3.796485  [13010/50000]\n",
      "loss: 3.752846  [14010/50000]\n",
      "loss: 3.854059  [15010/50000]\n",
      "loss: 3.810615  [16010/50000]\n",
      "loss: 3.781391  [17010/50000]\n",
      "loss: 3.873237  [18010/50000]\n",
      "loss: 3.996990  [19010/50000]\n",
      "loss: 3.792570  [20010/50000]\n",
      "loss: 3.795016  [21010/50000]\n",
      "loss: 3.776920  [22010/50000]\n",
      "loss: 3.782178  [23010/50000]\n",
      "loss: 3.791088  [24010/50000]\n",
      "loss: 3.857095  [25010/50000]\n",
      "loss: 3.830114  [26010/50000]\n",
      "loss: 3.769165  [27010/50000]\n",
      "loss: 3.853783  [28010/50000]\n",
      "loss: 3.879873  [29010/50000]\n",
      "loss: 4.003617  [30010/50000]\n",
      "loss: 3.864052  [31010/50000]\n",
      "loss: 3.788129  [32010/50000]\n",
      "loss: 3.940972  [33010/50000]\n",
      "loss: 3.870253  [34010/50000]\n",
      "loss: 3.926374  [35010/50000]\n",
      "loss: 3.795385  [36010/50000]\n",
      "loss: 3.901280  [37010/50000]\n",
      "loss: 3.962458  [38010/50000]\n",
      "loss: 3.783175  [39010/50000]\n",
      "loss: 3.820393  [40010/50000]\n",
      "loss: 3.980406  [41010/50000]\n",
      "loss: 3.930805  [42010/50000]\n",
      "loss: 3.836675  [43010/50000]\n",
      "loss: 3.820154  [44010/50000]\n",
      "loss: 3.978673  [45010/50000]\n",
      "loss: 3.823766  [46010/50000]\n",
      "loss: 3.753683  [47010/50000]\n",
      "loss: 3.823642  [48010/50000]\n",
      "loss: 3.966880  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 3.943257 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 3.841359  [   10/50000]\n",
      "loss: 4.001252  [ 1010/50000]\n",
      "loss: 3.835686  [ 2010/50000]\n",
      "loss: 3.772766  [ 3010/50000]\n",
      "loss: 3.919305  [ 4010/50000]\n",
      "loss: 3.777224  [ 5010/50000]\n",
      "loss: 3.963069  [ 6010/50000]\n",
      "loss: 3.904354  [ 7010/50000]\n",
      "loss: 3.916752  [ 8010/50000]\n",
      "loss: 3.762868  [ 9010/50000]\n",
      "loss: 3.989870  [10010/50000]\n",
      "loss: 3.754102  [11010/50000]\n",
      "loss: 3.800419  [12010/50000]\n",
      "loss: 3.803675  [13010/50000]\n",
      "loss: 3.846000  [14010/50000]\n",
      "loss: 3.851309  [15010/50000]\n",
      "loss: 3.954029  [16010/50000]\n",
      "loss: 3.931927  [17010/50000]\n",
      "loss: 3.743006  [18010/50000]\n",
      "loss: 3.767862  [19010/50000]\n",
      "loss: 3.810696  [20010/50000]\n",
      "loss: 3.883666  [21010/50000]\n",
      "loss: 3.829924  [22010/50000]\n",
      "loss: 3.754315  [23010/50000]\n",
      "loss: 3.963327  [24010/50000]\n",
      "loss: 4.016747  [25010/50000]\n",
      "loss: 3.749951  [26010/50000]\n",
      "loss: 3.883553  [27010/50000]\n",
      "loss: 3.997740  [28010/50000]\n",
      "loss: 3.767905  [29010/50000]\n",
      "loss: 3.871886  [30010/50000]\n",
      "loss: 3.787395  [31010/50000]\n",
      "loss: 3.826049  [32010/50000]\n",
      "loss: 3.856142  [33010/50000]\n",
      "loss: 3.812017  [34010/50000]\n",
      "loss: 3.971211  [35010/50000]\n",
      "loss: 3.809232  [36010/50000]\n",
      "loss: 4.096885  [37010/50000]\n",
      "loss: 3.811249  [38010/50000]\n",
      "loss: 3.833066  [39010/50000]\n",
      "loss: 3.759843  [40010/50000]\n",
      "loss: 4.126551  [41010/50000]\n",
      "loss: 3.798548  [42010/50000]\n",
      "loss: 3.824687  [43010/50000]\n",
      "loss: 3.854666  [44010/50000]\n",
      "loss: 3.767638  [45010/50000]\n",
      "loss: 3.869436  [46010/50000]\n",
      "loss: 3.761439  [47010/50000]\n",
      "loss: 3.851685  [48010/50000]\n",
      "loss: 3.888183  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 3.946480 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 3.893859  [   10/50000]\n",
      "loss: 3.871038  [ 1010/50000]\n",
      "loss: 3.786628  [ 2010/50000]\n",
      "loss: 3.951420  [ 3010/50000]\n",
      "loss: 3.761291  [ 4010/50000]\n",
      "loss: 3.875372  [ 5010/50000]\n",
      "loss: 3.911283  [ 6010/50000]\n",
      "loss: 3.769075  [ 7010/50000]\n",
      "loss: 4.063643  [ 8010/50000]\n",
      "loss: 3.896854  [ 9010/50000]\n",
      "loss: 3.801144  [10010/50000]\n",
      "loss: 3.956504  [11010/50000]\n",
      "loss: 3.782460  [12010/50000]\n",
      "loss: 3.818739  [13010/50000]\n",
      "loss: 3.835692  [14010/50000]\n",
      "loss: 3.773041  [15010/50000]\n",
      "loss: 3.901518  [16010/50000]\n",
      "loss: 3.924791  [17010/50000]\n",
      "loss: 3.891963  [18010/50000]\n",
      "loss: 3.794849  [19010/50000]\n",
      "loss: 3.845906  [20010/50000]\n",
      "loss: 3.777484  [21010/50000]\n",
      "loss: 3.794967  [22010/50000]\n",
      "loss: 3.763559  [23010/50000]\n",
      "loss: 3.982440  [24010/50000]\n",
      "loss: 3.910416  [25010/50000]\n",
      "loss: 3.782483  [26010/50000]\n",
      "loss: 3.781277  [27010/50000]\n",
      "loss: 3.996143  [28010/50000]\n",
      "loss: 4.128031  [29010/50000]\n",
      "loss: 3.870087  [30010/50000]\n",
      "loss: 3.943824  [31010/50000]\n",
      "loss: 3.833485  [32010/50000]\n",
      "loss: 3.860756  [33010/50000]\n",
      "loss: 3.869969  [34010/50000]\n",
      "loss: 3.918438  [35010/50000]\n",
      "loss: 3.826724  [36010/50000]\n",
      "loss: 3.770570  [37010/50000]\n",
      "loss: 3.762638  [38010/50000]\n",
      "loss: 3.883001  [39010/50000]\n",
      "loss: 3.836219  [40010/50000]\n",
      "loss: 3.865973  [41010/50000]\n",
      "loss: 3.848247  [42010/50000]\n",
      "loss: 3.865438  [43010/50000]\n",
      "loss: 3.776228  [44010/50000]\n",
      "loss: 3.921185  [45010/50000]\n",
      "loss: 3.781061  [46010/50000]\n",
      "loss: 3.864724  [47010/50000]\n",
      "loss: 3.872452  [48010/50000]\n",
      "loss: 3.974000  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.5%, Avg loss: 3.941331 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.013910  [   10/50000]\n",
      "loss: 3.909701  [ 1010/50000]\n",
      "loss: 3.792336  [ 2010/50000]\n",
      "loss: 3.862980  [ 3010/50000]\n",
      "loss: 3.955518  [ 4010/50000]\n",
      "loss: 3.744904  [ 5010/50000]\n",
      "loss: 3.914048  [ 6010/50000]\n",
      "loss: 3.779401  [ 7010/50000]\n",
      "loss: 3.757117  [ 8010/50000]\n",
      "loss: 3.750886  [ 9010/50000]\n",
      "loss: 3.855224  [10010/50000]\n",
      "loss: 4.094243  [11010/50000]\n",
      "loss: 3.830574  [12010/50000]\n",
      "loss: 3.797263  [13010/50000]\n",
      "loss: 4.113146  [14010/50000]\n",
      "loss: 3.774372  [15010/50000]\n",
      "loss: 3.764418  [16010/50000]\n",
      "loss: 3.900262  [17010/50000]\n",
      "loss: 3.850894  [18010/50000]\n",
      "loss: 3.886729  [19010/50000]\n",
      "loss: 3.855945  [20010/50000]\n",
      "loss: 3.864247  [21010/50000]\n",
      "loss: 3.879863  [22010/50000]\n",
      "loss: 3.816069  [23010/50000]\n",
      "loss: 3.772516  [24010/50000]\n",
      "loss: 3.780416  [25010/50000]\n",
      "loss: 3.764778  [26010/50000]\n",
      "loss: 3.883420  [27010/50000]\n",
      "loss: 3.828571  [28010/50000]\n",
      "loss: 3.838132  [29010/50000]\n",
      "loss: 3.998326  [30010/50000]\n",
      "loss: 3.838783  [31010/50000]\n",
      "loss: 3.958827  [32010/50000]\n",
      "loss: 3.952328  [33010/50000]\n",
      "loss: 3.764128  [34010/50000]\n",
      "loss: 3.861455  [35010/50000]\n",
      "loss: 3.947041  [36010/50000]\n",
      "loss: 3.874606  [37010/50000]\n",
      "loss: 3.824114  [38010/50000]\n",
      "loss: 3.874987  [39010/50000]\n",
      "loss: 3.890316  [40010/50000]\n",
      "loss: 3.953969  [41010/50000]\n",
      "loss: 3.825821  [42010/50000]\n",
      "loss: 3.788029  [43010/50000]\n",
      "loss: 3.847450  [44010/50000]\n",
      "loss: 4.024692  [45010/50000]\n",
      "loss: 3.784198  [46010/50000]\n",
      "loss: 3.783905  [47010/50000]\n",
      "loss: 3.882978  [48010/50000]\n",
      "loss: 3.770072  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 3.943306 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 3.761150  [   10/50000]\n",
      "loss: 3.773528  [ 1010/50000]\n",
      "loss: 3.998652  [ 2010/50000]\n",
      "loss: 3.936962  [ 3010/50000]\n",
      "loss: 3.823140  [ 4010/50000]\n",
      "loss: 3.754875  [ 5010/50000]\n",
      "loss: 3.836410  [ 6010/50000]\n",
      "loss: 3.869616  [ 7010/50000]\n",
      "loss: 3.768594  [ 8010/50000]\n",
      "loss: 3.761198  [ 9010/50000]\n",
      "loss: 3.742215  [10010/50000]\n",
      "loss: 3.871696  [11010/50000]\n",
      "loss: 3.828097  [12010/50000]\n",
      "loss: 3.838108  [13010/50000]\n",
      "loss: 3.732646  [14010/50000]\n",
      "loss: 3.901508  [15010/50000]\n",
      "loss: 3.887688  [16010/50000]\n",
      "loss: 3.843672  [17010/50000]\n",
      "loss: 3.893403  [18010/50000]\n",
      "loss: 3.798624  [19010/50000]\n",
      "loss: 3.883324  [20010/50000]\n",
      "loss: 3.889899  [21010/50000]\n",
      "loss: 3.900516  [22010/50000]\n",
      "loss: 3.835704  [23010/50000]\n",
      "loss: 3.834277  [24010/50000]\n",
      "loss: 3.892787  [25010/50000]\n",
      "loss: 3.749870  [26010/50000]\n",
      "loss: 3.753464  [27010/50000]\n",
      "loss: 3.863865  [28010/50000]\n",
      "loss: 3.805219  [29010/50000]\n",
      "loss: 3.803184  [30010/50000]\n",
      "loss: 3.769664  [31010/50000]\n",
      "loss: 3.905231  [32010/50000]\n",
      "loss: 3.852627  [33010/50000]\n",
      "loss: 3.871092  [34010/50000]\n",
      "loss: 3.754073  [35010/50000]\n",
      "loss: 3.954543  [36010/50000]\n",
      "loss: 3.775650  [37010/50000]\n",
      "loss: 3.894271  [38010/50000]\n",
      "loss: 3.782100  [39010/50000]\n",
      "loss: 3.814395  [40010/50000]\n",
      "loss: 3.806083  [41010/50000]\n",
      "loss: 3.840647  [42010/50000]\n",
      "loss: 3.848851  [43010/50000]\n",
      "loss: 4.003457  [44010/50000]\n",
      "loss: 3.927982  [45010/50000]\n",
      "loss: 3.832466  [46010/50000]\n",
      "loss: 3.766200  [47010/50000]\n",
      "loss: 3.979742  [48010/50000]\n",
      "loss: 3.774832  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 3.938945 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 3.906725  [   10/50000]\n",
      "loss: 3.762289  [ 1010/50000]\n",
      "loss: 3.774937  [ 2010/50000]\n",
      "loss: 3.930541  [ 3010/50000]\n",
      "loss: 3.739124  [ 4010/50000]\n",
      "loss: 3.932174  [ 5010/50000]\n",
      "loss: 3.873014  [ 6010/50000]\n",
      "loss: 3.774072  [ 7010/50000]\n",
      "loss: 3.773935  [ 8010/50000]\n",
      "loss: 3.793459  [ 9010/50000]\n",
      "loss: 3.802878  [10010/50000]\n",
      "loss: 3.897197  [11010/50000]\n",
      "loss: 3.894599  [12010/50000]\n",
      "loss: 3.804174  [13010/50000]\n",
      "loss: 3.748663  [14010/50000]\n",
      "loss: 3.796749  [15010/50000]\n",
      "loss: 3.914014  [16010/50000]\n",
      "loss: 3.963862  [17010/50000]\n",
      "loss: 3.754269  [18010/50000]\n",
      "loss: 3.837361  [19010/50000]\n",
      "loss: 3.783731  [20010/50000]\n",
      "loss: 4.001782  [21010/50000]\n",
      "loss: 3.767952  [22010/50000]\n",
      "loss: 3.777223  [23010/50000]\n",
      "loss: 3.955730  [24010/50000]\n",
      "loss: 3.889149  [25010/50000]\n",
      "loss: 3.891773  [26010/50000]\n",
      "loss: 3.834033  [27010/50000]\n",
      "loss: 3.745619  [28010/50000]\n",
      "loss: 3.735559  [29010/50000]\n",
      "loss: 3.855036  [30010/50000]\n",
      "loss: 3.744254  [31010/50000]\n",
      "loss: 3.860455  [32010/50000]\n",
      "loss: 3.793879  [33010/50000]\n",
      "loss: 3.744572  [34010/50000]\n",
      "loss: 3.763771  [35010/50000]\n",
      "loss: 3.753039  [36010/50000]\n",
      "loss: 3.750955  [37010/50000]\n",
      "loss: 3.865456  [38010/50000]\n",
      "loss: 3.897329  [39010/50000]\n",
      "loss: 3.778561  [40010/50000]\n",
      "loss: 3.804322  [41010/50000]\n",
      "loss: 3.779773  [42010/50000]\n",
      "loss: 3.841707  [43010/50000]\n",
      "loss: 3.787146  [44010/50000]\n",
      "loss: 3.942510  [45010/50000]\n",
      "loss: 3.872321  [46010/50000]\n",
      "loss: 3.760765  [47010/50000]\n",
      "loss: 3.777876  [48010/50000]\n",
      "loss: 3.867718  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.0%, Avg loss: 3.936170 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 3.754577  [   10/50000]\n",
      "loss: 3.828974  [ 1010/50000]\n",
      "loss: 3.778079  [ 2010/50000]\n",
      "loss: 3.887490  [ 3010/50000]\n",
      "loss: 3.737708  [ 4010/50000]\n",
      "loss: 3.847472  [ 5010/50000]\n",
      "loss: 3.740925  [ 6010/50000]\n",
      "loss: 3.835501  [ 7010/50000]\n",
      "loss: 3.979970  [ 8010/50000]\n",
      "loss: 3.742411  [ 9010/50000]\n",
      "loss: 3.931911  [10010/50000]\n",
      "loss: 3.905972  [11010/50000]\n",
      "loss: 3.791997  [12010/50000]\n",
      "loss: 3.761604  [13010/50000]\n",
      "loss: 3.840289  [14010/50000]\n",
      "loss: 3.740524  [15010/50000]\n",
      "loss: 3.769736  [16010/50000]\n",
      "loss: 3.948076  [17010/50000]\n",
      "loss: 4.012864  [18010/50000]\n",
      "loss: 3.834441  [19010/50000]\n",
      "loss: 3.789577  [20010/50000]\n",
      "loss: 3.752433  [21010/50000]\n",
      "loss: 3.797727  [22010/50000]\n",
      "loss: 3.957262  [23010/50000]\n",
      "loss: 3.813665  [24010/50000]\n",
      "loss: 3.847903  [25010/50000]\n",
      "loss: 3.748057  [26010/50000]\n",
      "loss: 3.816219  [27010/50000]\n",
      "loss: 3.940831  [28010/50000]\n",
      "loss: 3.889702  [29010/50000]\n",
      "loss: 4.014973  [30010/50000]\n",
      "loss: 3.779711  [31010/50000]\n",
      "loss: 3.753999  [32010/50000]\n",
      "loss: 3.846189  [33010/50000]\n",
      "loss: 3.795019  [34010/50000]\n",
      "loss: 3.744062  [35010/50000]\n",
      "loss: 3.779634  [36010/50000]\n",
      "loss: 3.788159  [37010/50000]\n",
      "loss: 3.809725  [38010/50000]\n",
      "loss: 3.808228  [39010/50000]\n",
      "loss: 3.744942  [40010/50000]\n",
      "loss: 3.759781  [41010/50000]\n",
      "loss: 3.755277  [42010/50000]\n",
      "loss: 3.872514  [43010/50000]\n",
      "loss: 3.751888  [44010/50000]\n",
      "loss: 3.784649  [45010/50000]\n",
      "loss: 3.843590  [46010/50000]\n",
      "loss: 3.767961  [47010/50000]\n",
      "loss: 3.787821  [48010/50000]\n",
      "loss: 3.941353  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 3.938118 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 3.892147  [   10/50000]\n",
      "loss: 3.838787  [ 1010/50000]\n",
      "loss: 3.781300  [ 2010/50000]\n",
      "loss: 3.743056  [ 3010/50000]\n",
      "loss: 4.000186  [ 4010/50000]\n",
      "loss: 3.768409  [ 5010/50000]\n",
      "loss: 3.734453  [ 6010/50000]\n",
      "loss: 3.949494  [ 7010/50000]\n",
      "loss: 3.759029  [ 8010/50000]\n",
      "loss: 3.928464  [ 9010/50000]\n",
      "loss: 3.738541  [10010/50000]\n",
      "loss: 3.988201  [11010/50000]\n",
      "loss: 3.941245  [12010/50000]\n",
      "loss: 3.813706  [13010/50000]\n",
      "loss: 3.768263  [14010/50000]\n",
      "loss: 3.814487  [15010/50000]\n",
      "loss: 3.877525  [16010/50000]\n",
      "loss: 3.745312  [17010/50000]\n",
      "loss: 3.935656  [18010/50000]\n",
      "loss: 3.806421  [19010/50000]\n",
      "loss: 3.772633  [20010/50000]\n",
      "loss: 3.803772  [21010/50000]\n",
      "loss: 3.798888  [22010/50000]\n",
      "loss: 3.917179  [23010/50000]\n",
      "loss: 3.769672  [24010/50000]\n",
      "loss: 3.853270  [25010/50000]\n",
      "loss: 3.939662  [26010/50000]\n",
      "loss: 3.842461  [27010/50000]\n",
      "loss: 3.983396  [28010/50000]\n",
      "loss: 3.800502  [29010/50000]\n",
      "loss: 3.786889  [30010/50000]\n",
      "loss: 3.748451  [31010/50000]\n",
      "loss: 3.810642  [32010/50000]\n",
      "loss: 3.853488  [33010/50000]\n",
      "loss: 3.925169  [34010/50000]\n",
      "loss: 3.826909  [35010/50000]\n",
      "loss: 3.930645  [36010/50000]\n",
      "loss: 3.739768  [37010/50000]\n",
      "loss: 3.903702  [38010/50000]\n",
      "loss: 3.989086  [39010/50000]\n",
      "loss: 3.990549  [40010/50000]\n",
      "loss: 3.848460  [41010/50000]\n",
      "loss: 3.932497  [42010/50000]\n",
      "loss: 3.741530  [43010/50000]\n",
      "loss: 3.844913  [44010/50000]\n",
      "loss: 3.842000  [45010/50000]\n",
      "loss: 3.851697  [46010/50000]\n",
      "loss: 3.732510  [47010/50000]\n",
      "loss: 3.885187  [48010/50000]\n",
      "loss: 3.897748  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 35.9%, Avg loss: 3.941769 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 3.871052  [   10/50000]\n",
      "loss: 3.760165  [ 1010/50000]\n",
      "loss: 3.765508  [ 2010/50000]\n",
      "loss: 3.839145  [ 3010/50000]\n",
      "loss: 3.857877  [ 4010/50000]\n",
      "loss: 3.815130  [ 5010/50000]\n",
      "loss: 3.834589  [ 6010/50000]\n",
      "loss: 3.755998  [ 7010/50000]\n",
      "loss: 3.837890  [ 8010/50000]\n",
      "loss: 3.730553  [ 9010/50000]\n",
      "loss: 3.754131  [10010/50000]\n",
      "loss: 3.731445  [11010/50000]\n",
      "loss: 3.763582  [12010/50000]\n",
      "loss: 3.946170  [13010/50000]\n",
      "loss: 3.739733  [14010/50000]\n",
      "loss: 3.974549  [15010/50000]\n",
      "loss: 3.751288  [16010/50000]\n",
      "loss: 3.913317  [17010/50000]\n",
      "loss: 3.725190  [18010/50000]\n",
      "loss: 3.845996  [19010/50000]\n",
      "loss: 3.899373  [20010/50000]\n",
      "loss: 3.840034  [21010/50000]\n",
      "loss: 3.751277  [22010/50000]\n",
      "loss: 3.738865  [23010/50000]\n",
      "loss: 3.931360  [24010/50000]\n",
      "loss: 3.848109  [25010/50000]\n",
      "loss: 3.850095  [26010/50000]\n",
      "loss: 3.748580  [27010/50000]\n",
      "loss: 3.852748  [28010/50000]\n",
      "loss: 3.802634  [29010/50000]\n",
      "loss: 3.741553  [30010/50000]\n",
      "loss: 3.758792  [31010/50000]\n",
      "loss: 3.807140  [32010/50000]\n",
      "loss: 3.948938  [33010/50000]\n",
      "loss: 3.756960  [34010/50000]\n",
      "loss: 3.846123  [35010/50000]\n",
      "loss: 3.776508  [36010/50000]\n",
      "loss: 3.954493  [37010/50000]\n",
      "loss: 3.850605  [38010/50000]\n",
      "loss: 3.738593  [39010/50000]\n",
      "loss: 3.846879  [40010/50000]\n",
      "loss: 3.744533  [41010/50000]\n",
      "loss: 3.734971  [42010/50000]\n",
      "loss: 3.786487  [43010/50000]\n",
      "loss: 3.867200  [44010/50000]\n",
      "loss: 3.741032  [45010/50000]\n",
      "loss: 3.741840  [46010/50000]\n",
      "loss: 3.763952  [47010/50000]\n",
      "loss: 3.864930  [48010/50000]\n",
      "loss: 3.871902  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 3.935907 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 3.764823  [   10/50000]\n",
      "loss: 3.764948  [ 1010/50000]\n",
      "loss: 3.868767  [ 2010/50000]\n",
      "loss: 3.755249  [ 3010/50000]\n",
      "loss: 3.747690  [ 4010/50000]\n",
      "loss: 3.738722  [ 5010/50000]\n",
      "loss: 3.923395  [ 6010/50000]\n",
      "loss: 3.964593  [ 7010/50000]\n",
      "loss: 3.804441  [ 8010/50000]\n",
      "loss: 3.856011  [ 9010/50000]\n",
      "loss: 3.760881  [10010/50000]\n",
      "loss: 3.722589  [11010/50000]\n",
      "loss: 3.750333  [12010/50000]\n",
      "loss: 3.866323  [13010/50000]\n",
      "loss: 3.744455  [14010/50000]\n",
      "loss: 3.734695  [15010/50000]\n",
      "loss: 3.741765  [16010/50000]\n",
      "loss: 3.938476  [17010/50000]\n",
      "loss: 3.737213  [18010/50000]\n",
      "loss: 3.890988  [19010/50000]\n",
      "loss: 3.751220  [20010/50000]\n",
      "loss: 3.728450  [21010/50000]\n",
      "loss: 3.817464  [22010/50000]\n",
      "loss: 3.934229  [23010/50000]\n",
      "loss: 3.801952  [24010/50000]\n",
      "loss: 3.790501  [25010/50000]\n",
      "loss: 3.740561  [26010/50000]\n",
      "loss: 3.746938  [27010/50000]\n",
      "loss: 3.827929  [28010/50000]\n",
      "loss: 3.937387  [29010/50000]\n",
      "loss: 3.756027  [30010/50000]\n",
      "loss: 3.833028  [31010/50000]\n",
      "loss: 3.731513  [32010/50000]\n",
      "loss: 3.807910  [33010/50000]\n",
      "loss: 3.899332  [34010/50000]\n",
      "loss: 3.791670  [35010/50000]\n",
      "loss: 3.839234  [36010/50000]\n",
      "loss: 3.721976  [37010/50000]\n",
      "loss: 3.733948  [38010/50000]\n",
      "loss: 3.802497  [39010/50000]\n",
      "loss: 3.813208  [40010/50000]\n",
      "loss: 3.898324  [41010/50000]\n",
      "loss: 3.851312  [42010/50000]\n",
      "loss: 3.760718  [43010/50000]\n",
      "loss: 3.936742  [44010/50000]\n",
      "loss: 3.830626  [45010/50000]\n",
      "loss: 3.750043  [46010/50000]\n",
      "loss: 3.752391  [47010/50000]\n",
      "loss: 3.767074  [48010/50000]\n",
      "loss: 3.834979  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.4%, Avg loss: 3.939419 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 3.745203  [   10/50000]\n",
      "loss: 3.733621  [ 1010/50000]\n",
      "loss: 3.807237  [ 2010/50000]\n",
      "loss: 3.823522  [ 3010/50000]\n",
      "loss: 3.791601  [ 4010/50000]\n",
      "loss: 3.720378  [ 5010/50000]\n",
      "loss: 3.801174  [ 6010/50000]\n",
      "loss: 3.822260  [ 7010/50000]\n",
      "loss: 3.843467  [ 8010/50000]\n",
      "loss: 3.740778  [ 9010/50000]\n",
      "loss: 3.822827  [10010/50000]\n",
      "loss: 4.018311  [11010/50000]\n",
      "loss: 3.737069  [12010/50000]\n",
      "loss: 3.769433  [13010/50000]\n",
      "loss: 3.828631  [14010/50000]\n",
      "loss: 3.743119  [15010/50000]\n",
      "loss: 3.824514  [16010/50000]\n",
      "loss: 3.756832  [17010/50000]\n",
      "loss: 3.747623  [18010/50000]\n",
      "loss: 3.890370  [19010/50000]\n",
      "loss: 3.755929  [20010/50000]\n",
      "loss: 3.847164  [21010/50000]\n",
      "loss: 3.800770  [22010/50000]\n",
      "loss: 3.781522  [23010/50000]\n",
      "loss: 3.888311  [24010/50000]\n",
      "loss: 3.765887  [25010/50000]\n",
      "loss: 3.759078  [26010/50000]\n",
      "loss: 3.850984  [27010/50000]\n",
      "loss: 3.815316  [28010/50000]\n",
      "loss: 3.721730  [29010/50000]\n",
      "loss: 3.803576  [30010/50000]\n",
      "loss: 3.741632  [31010/50000]\n",
      "loss: 3.771639  [32010/50000]\n",
      "loss: 3.939792  [33010/50000]\n",
      "loss: 3.822450  [34010/50000]\n",
      "loss: 3.855921  [35010/50000]\n",
      "loss: 3.801949  [36010/50000]\n",
      "loss: 3.992862  [37010/50000]\n",
      "loss: 3.991015  [38010/50000]\n",
      "loss: 3.796984  [39010/50000]\n",
      "loss: 3.769190  [40010/50000]\n",
      "loss: 3.799869  [41010/50000]\n",
      "loss: 3.804502  [42010/50000]\n",
      "loss: 3.801700  [43010/50000]\n",
      "loss: 3.740277  [44010/50000]\n",
      "loss: 3.940453  [45010/50000]\n",
      "loss: 3.798284  [46010/50000]\n",
      "loss: 3.755419  [47010/50000]\n",
      "loss: 3.820096  [48010/50000]\n",
      "loss: 4.006851  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.9%, Avg loss: 3.934722 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 3.772149  [   10/50000]\n",
      "loss: 3.815005  [ 1010/50000]\n",
      "loss: 3.765225  [ 2010/50000]\n",
      "loss: 3.722519  [ 3010/50000]\n",
      "loss: 3.775608  [ 4010/50000]\n",
      "loss: 3.735894  [ 5010/50000]\n",
      "loss: 3.750630  [ 6010/50000]\n",
      "loss: 3.951119  [ 7010/50000]\n",
      "loss: 3.760882  [ 8010/50000]\n",
      "loss: 3.821290  [ 9010/50000]\n",
      "loss: 3.731661  [10010/50000]\n",
      "loss: 3.746263  [11010/50000]\n",
      "loss: 3.747798  [12010/50000]\n",
      "loss: 3.770154  [13010/50000]\n",
      "loss: 3.751701  [14010/50000]\n",
      "loss: 3.943802  [15010/50000]\n",
      "loss: 3.870425  [16010/50000]\n",
      "loss: 3.805275  [17010/50000]\n",
      "loss: 3.755127  [18010/50000]\n",
      "loss: 3.795909  [19010/50000]\n",
      "loss: 3.996723  [20010/50000]\n",
      "loss: 3.741704  [21010/50000]\n",
      "loss: 3.923518  [22010/50000]\n",
      "loss: 3.850413  [23010/50000]\n",
      "loss: 3.716187  [24010/50000]\n",
      "loss: 3.823229  [25010/50000]\n",
      "loss: 3.756958  [26010/50000]\n",
      "loss: 3.726806  [27010/50000]\n",
      "loss: 3.913374  [28010/50000]\n",
      "loss: 3.822864  [29010/50000]\n",
      "loss: 3.828319  [30010/50000]\n",
      "loss: 3.809895  [31010/50000]\n",
      "loss: 3.739525  [32010/50000]\n",
      "loss: 3.768677  [33010/50000]\n",
      "loss: 3.809640  [34010/50000]\n",
      "loss: 3.856885  [35010/50000]\n",
      "loss: 3.789272  [36010/50000]\n",
      "loss: 3.793763  [37010/50000]\n",
      "loss: 3.740092  [38010/50000]\n",
      "loss: 4.114464  [39010/50000]\n",
      "loss: 3.824504  [40010/50000]\n",
      "loss: 3.723665  [41010/50000]\n",
      "loss: 3.799449  [42010/50000]\n",
      "loss: 3.759097  [43010/50000]\n",
      "loss: 3.747739  [44010/50000]\n",
      "loss: 3.810326  [45010/50000]\n",
      "loss: 3.737801  [46010/50000]\n",
      "loss: 3.834575  [47010/50000]\n",
      "loss: 3.805795  [48010/50000]\n",
      "loss: 3.868579  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.8%, Avg loss: 3.937790 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 3.775702  [   10/50000]\n",
      "loss: 3.784606  [ 1010/50000]\n",
      "loss: 3.885526  [ 2010/50000]\n",
      "loss: 3.768984  [ 3010/50000]\n",
      "loss: 3.735278  [ 4010/50000]\n",
      "loss: 3.875607  [ 5010/50000]\n",
      "loss: 3.793590  [ 6010/50000]\n",
      "loss: 3.786135  [ 7010/50000]\n",
      "loss: 3.887676  [ 8010/50000]\n",
      "loss: 3.756115  [ 9010/50000]\n",
      "loss: 3.782585  [10010/50000]\n",
      "loss: 3.745269  [11010/50000]\n",
      "loss: 3.768518  [12010/50000]\n",
      "loss: 3.732744  [13010/50000]\n",
      "loss: 3.933034  [14010/50000]\n",
      "loss: 3.864205  [15010/50000]\n",
      "loss: 3.845908  [16010/50000]\n",
      "loss: 3.724401  [17010/50000]\n",
      "loss: 3.740071  [18010/50000]\n",
      "loss: 3.771360  [19010/50000]\n",
      "loss: 3.758631  [20010/50000]\n",
      "loss: 3.781100  [21010/50000]\n",
      "loss: 3.891984  [22010/50000]\n",
      "loss: 3.773333  [23010/50000]\n",
      "loss: 3.793881  [24010/50000]\n",
      "loss: 3.917323  [25010/50000]\n",
      "loss: 3.767333  [26010/50000]\n",
      "loss: 3.789087  [27010/50000]\n",
      "loss: 3.824455  [28010/50000]\n",
      "loss: 3.747926  [29010/50000]\n",
      "loss: 3.752297  [30010/50000]\n",
      "loss: 3.836330  [31010/50000]\n",
      "loss: 3.799927  [32010/50000]\n",
      "loss: 3.829521  [33010/50000]\n",
      "loss: 3.966019  [34010/50000]\n",
      "loss: 3.716315  [35010/50000]\n",
      "loss: 3.784324  [36010/50000]\n",
      "loss: 3.877972  [37010/50000]\n",
      "loss: 3.731000  [38010/50000]\n",
      "loss: 3.847928  [39010/50000]\n",
      "loss: 3.751958  [40010/50000]\n",
      "loss: 3.825906  [41010/50000]\n",
      "loss: 3.733573  [42010/50000]\n",
      "loss: 3.994503  [43010/50000]\n",
      "loss: 3.845051  [44010/50000]\n",
      "loss: 3.798752  [45010/50000]\n",
      "loss: 3.769608  [46010/50000]\n",
      "loss: 3.808211  [47010/50000]\n",
      "loss: 3.744322  [48010/50000]\n",
      "loss: 3.745208  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.9%, Avg loss: 3.940008 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 3.738480  [   10/50000]\n",
      "loss: 3.734983  [ 1010/50000]\n",
      "loss: 3.753999  [ 2010/50000]\n",
      "loss: 3.776807  [ 3010/50000]\n",
      "loss: 3.765942  [ 4010/50000]\n",
      "loss: 3.821759  [ 5010/50000]\n",
      "loss: 3.841099  [ 6010/50000]\n",
      "loss: 3.775414  [ 7010/50000]\n",
      "loss: 3.736748  [ 8010/50000]\n",
      "loss: 3.881273  [ 9010/50000]\n",
      "loss: 3.748177  [10010/50000]\n",
      "loss: 3.731313  [11010/50000]\n",
      "loss: 3.744327  [12010/50000]\n",
      "loss: 3.802795  [13010/50000]\n",
      "loss: 3.826932  [14010/50000]\n",
      "loss: 3.785741  [15010/50000]\n",
      "loss: 3.764299  [16010/50000]\n",
      "loss: 3.740931  [17010/50000]\n",
      "loss: 3.803718  [18010/50000]\n",
      "loss: 3.767653  [19010/50000]\n",
      "loss: 3.762302  [20010/50000]\n",
      "loss: 3.727605  [21010/50000]\n",
      "loss: 3.795094  [22010/50000]\n",
      "loss: 3.817452  [23010/50000]\n",
      "loss: 3.891804  [24010/50000]\n",
      "loss: 3.844614  [25010/50000]\n",
      "loss: 3.792133  [26010/50000]\n",
      "loss: 3.920874  [27010/50000]\n",
      "loss: 3.888039  [28010/50000]\n",
      "loss: 3.834653  [29010/50000]\n",
      "loss: 3.784525  [30010/50000]\n",
      "loss: 3.807430  [31010/50000]\n",
      "loss: 3.786935  [32010/50000]\n",
      "loss: 3.765451  [33010/50000]\n",
      "loss: 3.846732  [34010/50000]\n",
      "loss: 3.752534  [35010/50000]\n",
      "loss: 3.760883  [36010/50000]\n",
      "loss: 3.830235  [37010/50000]\n",
      "loss: 3.769910  [38010/50000]\n",
      "loss: 3.878520  [39010/50000]\n",
      "loss: 3.745142  [40010/50000]\n",
      "loss: 3.822678  [41010/50000]\n",
      "loss: 3.842769  [42010/50000]\n",
      "loss: 3.854598  [43010/50000]\n",
      "loss: 3.741950  [44010/50000]\n",
      "loss: 3.727593  [45010/50000]\n",
      "loss: 3.758415  [46010/50000]\n",
      "loss: 3.806802  [47010/50000]\n",
      "loss: 3.779536  [48010/50000]\n",
      "loss: 4.000586  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 3.936593 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 3.725833  [   10/50000]\n",
      "loss: 3.820358  [ 1010/50000]\n",
      "loss: 3.745409  [ 2010/50000]\n",
      "loss: 3.770741  [ 3010/50000]\n",
      "loss: 3.728494  [ 4010/50000]\n",
      "loss: 3.755825  [ 5010/50000]\n",
      "loss: 4.012475  [ 6010/50000]\n",
      "loss: 3.811274  [ 7010/50000]\n",
      "loss: 3.770740  [ 8010/50000]\n",
      "loss: 3.739505  [ 9010/50000]\n",
      "loss: 3.750714  [10010/50000]\n",
      "loss: 3.877818  [11010/50000]\n",
      "loss: 3.771358  [12010/50000]\n",
      "loss: 3.745506  [13010/50000]\n",
      "loss: 3.724396  [14010/50000]\n",
      "loss: 3.761834  [15010/50000]\n",
      "loss: 3.903012  [16010/50000]\n",
      "loss: 3.754891  [17010/50000]\n",
      "loss: 3.740708  [18010/50000]\n",
      "loss: 3.738841  [19010/50000]\n",
      "loss: 3.742174  [20010/50000]\n",
      "loss: 3.732013  [21010/50000]\n",
      "loss: 3.724711  [22010/50000]\n",
      "loss: 3.834436  [23010/50000]\n",
      "loss: 3.919085  [24010/50000]\n",
      "loss: 3.722603  [25010/50000]\n",
      "loss: 3.798968  [26010/50000]\n",
      "loss: 3.719907  [27010/50000]\n",
      "loss: 3.732800  [28010/50000]\n",
      "loss: 3.726570  [29010/50000]\n",
      "loss: 3.764232  [30010/50000]\n",
      "loss: 3.722320  [31010/50000]\n",
      "loss: 3.738504  [32010/50000]\n",
      "loss: 3.778460  [33010/50000]\n",
      "loss: 3.723112  [34010/50000]\n",
      "loss: 3.808597  [35010/50000]\n",
      "loss: 3.955136  [36010/50000]\n",
      "loss: 3.743343  [37010/50000]\n",
      "loss: 3.854972  [38010/50000]\n",
      "loss: 3.855784  [39010/50000]\n",
      "loss: 3.759697  [40010/50000]\n",
      "loss: 3.864091  [41010/50000]\n",
      "loss: 3.958812  [42010/50000]\n",
      "loss: 3.730836  [43010/50000]\n",
      "loss: 3.776669  [44010/50000]\n",
      "loss: 3.990279  [45010/50000]\n",
      "loss: 3.771319  [46010/50000]\n",
      "loss: 3.950093  [47010/50000]\n",
      "loss: 3.715723  [48010/50000]\n",
      "loss: 3.736197  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 3.942993 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 3.760010  [   10/50000]\n",
      "loss: 3.821936  [ 1010/50000]\n",
      "loss: 3.805341  [ 2010/50000]\n",
      "loss: 3.761985  [ 3010/50000]\n",
      "loss: 3.786689  [ 4010/50000]\n",
      "loss: 3.724330  [ 5010/50000]\n",
      "loss: 3.835569  [ 6010/50000]\n",
      "loss: 3.772197  [ 7010/50000]\n",
      "loss: 3.776981  [ 8010/50000]\n",
      "loss: 3.837533  [ 9010/50000]\n",
      "loss: 3.847470  [10010/50000]\n",
      "loss: 3.741265  [11010/50000]\n",
      "loss: 3.816468  [12010/50000]\n",
      "loss: 3.755507  [13010/50000]\n",
      "loss: 3.828674  [14010/50000]\n",
      "loss: 3.731661  [15010/50000]\n",
      "loss: 3.717612  [16010/50000]\n",
      "loss: 3.739717  [17010/50000]\n",
      "loss: 3.767007  [18010/50000]\n",
      "loss: 3.743476  [19010/50000]\n",
      "loss: 3.860106  [20010/50000]\n",
      "loss: 3.877078  [21010/50000]\n",
      "loss: 3.866076  [22010/50000]\n",
      "loss: 3.890136  [23010/50000]\n",
      "loss: 3.961283  [24010/50000]\n",
      "loss: 3.728978  [25010/50000]\n",
      "loss: 3.885025  [26010/50000]\n",
      "loss: 3.789438  [27010/50000]\n",
      "loss: 3.939153  [28010/50000]\n",
      "loss: 3.734299  [29010/50000]\n",
      "loss: 3.796005  [30010/50000]\n",
      "loss: 3.863166  [31010/50000]\n",
      "loss: 3.742651  [32010/50000]\n",
      "loss: 3.800960  [33010/50000]\n",
      "loss: 3.728405  [34010/50000]\n",
      "loss: 3.741147  [35010/50000]\n",
      "loss: 3.798784  [36010/50000]\n",
      "loss: 3.789287  [37010/50000]\n",
      "loss: 3.765892  [38010/50000]\n",
      "loss: 3.816020  [39010/50000]\n",
      "loss: 3.948104  [40010/50000]\n",
      "loss: 3.778953  [41010/50000]\n",
      "loss: 3.744314  [42010/50000]\n",
      "loss: 3.720098  [43010/50000]\n",
      "loss: 3.759642  [44010/50000]\n",
      "loss: 3.732869  [45010/50000]\n",
      "loss: 3.756252  [46010/50000]\n",
      "loss: 3.834474  [47010/50000]\n",
      "loss: 3.847374  [48010/50000]\n",
      "loss: 3.728835  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 3.934972 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 3.832793  [   10/50000]\n",
      "loss: 3.749752  [ 1010/50000]\n",
      "loss: 3.738298  [ 2010/50000]\n",
      "loss: 3.847298  [ 3010/50000]\n",
      "loss: 3.725165  [ 4010/50000]\n",
      "loss: 3.841109  [ 5010/50000]\n",
      "loss: 3.802416  [ 6010/50000]\n",
      "loss: 3.748791  [ 7010/50000]\n",
      "loss: 3.807890  [ 8010/50000]\n",
      "loss: 3.746532  [ 9010/50000]\n",
      "loss: 3.762813  [10010/50000]\n",
      "loss: 3.902248  [11010/50000]\n",
      "loss: 3.834019  [12010/50000]\n",
      "loss: 3.895816  [13010/50000]\n",
      "loss: 3.834231  [14010/50000]\n",
      "loss: 3.894677  [15010/50000]\n",
      "loss: 3.809905  [16010/50000]\n",
      "loss: 3.812109  [17010/50000]\n",
      "loss: 3.756261  [18010/50000]\n",
      "loss: 3.850115  [19010/50000]\n",
      "loss: 3.803754  [20010/50000]\n",
      "loss: 3.742790  [21010/50000]\n",
      "loss: 3.830956  [22010/50000]\n",
      "loss: 3.841020  [23010/50000]\n",
      "loss: 3.713785  [24010/50000]\n",
      "loss: 3.735294  [25010/50000]\n",
      "loss: 3.809472  [26010/50000]\n",
      "loss: 3.856460  [27010/50000]\n",
      "loss: 3.742628  [28010/50000]\n",
      "loss: 3.734407  [29010/50000]\n",
      "loss: 3.767038  [30010/50000]\n",
      "loss: 3.809000  [31010/50000]\n",
      "loss: 3.729674  [32010/50000]\n",
      "loss: 3.902544  [33010/50000]\n",
      "loss: 3.909909  [34010/50000]\n",
      "loss: 3.716634  [35010/50000]\n",
      "loss: 3.787224  [36010/50000]\n",
      "loss: 3.819333  [37010/50000]\n",
      "loss: 3.824396  [38010/50000]\n",
      "loss: 3.753160  [39010/50000]\n",
      "loss: 3.791543  [40010/50000]\n",
      "loss: 3.736124  [41010/50000]\n",
      "loss: 3.731405  [42010/50000]\n",
      "loss: 3.740889  [43010/50000]\n",
      "loss: 4.031567  [44010/50000]\n",
      "loss: 3.779320  [45010/50000]\n",
      "loss: 3.805817  [46010/50000]\n",
      "loss: 3.882339  [47010/50000]\n",
      "loss: 3.802289  [48010/50000]\n",
      "loss: 3.716851  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 3.941373 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 3.876263  [   10/50000]\n",
      "loss: 3.717128  [ 1010/50000]\n",
      "loss: 3.714412  [ 2010/50000]\n",
      "loss: 3.815344  [ 3010/50000]\n",
      "loss: 3.811874  [ 4010/50000]\n",
      "loss: 3.706883  [ 5010/50000]\n",
      "loss: 3.812466  [ 6010/50000]\n",
      "loss: 3.814754  [ 7010/50000]\n",
      "loss: 3.817038  [ 8010/50000]\n",
      "loss: 3.725251  [ 9010/50000]\n",
      "loss: 3.704840  [10010/50000]\n",
      "loss: 3.737990  [11010/50000]\n",
      "loss: 3.838781  [12010/50000]\n",
      "loss: 3.849864  [13010/50000]\n",
      "loss: 3.724651  [14010/50000]\n",
      "loss: 3.740206  [15010/50000]\n",
      "loss: 3.844972  [16010/50000]\n",
      "loss: 3.807867  [17010/50000]\n",
      "loss: 3.828333  [18010/50000]\n",
      "loss: 3.705513  [19010/50000]\n",
      "loss: 3.764439  [20010/50000]\n",
      "loss: 3.719931  [21010/50000]\n",
      "loss: 3.709346  [22010/50000]\n",
      "loss: 3.744046  [23010/50000]\n",
      "loss: 3.733804  [24010/50000]\n",
      "loss: 3.763759  [25010/50000]\n",
      "loss: 3.779765  [26010/50000]\n",
      "loss: 3.710620  [27010/50000]\n",
      "loss: 3.750170  [28010/50000]\n",
      "loss: 3.769439  [29010/50000]\n",
      "loss: 3.722345  [30010/50000]\n",
      "loss: 3.907780  [31010/50000]\n",
      "loss: 3.773363  [32010/50000]\n",
      "loss: 3.731358  [33010/50000]\n",
      "loss: 3.727895  [34010/50000]\n",
      "loss: 3.748748  [35010/50000]\n",
      "loss: 3.737338  [36010/50000]\n",
      "loss: 3.779231  [37010/50000]\n",
      "loss: 3.820520  [38010/50000]\n",
      "loss: 3.722296  [39010/50000]\n",
      "loss: 3.716293  [40010/50000]\n",
      "loss: 3.840371  [41010/50000]\n",
      "loss: 3.807594  [42010/50000]\n",
      "loss: 3.722024  [43010/50000]\n",
      "loss: 3.739662  [44010/50000]\n",
      "loss: 3.726081  [45010/50000]\n",
      "loss: 3.820618  [46010/50000]\n",
      "loss: 3.716309  [47010/50000]\n",
      "loss: 3.708783  [48010/50000]\n",
      "loss: 3.765078  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 3.934848 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 3.726361  [   10/50000]\n",
      "loss: 3.846638  [ 1010/50000]\n",
      "loss: 3.726758  [ 2010/50000]\n",
      "loss: 3.706696  [ 3010/50000]\n",
      "loss: 3.825117  [ 4010/50000]\n",
      "loss: 3.779048  [ 5010/50000]\n",
      "loss: 3.914572  [ 6010/50000]\n",
      "loss: 3.722062  [ 7010/50000]\n",
      "loss: 3.921575  [ 8010/50000]\n",
      "loss: 3.861912  [ 9010/50000]\n",
      "loss: 3.816559  [10010/50000]\n",
      "loss: 3.734838  [11010/50000]\n",
      "loss: 3.722925  [12010/50000]\n",
      "loss: 3.733507  [13010/50000]\n",
      "loss: 3.801529  [14010/50000]\n",
      "loss: 3.839569  [15010/50000]\n",
      "loss: 3.719613  [16010/50000]\n",
      "loss: 3.779398  [17010/50000]\n",
      "loss: 3.912765  [18010/50000]\n",
      "loss: 3.718551  [19010/50000]\n",
      "loss: 3.777213  [20010/50000]\n",
      "loss: 3.818946  [21010/50000]\n",
      "loss: 3.726189  [22010/50000]\n",
      "loss: 3.943124  [23010/50000]\n",
      "loss: 3.871145  [24010/50000]\n",
      "loss: 3.830564  [25010/50000]\n",
      "loss: 3.721063  [26010/50000]\n",
      "loss: 3.917740  [27010/50000]\n",
      "loss: 3.831830  [28010/50000]\n",
      "loss: 3.867499  [29010/50000]\n",
      "loss: 3.798836  [30010/50000]\n",
      "loss: 3.840909  [31010/50000]\n",
      "loss: 3.786799  [32010/50000]\n",
      "loss: 3.711835  [33010/50000]\n",
      "loss: 3.721680  [34010/50000]\n",
      "loss: 3.814448  [35010/50000]\n",
      "loss: 3.728225  [36010/50000]\n",
      "loss: 3.811196  [37010/50000]\n",
      "loss: 3.722855  [38010/50000]\n",
      "loss: 3.723396  [39010/50000]\n",
      "loss: 3.714109  [40010/50000]\n",
      "loss: 3.756710  [41010/50000]\n",
      "loss: 3.771551  [42010/50000]\n",
      "loss: 3.721969  [43010/50000]\n",
      "loss: 3.781738  [44010/50000]\n",
      "loss: 3.738843  [45010/50000]\n",
      "loss: 3.729688  [46010/50000]\n",
      "loss: 3.722172  [47010/50000]\n",
      "loss: 3.701940  [48010/50000]\n",
      "loss: 3.892218  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 3.942838 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 3.756154  [   10/50000]\n",
      "loss: 3.715419  [ 1010/50000]\n",
      "loss: 3.813104  [ 2010/50000]\n",
      "loss: 3.833141  [ 3010/50000]\n",
      "loss: 3.774189  [ 4010/50000]\n",
      "loss: 3.724528  [ 5010/50000]\n",
      "loss: 3.710937  [ 6010/50000]\n",
      "loss: 3.715955  [ 7010/50000]\n",
      "loss: 3.728451  [ 8010/50000]\n",
      "loss: 3.749388  [ 9010/50000]\n",
      "loss: 3.712142  [10010/50000]\n",
      "loss: 3.698095  [11010/50000]\n",
      "loss: 3.727325  [12010/50000]\n",
      "loss: 3.727335  [13010/50000]\n",
      "loss: 3.767921  [14010/50000]\n",
      "loss: 3.976041  [15010/50000]\n",
      "loss: 3.726903  [16010/50000]\n",
      "loss: 3.733403  [17010/50000]\n",
      "loss: 3.698776  [18010/50000]\n",
      "loss: 3.982821  [19010/50000]\n",
      "loss: 3.725681  [20010/50000]\n",
      "loss: 3.874872  [21010/50000]\n",
      "loss: 3.746189  [22010/50000]\n",
      "loss: 3.778306  [23010/50000]\n",
      "loss: 3.780826  [24010/50000]\n",
      "loss: 3.985865  [25010/50000]\n",
      "loss: 3.728394  [26010/50000]\n",
      "loss: 3.726618  [27010/50000]\n",
      "loss: 3.823902  [28010/50000]\n",
      "loss: 3.980506  [29010/50000]\n",
      "loss: 3.771140  [30010/50000]\n",
      "loss: 3.786563  [31010/50000]\n",
      "loss: 3.759140  [32010/50000]\n",
      "loss: 3.830208  [33010/50000]\n",
      "loss: 3.822512  [34010/50000]\n",
      "loss: 3.778684  [35010/50000]\n",
      "loss: 3.716978  [36010/50000]\n",
      "loss: 3.764458  [37010/50000]\n",
      "loss: 3.739792  [38010/50000]\n",
      "loss: 3.835915  [39010/50000]\n",
      "loss: 3.907410  [40010/50000]\n",
      "loss: 3.847989  [41010/50000]\n",
      "loss: 3.766205  [42010/50000]\n",
      "loss: 3.787964  [43010/50000]\n",
      "loss: 3.833313  [44010/50000]\n",
      "loss: 3.890347  [45010/50000]\n",
      "loss: 3.833779  [46010/50000]\n",
      "loss: 3.748086  [47010/50000]\n",
      "loss: 3.799644  [48010/50000]\n",
      "loss: 3.715148  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.6%, Avg loss: 3.944942 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 3.906702  [   10/50000]\n",
      "loss: 3.820231  [ 1010/50000]\n",
      "loss: 3.783695  [ 2010/50000]\n",
      "loss: 3.740897  [ 3010/50000]\n",
      "loss: 3.817155  [ 4010/50000]\n",
      "loss: 3.811567  [ 5010/50000]\n",
      "loss: 3.727425  [ 6010/50000]\n",
      "loss: 3.803442  [ 7010/50000]\n",
      "loss: 3.764704  [ 8010/50000]\n",
      "loss: 3.828672  [ 9010/50000]\n",
      "loss: 3.711472  [10010/50000]\n",
      "loss: 3.916503  [11010/50000]\n",
      "loss: 3.730846  [12010/50000]\n",
      "loss: 3.809757  [13010/50000]\n",
      "loss: 3.736439  [14010/50000]\n",
      "loss: 3.767108  [15010/50000]\n",
      "loss: 3.791497  [16010/50000]\n",
      "loss: 3.932571  [17010/50000]\n",
      "loss: 3.739384  [18010/50000]\n",
      "loss: 3.851524  [19010/50000]\n",
      "loss: 3.709664  [20010/50000]\n",
      "loss: 3.825078  [21010/50000]\n",
      "loss: 3.725404  [22010/50000]\n",
      "loss: 3.708713  [23010/50000]\n",
      "loss: 3.798995  [24010/50000]\n",
      "loss: 3.791873  [25010/50000]\n",
      "loss: 3.901817  [26010/50000]\n",
      "loss: 3.750737  [27010/50000]\n",
      "loss: 3.741517  [28010/50000]\n",
      "loss: 3.762681  [29010/50000]\n",
      "loss: 3.715542  [30010/50000]\n",
      "loss: 3.717259  [31010/50000]\n",
      "loss: 3.727835  [32010/50000]\n",
      "loss: 3.753370  [33010/50000]\n",
      "loss: 3.721166  [34010/50000]\n",
      "loss: 3.825324  [35010/50000]\n",
      "loss: 3.761630  [36010/50000]\n",
      "loss: 3.804974  [37010/50000]\n",
      "loss: 3.740427  [38010/50000]\n",
      "loss: 3.714560  [39010/50000]\n",
      "loss: 3.812690  [40010/50000]\n",
      "loss: 3.816608  [41010/50000]\n",
      "loss: 3.711753  [42010/50000]\n",
      "loss: 3.731468  [43010/50000]\n",
      "loss: 3.714432  [44010/50000]\n",
      "loss: 3.724920  [45010/50000]\n",
      "loss: 3.719282  [46010/50000]\n",
      "loss: 3.768741  [47010/50000]\n",
      "loss: 3.799558  [48010/50000]\n",
      "loss: 3.804278  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.4%, Avg loss: 3.949323 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 3.808469  [   10/50000]\n",
      "loss: 3.737815  [ 1010/50000]\n",
      "loss: 3.751040  [ 2010/50000]\n",
      "loss: 3.721246  [ 3010/50000]\n",
      "loss: 3.754208  [ 4010/50000]\n",
      "loss: 3.734185  [ 5010/50000]\n",
      "loss: 3.815907  [ 6010/50000]\n",
      "loss: 3.737443  [ 7010/50000]\n",
      "loss: 3.714860  [ 8010/50000]\n",
      "loss: 3.904853  [ 9010/50000]\n",
      "loss: 3.798989  [10010/50000]\n",
      "loss: 3.747184  [11010/50000]\n",
      "loss: 3.814229  [12010/50000]\n",
      "loss: 3.852379  [13010/50000]\n",
      "loss: 3.850871  [14010/50000]\n",
      "loss: 3.699395  [15010/50000]\n",
      "loss: 3.845751  [16010/50000]\n",
      "loss: 3.690232  [17010/50000]\n",
      "loss: 3.749969  [18010/50000]\n",
      "loss: 3.732275  [19010/50000]\n",
      "loss: 3.807995  [20010/50000]\n",
      "loss: 3.766312  [21010/50000]\n",
      "loss: 3.741611  [22010/50000]\n",
      "loss: 3.863452  [23010/50000]\n",
      "loss: 3.715677  [24010/50000]\n",
      "loss: 3.759391  [25010/50000]\n",
      "loss: 3.733699  [26010/50000]\n",
      "loss: 3.836310  [27010/50000]\n",
      "loss: 3.724370  [28010/50000]\n",
      "loss: 3.728873  [29010/50000]\n",
      "loss: 3.845120  [30010/50000]\n",
      "loss: 3.732519  [31010/50000]\n",
      "loss: 3.719435  [32010/50000]\n",
      "loss: 3.693882  [33010/50000]\n",
      "loss: 3.752313  [34010/50000]\n",
      "loss: 3.882890  [35010/50000]\n",
      "loss: 3.734308  [36010/50000]\n",
      "loss: 3.726829  [37010/50000]\n",
      "loss: 3.800664  [38010/50000]\n",
      "loss: 3.802370  [39010/50000]\n",
      "loss: 3.693480  [40010/50000]\n",
      "loss: 3.759406  [41010/50000]\n",
      "loss: 3.846307  [42010/50000]\n",
      "loss: 3.702983  [43010/50000]\n",
      "loss: 3.723450  [44010/50000]\n",
      "loss: 3.787888  [45010/50000]\n",
      "loss: 3.728634  [46010/50000]\n",
      "loss: 3.764806  [47010/50000]\n",
      "loss: 3.793169  [48010/50000]\n",
      "loss: 3.731683  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.3%, Avg loss: 3.943956 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 3.803405  [   10/50000]\n",
      "loss: 3.766642  [ 1010/50000]\n",
      "loss: 3.725991  [ 2010/50000]\n",
      "loss: 3.793835  [ 3010/50000]\n",
      "loss: 3.802847  [ 4010/50000]\n",
      "loss: 3.713089  [ 5010/50000]\n",
      "loss: 3.894202  [ 6010/50000]\n",
      "loss: 3.750266  [ 7010/50000]\n",
      "loss: 3.719353  [ 8010/50000]\n",
      "loss: 3.709399  [ 9010/50000]\n",
      "loss: 3.734189  [10010/50000]\n",
      "loss: 3.684312  [11010/50000]\n",
      "loss: 3.708937  [12010/50000]\n",
      "loss: 3.831014  [13010/50000]\n",
      "loss: 3.841489  [14010/50000]\n",
      "loss: 3.728535  [15010/50000]\n",
      "loss: 3.816882  [16010/50000]\n",
      "loss: 3.902945  [17010/50000]\n",
      "loss: 3.707659  [18010/50000]\n",
      "loss: 3.690320  [19010/50000]\n",
      "loss: 3.706192  [20010/50000]\n",
      "loss: 3.915750  [21010/50000]\n",
      "loss: 3.787292  [22010/50000]\n",
      "loss: 3.823490  [23010/50000]\n",
      "loss: 3.770831  [24010/50000]\n",
      "loss: 3.730925  [25010/50000]\n",
      "loss: 3.796129  [26010/50000]\n",
      "loss: 3.749617  [27010/50000]\n",
      "loss: 3.806166  [28010/50000]\n",
      "loss: 3.745792  [29010/50000]\n",
      "loss: 3.764375  [30010/50000]\n",
      "loss: 3.757760  [31010/50000]\n",
      "loss: 3.749324  [32010/50000]\n",
      "loss: 3.715270  [33010/50000]\n",
      "loss: 3.702185  [34010/50000]\n",
      "loss: 3.788686  [35010/50000]\n",
      "loss: 3.879875  [36010/50000]\n",
      "loss: 3.711134  [37010/50000]\n",
      "loss: 3.807798  [38010/50000]\n",
      "loss: 3.775883  [39010/50000]\n",
      "loss: 3.822541  [40010/50000]\n",
      "loss: 3.834347  [41010/50000]\n",
      "loss: 3.811866  [42010/50000]\n",
      "loss: 3.869843  [43010/50000]\n",
      "loss: 3.698982  [44010/50000]\n",
      "loss: 3.919418  [45010/50000]\n",
      "loss: 3.733189  [46010/50000]\n",
      "loss: 3.793013  [47010/50000]\n",
      "loss: 3.798967  [48010/50000]\n",
      "loss: 3.728571  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 3.947940 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 3.703145  [   10/50000]\n",
      "loss: 3.787389  [ 1010/50000]\n",
      "loss: 3.720943  [ 2010/50000]\n",
      "loss: 3.873613  [ 3010/50000]\n",
      "loss: 3.719004  [ 4010/50000]\n",
      "loss: 3.801071  [ 5010/50000]\n",
      "loss: 3.750631  [ 6010/50000]\n",
      "loss: 3.706350  [ 7010/50000]\n",
      "loss: 3.819775  [ 8010/50000]\n",
      "loss: 3.727069  [ 9010/50000]\n",
      "loss: 3.694279  [10010/50000]\n",
      "loss: 3.764559  [11010/50000]\n",
      "loss: 3.738304  [12010/50000]\n",
      "loss: 3.720382  [13010/50000]\n",
      "loss: 3.815609  [14010/50000]\n",
      "loss: 3.807831  [15010/50000]\n",
      "loss: 3.816408  [16010/50000]\n",
      "loss: 3.720284  [17010/50000]\n",
      "loss: 3.698385  [18010/50000]\n",
      "loss: 3.856038  [19010/50000]\n",
      "loss: 3.790664  [20010/50000]\n",
      "loss: 3.730975  [21010/50000]\n",
      "loss: 3.753936  [22010/50000]\n",
      "loss: 3.910693  [23010/50000]\n",
      "loss: 3.704210  [24010/50000]\n",
      "loss: 3.820910  [25010/50000]\n",
      "loss: 3.723701  [26010/50000]\n",
      "loss: 3.750282  [27010/50000]\n",
      "loss: 3.780991  [28010/50000]\n",
      "loss: 3.718611  [29010/50000]\n",
      "loss: 3.801434  [30010/50000]\n",
      "loss: 3.754105  [31010/50000]\n",
      "loss: 3.719739  [32010/50000]\n",
      "loss: 3.713771  [33010/50000]\n",
      "loss: 3.702686  [34010/50000]\n",
      "loss: 3.745022  [35010/50000]\n",
      "loss: 3.906808  [36010/50000]\n",
      "loss: 3.708506  [37010/50000]\n",
      "loss: 3.734381  [38010/50000]\n",
      "loss: 3.711735  [39010/50000]\n",
      "loss: 3.704236  [40010/50000]\n",
      "loss: 3.834179  [41010/50000]\n",
      "loss: 3.751518  [42010/50000]\n",
      "loss: 3.733014  [43010/50000]\n",
      "loss: 3.710119  [44010/50000]\n",
      "loss: 3.735915  [45010/50000]\n",
      "loss: 3.775503  [46010/50000]\n",
      "loss: 3.781621  [47010/50000]\n",
      "loss: 3.837765  [48010/50000]\n",
      "loss: 3.699480  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 3.956351 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 3.719262  [   10/50000]\n",
      "loss: 3.716921  [ 1010/50000]\n",
      "loss: 3.815176  [ 2010/50000]\n",
      "loss: 3.800973  [ 3010/50000]\n",
      "loss: 3.689644  [ 4010/50000]\n",
      "loss: 3.790249  [ 5010/50000]\n",
      "loss: 3.874479  [ 6010/50000]\n",
      "loss: 3.709835  [ 7010/50000]\n",
      "loss: 3.819951  [ 8010/50000]\n",
      "loss: 3.705287  [ 9010/50000]\n",
      "loss: 3.722842  [10010/50000]\n",
      "loss: 3.773848  [11010/50000]\n",
      "loss: 3.813650  [12010/50000]\n",
      "loss: 3.730033  [13010/50000]\n",
      "loss: 3.716960  [14010/50000]\n",
      "loss: 3.762061  [15010/50000]\n",
      "loss: 3.739954  [16010/50000]\n",
      "loss: 3.713875  [17010/50000]\n",
      "loss: 3.702921  [18010/50000]\n",
      "loss: 3.720976  [19010/50000]\n",
      "loss: 3.720292  [20010/50000]\n",
      "loss: 3.739728  [21010/50000]\n",
      "loss: 3.837917  [22010/50000]\n",
      "loss: 3.866067  [23010/50000]\n",
      "loss: 3.780770  [24010/50000]\n",
      "loss: 3.807435  [25010/50000]\n",
      "loss: 3.805287  [26010/50000]\n",
      "loss: 3.700848  [27010/50000]\n",
      "loss: 3.770211  [28010/50000]\n",
      "loss: 3.829296  [29010/50000]\n",
      "loss: 3.699870  [30010/50000]\n",
      "loss: 3.709534  [31010/50000]\n",
      "loss: 3.729127  [32010/50000]\n",
      "loss: 3.790414  [33010/50000]\n",
      "loss: 3.710998  [34010/50000]\n",
      "loss: 3.724155  [35010/50000]\n",
      "loss: 3.702523  [36010/50000]\n",
      "loss: 3.731688  [37010/50000]\n",
      "loss: 3.898221  [38010/50000]\n",
      "loss: 3.813422  [39010/50000]\n",
      "loss: 3.869528  [40010/50000]\n",
      "loss: 3.723781  [41010/50000]\n",
      "loss: 3.828600  [42010/50000]\n",
      "loss: 3.716304  [43010/50000]\n",
      "loss: 3.963528  [44010/50000]\n",
      "loss: 3.794922  [45010/50000]\n",
      "loss: 3.701904  [46010/50000]\n",
      "loss: 3.723166  [47010/50000]\n",
      "loss: 3.725898  [48010/50000]\n",
      "loss: 3.705824  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.4%, Avg loss: 3.945008 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 3.747329  [   10/50000]\n",
      "loss: 3.700454  [ 1010/50000]\n",
      "loss: 3.793084  [ 2010/50000]\n",
      "loss: 3.721533  [ 3010/50000]\n",
      "loss: 3.721179  [ 4010/50000]\n",
      "loss: 3.732356  [ 5010/50000]\n",
      "loss: 3.747246  [ 6010/50000]\n",
      "loss: 3.714378  [ 7010/50000]\n",
      "loss: 3.898372  [ 8010/50000]\n",
      "loss: 3.835332  [ 9010/50000]\n",
      "loss: 3.710852  [10010/50000]\n",
      "loss: 3.815245  [11010/50000]\n",
      "loss: 3.840715  [12010/50000]\n",
      "loss: 3.693422  [13010/50000]\n",
      "loss: 3.808799  [14010/50000]\n",
      "loss: 3.787966  [15010/50000]\n",
      "loss: 3.759024  [16010/50000]\n",
      "loss: 3.816599  [17010/50000]\n",
      "loss: 3.709132  [18010/50000]\n",
      "loss: 3.864856  [19010/50000]\n",
      "loss: 3.715211  [20010/50000]\n",
      "loss: 3.715284  [21010/50000]\n",
      "loss: 4.013953  [22010/50000]\n",
      "loss: 3.705485  [23010/50000]\n",
      "loss: 3.761351  [24010/50000]\n",
      "loss: 3.826942  [25010/50000]\n",
      "loss: 3.881429  [26010/50000]\n",
      "loss: 3.814486  [27010/50000]\n",
      "loss: 3.718898  [28010/50000]\n",
      "loss: 3.898798  [29010/50000]\n",
      "loss: 3.868811  [30010/50000]\n",
      "loss: 3.719509  [31010/50000]\n",
      "loss: 3.765917  [32010/50000]\n",
      "loss: 3.719513  [33010/50000]\n",
      "loss: 3.872780  [34010/50000]\n",
      "loss: 3.705240  [35010/50000]\n",
      "loss: 3.845124  [36010/50000]\n",
      "loss: 3.717576  [37010/50000]\n",
      "loss: 3.854113  [38010/50000]\n",
      "loss: 3.795867  [39010/50000]\n",
      "loss: 3.742374  [40010/50000]\n",
      "loss: 3.690004  [41010/50000]\n",
      "loss: 3.714768  [42010/50000]\n",
      "loss: 3.726372  [43010/50000]\n",
      "loss: 3.813644  [44010/50000]\n",
      "loss: 3.709290  [45010/50000]\n",
      "loss: 3.928652  [46010/50000]\n",
      "loss: 3.707051  [47010/50000]\n",
      "loss: 3.727564  [48010/50000]\n",
      "loss: 3.694834  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 3.942350 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 3.708619  [   10/50000]\n",
      "loss: 3.708886  [ 1010/50000]\n",
      "loss: 3.726186  [ 2010/50000]\n",
      "loss: 3.697208  [ 3010/50000]\n",
      "loss: 3.754592  [ 4010/50000]\n",
      "loss: 3.710735  [ 5010/50000]\n",
      "loss: 3.727822  [ 6010/50000]\n",
      "loss: 3.738643  [ 7010/50000]\n",
      "loss: 3.750680  [ 8010/50000]\n",
      "loss: 3.898780  [ 9010/50000]\n",
      "loss: 3.974758  [10010/50000]\n",
      "loss: 3.776675  [11010/50000]\n",
      "loss: 3.694028  [12010/50000]\n",
      "loss: 3.785860  [13010/50000]\n",
      "loss: 3.695842  [14010/50000]\n",
      "loss: 3.885473  [15010/50000]\n",
      "loss: 3.691064  [16010/50000]\n",
      "loss: 3.956219  [17010/50000]\n",
      "loss: 3.795097  [18010/50000]\n",
      "loss: 3.768530  [19010/50000]\n",
      "loss: 3.821512  [20010/50000]\n",
      "loss: 3.704342  [21010/50000]\n",
      "loss: 3.740408  [22010/50000]\n",
      "loss: 3.793433  [23010/50000]\n",
      "loss: 3.714396  [24010/50000]\n",
      "loss: 3.711193  [25010/50000]\n",
      "loss: 3.844150  [26010/50000]\n",
      "loss: 3.858335  [27010/50000]\n",
      "loss: 3.795724  [28010/50000]\n",
      "loss: 3.718941  [29010/50000]\n",
      "loss: 3.754250  [30010/50000]\n",
      "loss: 3.907637  [31010/50000]\n",
      "loss: 3.703687  [32010/50000]\n",
      "loss: 3.800403  [33010/50000]\n",
      "loss: 3.716775  [34010/50000]\n",
      "loss: 3.804080  [35010/50000]\n",
      "loss: 3.724508  [36010/50000]\n",
      "loss: 3.783633  [37010/50000]\n",
      "loss: 3.696618  [38010/50000]\n",
      "loss: 3.789172  [39010/50000]\n",
      "loss: 3.702508  [40010/50000]\n",
      "loss: 3.778683  [41010/50000]\n",
      "loss: 3.714756  [42010/50000]\n",
      "loss: 3.700089  [43010/50000]\n",
      "loss: 3.804095  [44010/50000]\n",
      "loss: 3.797439  [45010/50000]\n",
      "loss: 3.708838  [46010/50000]\n",
      "loss: 3.716441  [47010/50000]\n",
      "loss: 3.805904  [48010/50000]\n",
      "loss: 3.721867  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.5%, Avg loss: 3.940369 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 3.713243  [   10/50000]\n",
      "loss: 3.767264  [ 1010/50000]\n",
      "loss: 3.688348  [ 2010/50000]\n",
      "loss: 3.699141  [ 3010/50000]\n",
      "loss: 3.885691  [ 4010/50000]\n",
      "loss: 3.692571  [ 5010/50000]\n",
      "loss: 3.703960  [ 6010/50000]\n",
      "loss: 3.772483  [ 7010/50000]\n",
      "loss: 3.713758  [ 8010/50000]\n",
      "loss: 3.929438  [ 9010/50000]\n",
      "loss: 3.807484  [10010/50000]\n",
      "loss: 3.806407  [11010/50000]\n",
      "loss: 3.719296  [12010/50000]\n",
      "loss: 3.705921  [13010/50000]\n",
      "loss: 3.812571  [14010/50000]\n",
      "loss: 3.714873  [15010/50000]\n",
      "loss: 3.708624  [16010/50000]\n",
      "loss: 3.801278  [17010/50000]\n",
      "loss: 3.697507  [18010/50000]\n",
      "loss: 3.752496  [19010/50000]\n",
      "loss: 3.797077  [20010/50000]\n",
      "loss: 3.769732  [21010/50000]\n",
      "loss: 3.807499  [22010/50000]\n",
      "loss: 3.831524  [23010/50000]\n",
      "loss: 3.694413  [24010/50000]\n",
      "loss: 3.709609  [25010/50000]\n",
      "loss: 3.715400  [26010/50000]\n",
      "loss: 3.693473  [27010/50000]\n",
      "loss: 4.032052  [28010/50000]\n",
      "loss: 3.725095  [29010/50000]\n",
      "loss: 3.799688  [30010/50000]\n",
      "loss: 3.717828  [31010/50000]\n",
      "loss: 3.693431  [32010/50000]\n",
      "loss: 3.690375  [33010/50000]\n",
      "loss: 3.807676  [34010/50000]\n",
      "loss: 3.709494  [35010/50000]\n",
      "loss: 3.919108  [36010/50000]\n",
      "loss: 3.690948  [37010/50000]\n",
      "loss: 3.715010  [38010/50000]\n",
      "loss: 3.712186  [39010/50000]\n",
      "loss: 3.818695  [40010/50000]\n",
      "loss: 3.983817  [41010/50000]\n",
      "loss: 3.792985  [42010/50000]\n",
      "loss: 3.935642  [43010/50000]\n",
      "loss: 3.791228  [44010/50000]\n",
      "loss: 3.705205  [45010/50000]\n",
      "loss: 3.739268  [46010/50000]\n",
      "loss: 3.715628  [47010/50000]\n",
      "loss: 3.790062  [48010/50000]\n",
      "loss: 3.703332  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 3.943624 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 3.708157  [   10/50000]\n",
      "loss: 3.724432  [ 1010/50000]\n",
      "loss: 3.704722  [ 2010/50000]\n",
      "loss: 3.820025  [ 3010/50000]\n",
      "loss: 3.708184  [ 4010/50000]\n",
      "loss: 3.819132  [ 5010/50000]\n",
      "loss: 3.688287  [ 6010/50000]\n",
      "loss: 3.701542  [ 7010/50000]\n",
      "loss: 3.775973  [ 8010/50000]\n",
      "loss: 3.739819  [ 9010/50000]\n",
      "loss: 3.787494  [10010/50000]\n",
      "loss: 3.762516  [11010/50000]\n",
      "loss: 3.720501  [12010/50000]\n",
      "loss: 3.688669  [13010/50000]\n",
      "loss: 3.825241  [14010/50000]\n",
      "loss: 3.731197  [15010/50000]\n",
      "loss: 3.704910  [16010/50000]\n",
      "loss: 3.698673  [17010/50000]\n",
      "loss: 3.718078  [18010/50000]\n",
      "loss: 3.714208  [19010/50000]\n",
      "loss: 3.797210  [20010/50000]\n",
      "loss: 3.718505  [21010/50000]\n",
      "loss: 3.697418  [22010/50000]\n",
      "loss: 3.706782  [23010/50000]\n",
      "loss: 3.720139  [24010/50000]\n",
      "loss: 3.843228  [25010/50000]\n",
      "loss: 3.719800  [26010/50000]\n",
      "loss: 3.794020  [27010/50000]\n",
      "loss: 3.764987  [28010/50000]\n",
      "loss: 3.721687  [29010/50000]\n",
      "loss: 3.810178  [30010/50000]\n",
      "loss: 3.696213  [31010/50000]\n",
      "loss: 3.705109  [32010/50000]\n",
      "loss: 3.728186  [33010/50000]\n",
      "loss: 3.733504  [34010/50000]\n",
      "loss: 3.750902  [35010/50000]\n",
      "loss: 3.801551  [36010/50000]\n",
      "loss: 3.822929  [37010/50000]\n",
      "loss: 3.709101  [38010/50000]\n",
      "loss: 3.691890  [39010/50000]\n",
      "loss: 3.696678  [40010/50000]\n",
      "loss: 3.714402  [41010/50000]\n",
      "loss: 3.694582  [42010/50000]\n",
      "loss: 3.728490  [43010/50000]\n",
      "loss: 3.805789  [44010/50000]\n",
      "loss: 3.723449  [45010/50000]\n",
      "loss: 3.739845  [46010/50000]\n",
      "loss: 3.720090  [47010/50000]\n",
      "loss: 3.718597  [48010/50000]\n",
      "loss: 3.695943  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 3.949044 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 3.697996  [   10/50000]\n",
      "loss: 3.711386  [ 1010/50000]\n",
      "loss: 3.810133  [ 2010/50000]\n",
      "loss: 3.791001  [ 3010/50000]\n",
      "loss: 3.697341  [ 4010/50000]\n",
      "loss: 3.727443  [ 5010/50000]\n",
      "loss: 3.714948  [ 6010/50000]\n",
      "loss: 3.712282  [ 7010/50000]\n",
      "loss: 3.700322  [ 8010/50000]\n",
      "loss: 3.742049  [ 9010/50000]\n",
      "loss: 3.873950  [10010/50000]\n",
      "loss: 3.709470  [11010/50000]\n",
      "loss: 3.710520  [12010/50000]\n",
      "loss: 3.715676  [13010/50000]\n",
      "loss: 3.686305  [14010/50000]\n",
      "loss: 3.741494  [15010/50000]\n",
      "loss: 3.700436  [16010/50000]\n",
      "loss: 3.822152  [17010/50000]\n",
      "loss: 3.694133  [18010/50000]\n",
      "loss: 3.705020  [19010/50000]\n",
      "loss: 3.799338  [20010/50000]\n",
      "loss: 3.745990  [21010/50000]\n",
      "loss: 3.704293  [22010/50000]\n",
      "loss: 3.814300  [23010/50000]\n",
      "loss: 3.740181  [24010/50000]\n",
      "loss: 3.709431  [25010/50000]\n",
      "loss: 3.863300  [26010/50000]\n",
      "loss: 3.821978  [27010/50000]\n",
      "loss: 3.799250  [28010/50000]\n",
      "loss: 3.721948  [29010/50000]\n",
      "loss: 3.699928  [30010/50000]\n",
      "loss: 3.717539  [31010/50000]\n",
      "loss: 3.706450  [32010/50000]\n",
      "loss: 3.713140  [33010/50000]\n",
      "loss: 3.802520  [34010/50000]\n",
      "loss: 3.765321  [35010/50000]\n",
      "loss: 3.930074  [36010/50000]\n",
      "loss: 3.739377  [37010/50000]\n",
      "loss: 3.745780  [38010/50000]\n",
      "loss: 3.809585  [39010/50000]\n",
      "loss: 3.706936  [40010/50000]\n",
      "loss: 3.735411  [41010/50000]\n",
      "loss: 3.708795  [42010/50000]\n",
      "loss: 3.688699  [43010/50000]\n",
      "loss: 3.703015  [44010/50000]\n",
      "loss: 3.838931  [45010/50000]\n",
      "loss: 3.727115  [46010/50000]\n",
      "loss: 3.705193  [47010/50000]\n",
      "loss: 3.736573  [48010/50000]\n",
      "loss: 3.727141  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 3.951393 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 3.702670  [   10/50000]\n",
      "loss: 3.708440  [ 1010/50000]\n",
      "loss: 3.704528  [ 2010/50000]\n",
      "loss: 3.812075  [ 3010/50000]\n",
      "loss: 3.717682  [ 4010/50000]\n",
      "loss: 3.705468  [ 5010/50000]\n",
      "loss: 3.799474  [ 6010/50000]\n",
      "loss: 3.746968  [ 7010/50000]\n",
      "loss: 3.793739  [ 8010/50000]\n",
      "loss: 3.831704  [ 9010/50000]\n",
      "loss: 3.721968  [10010/50000]\n",
      "loss: 3.694804  [11010/50000]\n",
      "loss: 3.673446  [12010/50000]\n",
      "loss: 3.793108  [13010/50000]\n",
      "loss: 3.695918  [14010/50000]\n",
      "loss: 3.711893  [15010/50000]\n",
      "loss: 3.697853  [16010/50000]\n",
      "loss: 3.745644  [17010/50000]\n",
      "loss: 3.778456  [18010/50000]\n",
      "loss: 3.694511  [19010/50000]\n",
      "loss: 3.765541  [20010/50000]\n",
      "loss: 3.749492  [21010/50000]\n",
      "loss: 3.714175  [22010/50000]\n",
      "loss: 3.719177  [23010/50000]\n",
      "loss: 3.812648  [24010/50000]\n",
      "loss: 3.723726  [25010/50000]\n",
      "loss: 3.868858  [26010/50000]\n",
      "loss: 3.699712  [27010/50000]\n",
      "loss: 3.837141  [28010/50000]\n",
      "loss: 3.691884  [29010/50000]\n",
      "loss: 3.766995  [30010/50000]\n",
      "loss: 3.721406  [31010/50000]\n",
      "loss: 3.809863  [32010/50000]\n",
      "loss: 3.702958  [33010/50000]\n",
      "loss: 3.795585  [34010/50000]\n",
      "loss: 3.747805  [35010/50000]\n",
      "loss: 3.704893  [36010/50000]\n",
      "loss: 3.793850  [37010/50000]\n",
      "loss: 3.849714  [38010/50000]\n",
      "loss: 3.728308  [39010/50000]\n",
      "loss: 3.703242  [40010/50000]\n",
      "loss: 3.721954  [41010/50000]\n",
      "loss: 3.700330  [42010/50000]\n",
      "loss: 3.708976  [43010/50000]\n",
      "loss: 3.709208  [44010/50000]\n",
      "loss: 3.712039  [45010/50000]\n",
      "loss: 3.718931  [46010/50000]\n",
      "loss: 3.779464  [47010/50000]\n",
      "loss: 3.684770  [48010/50000]\n",
      "loss: 3.700795  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 3.950993 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 3.754697  [   10/50000]\n",
      "loss: 3.843728  [ 1010/50000]\n",
      "loss: 3.731521  [ 2010/50000]\n",
      "loss: 3.693689  [ 3010/50000]\n",
      "loss: 3.748888  [ 4010/50000]\n",
      "loss: 3.690440  [ 5010/50000]\n",
      "loss: 3.713676  [ 6010/50000]\n",
      "loss: 3.702021  [ 7010/50000]\n",
      "loss: 3.836105  [ 8010/50000]\n",
      "loss: 3.712531  [ 9010/50000]\n",
      "loss: 3.781672  [10010/50000]\n",
      "loss: 3.794125  [11010/50000]\n",
      "loss: 3.790160  [12010/50000]\n",
      "loss: 3.790288  [13010/50000]\n",
      "loss: 3.695814  [14010/50000]\n",
      "loss: 3.859178  [15010/50000]\n",
      "loss: 3.799692  [16010/50000]\n",
      "loss: 3.777377  [17010/50000]\n",
      "loss: 3.705377  [18010/50000]\n",
      "loss: 3.781797  [19010/50000]\n",
      "loss: 3.692692  [20010/50000]\n",
      "loss: 3.891741  [21010/50000]\n",
      "loss: 3.687702  [22010/50000]\n",
      "loss: 3.717830  [23010/50000]\n",
      "loss: 3.695508  [24010/50000]\n",
      "loss: 3.901122  [25010/50000]\n",
      "loss: 3.724742  [26010/50000]\n",
      "loss: 3.797078  [27010/50000]\n",
      "loss: 3.697421  [28010/50000]\n",
      "loss: 3.840438  [29010/50000]\n",
      "loss: 3.777654  [30010/50000]\n",
      "loss: 3.703121  [31010/50000]\n",
      "loss: 3.839080  [32010/50000]\n",
      "loss: 3.780885  [33010/50000]\n",
      "loss: 3.762648  [34010/50000]\n",
      "loss: 3.773278  [35010/50000]\n",
      "loss: 3.714376  [36010/50000]\n",
      "loss: 3.772623  [37010/50000]\n",
      "loss: 3.724445  [38010/50000]\n",
      "loss: 3.799638  [39010/50000]\n",
      "loss: 3.753209  [40010/50000]\n",
      "loss: 3.706633  [41010/50000]\n",
      "loss: 3.774591  [42010/50000]\n",
      "loss: 3.707778  [43010/50000]\n",
      "loss: 3.720893  [44010/50000]\n",
      "loss: 3.702337  [45010/50000]\n",
      "loss: 3.724170  [46010/50000]\n",
      "loss: 3.797416  [47010/50000]\n",
      "loss: 3.688920  [48010/50000]\n",
      "loss: 3.718489  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 3.951222 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 3.723945  [   10/50000]\n",
      "loss: 3.718390  [ 1010/50000]\n",
      "loss: 3.704589  [ 2010/50000]\n",
      "loss: 3.690836  [ 3010/50000]\n",
      "loss: 3.732064  [ 4010/50000]\n",
      "loss: 3.813672  [ 5010/50000]\n",
      "loss: 3.837348  [ 6010/50000]\n",
      "loss: 3.789246  [ 7010/50000]\n",
      "loss: 3.692713  [ 8010/50000]\n",
      "loss: 3.764893  [ 9010/50000]\n",
      "loss: 3.692447  [10010/50000]\n",
      "loss: 3.745919  [11010/50000]\n",
      "loss: 3.679531  [12010/50000]\n",
      "loss: 3.811037  [13010/50000]\n",
      "loss: 3.832860  [14010/50000]\n",
      "loss: 3.772599  [15010/50000]\n",
      "loss: 3.703857  [16010/50000]\n",
      "loss: 3.716959  [17010/50000]\n",
      "loss: 3.746243  [18010/50000]\n",
      "loss: 3.713747  [19010/50000]\n",
      "loss: 3.713214  [20010/50000]\n",
      "loss: 3.807855  [21010/50000]\n",
      "loss: 3.793153  [22010/50000]\n",
      "loss: 3.691651  [23010/50000]\n",
      "loss: 3.698413  [24010/50000]\n",
      "loss: 3.695246  [25010/50000]\n",
      "loss: 3.815675  [26010/50000]\n",
      "loss: 3.747965  [27010/50000]\n",
      "loss: 3.718755  [28010/50000]\n",
      "loss: 3.732060  [29010/50000]\n",
      "loss: 3.712452  [30010/50000]\n",
      "loss: 3.745497  [31010/50000]\n",
      "loss: 3.742043  [32010/50000]\n",
      "loss: 3.791187  [33010/50000]\n",
      "loss: 3.765576  [34010/50000]\n",
      "loss: 3.787820  [35010/50000]\n",
      "loss: 3.698265  [36010/50000]\n",
      "loss: 3.740145  [37010/50000]\n",
      "loss: 3.718938  [38010/50000]\n",
      "loss: 3.692792  [39010/50000]\n",
      "loss: 3.709831  [40010/50000]\n",
      "loss: 3.742882  [41010/50000]\n",
      "loss: 3.694551  [42010/50000]\n",
      "loss: 3.721669  [43010/50000]\n",
      "loss: 3.685926  [44010/50000]\n",
      "loss: 3.701818  [45010/50000]\n",
      "loss: 3.825324  [46010/50000]\n",
      "loss: 3.686654  [47010/50000]\n",
      "loss: 3.767638  [48010/50000]\n",
      "loss: 3.829992  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 3.950318 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 3.749058  [   10/50000]\n",
      "loss: 3.719776  [ 1010/50000]\n",
      "loss: 3.800983  [ 2010/50000]\n",
      "loss: 3.704438  [ 3010/50000]\n",
      "loss: 3.728903  [ 4010/50000]\n",
      "loss: 3.707561  [ 5010/50000]\n",
      "loss: 3.699169  [ 6010/50000]\n",
      "loss: 3.960746  [ 7010/50000]\n",
      "loss: 3.756949  [ 8010/50000]\n",
      "loss: 3.695708  [ 9010/50000]\n",
      "loss: 3.712150  [10010/50000]\n",
      "loss: 3.686570  [11010/50000]\n",
      "loss: 3.786391  [12010/50000]\n",
      "loss: 3.691882  [13010/50000]\n",
      "loss: 3.831914  [14010/50000]\n",
      "loss: 3.695596  [15010/50000]\n",
      "loss: 3.715728  [16010/50000]\n",
      "loss: 3.703218  [17010/50000]\n",
      "loss: 3.797266  [18010/50000]\n",
      "loss: 3.702749  [19010/50000]\n",
      "loss: 3.719395  [20010/50000]\n",
      "loss: 3.930930  [21010/50000]\n",
      "loss: 3.879183  [22010/50000]\n",
      "loss: 3.720328  [23010/50000]\n",
      "loss: 3.700457  [24010/50000]\n",
      "loss: 3.737491  [25010/50000]\n",
      "loss: 3.795270  [26010/50000]\n",
      "loss: 3.730420  [27010/50000]\n",
      "loss: 3.797230  [28010/50000]\n",
      "loss: 3.729494  [29010/50000]\n",
      "loss: 3.694653  [30010/50000]\n",
      "loss: 3.701731  [31010/50000]\n",
      "loss: 3.721188  [32010/50000]\n",
      "loss: 3.765464  [33010/50000]\n",
      "loss: 3.695384  [34010/50000]\n",
      "loss: 3.687835  [35010/50000]\n",
      "loss: 3.818073  [36010/50000]\n",
      "loss: 3.686498  [37010/50000]\n",
      "loss: 3.700951  [38010/50000]\n",
      "loss: 3.709315  [39010/50000]\n",
      "loss: 3.697631  [40010/50000]\n",
      "loss: 3.702044  [41010/50000]\n",
      "loss: 3.689014  [42010/50000]\n",
      "loss: 3.821820  [43010/50000]\n",
      "loss: 3.773718  [44010/50000]\n",
      "loss: 3.800710  [45010/50000]\n",
      "loss: 3.697647  [46010/50000]\n",
      "loss: 3.692338  [47010/50000]\n",
      "loss: 3.702183  [48010/50000]\n",
      "loss: 3.711297  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 3.947122 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 3.741471  [   10/50000]\n",
      "loss: 3.805389  [ 1010/50000]\n",
      "loss: 3.696714  [ 2010/50000]\n",
      "loss: 3.773024  [ 3010/50000]\n",
      "loss: 3.796237  [ 4010/50000]\n",
      "loss: 3.762925  [ 5010/50000]\n",
      "loss: 3.690028  [ 6010/50000]\n",
      "loss: 3.819363  [ 7010/50000]\n",
      "loss: 3.698572  [ 8010/50000]\n",
      "loss: 3.811316  [ 9010/50000]\n",
      "loss: 3.701310  [10010/50000]\n",
      "loss: 3.750415  [11010/50000]\n",
      "loss: 3.775487  [12010/50000]\n",
      "loss: 3.919828  [13010/50000]\n",
      "loss: 3.807409  [14010/50000]\n",
      "loss: 3.733427  [15010/50000]\n",
      "loss: 3.806158  [16010/50000]\n",
      "loss: 3.692353  [17010/50000]\n",
      "loss: 3.815840  [18010/50000]\n",
      "loss: 3.707282  [19010/50000]\n",
      "loss: 3.878144  [20010/50000]\n",
      "loss: 3.706234  [21010/50000]\n",
      "loss: 3.681990  [22010/50000]\n",
      "loss: 3.703836  [23010/50000]\n",
      "loss: 3.827768  [24010/50000]\n",
      "loss: 3.690942  [25010/50000]\n",
      "loss: 3.681513  [26010/50000]\n",
      "loss: 3.688874  [27010/50000]\n",
      "loss: 3.711037  [28010/50000]\n",
      "loss: 3.707167  [29010/50000]\n",
      "loss: 3.794595  [30010/50000]\n",
      "loss: 3.723691  [31010/50000]\n",
      "loss: 3.699968  [32010/50000]\n",
      "loss: 3.692566  [33010/50000]\n",
      "loss: 3.791160  [34010/50000]\n",
      "loss: 3.697013  [35010/50000]\n",
      "loss: 3.699298  [36010/50000]\n",
      "loss: 3.698901  [37010/50000]\n",
      "loss: 3.697775  [38010/50000]\n",
      "loss: 3.700559  [39010/50000]\n",
      "loss: 3.808166  [40010/50000]\n",
      "loss: 3.790474  [41010/50000]\n",
      "loss: 3.711169  [42010/50000]\n",
      "loss: 3.687362  [43010/50000]\n",
      "loss: 3.702572  [44010/50000]\n",
      "loss: 3.836499  [45010/50000]\n",
      "loss: 3.713093  [46010/50000]\n",
      "loss: 3.742099  [47010/50000]\n",
      "loss: 3.700875  [48010/50000]\n",
      "loss: 3.843394  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 3.947616 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 3.774834  [   10/50000]\n",
      "loss: 3.707364  [ 1010/50000]\n",
      "loss: 3.786317  [ 2010/50000]\n",
      "loss: 3.692019  [ 3010/50000]\n",
      "loss: 3.705684  [ 4010/50000]\n",
      "loss: 3.708337  [ 5010/50000]\n",
      "loss: 3.711293  [ 6010/50000]\n",
      "loss: 3.733865  [ 7010/50000]\n",
      "loss: 3.792046  [ 8010/50000]\n",
      "loss: 3.701272  [ 9010/50000]\n",
      "loss: 3.708222  [10010/50000]\n",
      "loss: 3.803775  [11010/50000]\n",
      "loss: 3.800267  [12010/50000]\n",
      "loss: 3.797083  [13010/50000]\n",
      "loss: 3.768353  [14010/50000]\n",
      "loss: 3.768862  [15010/50000]\n",
      "loss: 3.713718  [16010/50000]\n",
      "loss: 3.687849  [17010/50000]\n",
      "loss: 3.694371  [18010/50000]\n",
      "loss: 3.697233  [19010/50000]\n",
      "loss: 3.688108  [20010/50000]\n",
      "loss: 3.822905  [21010/50000]\n",
      "loss: 3.716893  [22010/50000]\n",
      "loss: 3.703000  [23010/50000]\n",
      "loss: 3.716782  [24010/50000]\n",
      "loss: 3.687062  [25010/50000]\n",
      "loss: 3.717696  [26010/50000]\n",
      "loss: 3.749416  [27010/50000]\n",
      "loss: 3.722524  [28010/50000]\n",
      "loss: 3.795589  [29010/50000]\n",
      "loss: 3.745269  [30010/50000]\n",
      "loss: 3.699246  [31010/50000]\n",
      "loss: 3.774538  [32010/50000]\n",
      "loss: 3.694320  [33010/50000]\n",
      "loss: 3.684235  [34010/50000]\n",
      "loss: 3.703224  [35010/50000]\n",
      "loss: 3.688082  [36010/50000]\n",
      "loss: 3.685562  [37010/50000]\n",
      "loss: 3.691180  [38010/50000]\n",
      "loss: 3.719620  [39010/50000]\n",
      "loss: 3.693700  [40010/50000]\n",
      "loss: 3.815036  [41010/50000]\n",
      "loss: 3.693092  [42010/50000]\n",
      "loss: 3.681593  [43010/50000]\n",
      "loss: 3.728553  [44010/50000]\n",
      "loss: 3.707730  [45010/50000]\n",
      "loss: 3.705745  [46010/50000]\n",
      "loss: 3.895624  [47010/50000]\n",
      "loss: 3.684905  [48010/50000]\n",
      "loss: 3.694213  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 3.953840 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 3.732761  [   10/50000]\n",
      "loss: 3.775802  [ 1010/50000]\n",
      "loss: 3.828424  [ 2010/50000]\n",
      "loss: 3.799042  [ 3010/50000]\n",
      "loss: 3.695446  [ 4010/50000]\n",
      "loss: 3.675502  [ 5010/50000]\n",
      "loss: 3.784218  [ 6010/50000]\n",
      "loss: 3.730626  [ 7010/50000]\n",
      "loss: 3.757418  [ 8010/50000]\n",
      "loss: 3.703939  [ 9010/50000]\n",
      "loss: 3.730571  [10010/50000]\n",
      "loss: 3.703291  [11010/50000]\n",
      "loss: 3.692048  [12010/50000]\n",
      "loss: 3.749615  [13010/50000]\n",
      "loss: 3.750046  [14010/50000]\n",
      "loss: 3.774291  [15010/50000]\n",
      "loss: 3.681939  [16010/50000]\n",
      "loss: 3.755414  [17010/50000]\n",
      "loss: 3.711458  [18010/50000]\n",
      "loss: 3.688468  [19010/50000]\n",
      "loss: 3.797472  [20010/50000]\n",
      "loss: 3.744092  [21010/50000]\n",
      "loss: 3.825043  [22010/50000]\n",
      "loss: 3.764339  [23010/50000]\n",
      "loss: 3.813172  [24010/50000]\n",
      "loss: 3.833292  [25010/50000]\n",
      "loss: 3.695705  [26010/50000]\n",
      "loss: 3.693220  [27010/50000]\n",
      "loss: 3.795034  [28010/50000]\n",
      "loss: 3.818366  [29010/50000]\n",
      "loss: 3.705589  [30010/50000]\n",
      "loss: 3.718465  [31010/50000]\n",
      "loss: 3.726012  [32010/50000]\n",
      "loss: 3.693914  [33010/50000]\n",
      "loss: 3.688247  [34010/50000]\n",
      "loss: 3.697295  [35010/50000]\n",
      "loss: 3.704187  [36010/50000]\n",
      "loss: 3.801065  [37010/50000]\n",
      "loss: 3.694757  [38010/50000]\n",
      "loss: 3.704690  [39010/50000]\n",
      "loss: 3.780291  [40010/50000]\n",
      "loss: 3.693015  [41010/50000]\n",
      "loss: 3.694016  [42010/50000]\n",
      "loss: 3.699263  [43010/50000]\n",
      "loss: 3.700235  [44010/50000]\n",
      "loss: 3.780095  [45010/50000]\n",
      "loss: 3.684811  [46010/50000]\n",
      "loss: 3.702796  [47010/50000]\n",
      "loss: 3.677604  [48010/50000]\n",
      "loss: 3.692531  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 3.956309 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 3.790993  [   10/50000]\n",
      "loss: 3.701524  [ 1010/50000]\n",
      "loss: 3.724000  [ 2010/50000]\n",
      "loss: 3.689695  [ 3010/50000]\n",
      "loss: 3.710637  [ 4010/50000]\n",
      "loss: 3.689383  [ 5010/50000]\n",
      "loss: 3.844231  [ 6010/50000]\n",
      "loss: 3.741330  [ 7010/50000]\n",
      "loss: 3.775318  [ 8010/50000]\n",
      "loss: 3.703027  [ 9010/50000]\n",
      "loss: 3.723953  [10010/50000]\n",
      "loss: 3.678591  [11010/50000]\n",
      "loss: 3.696710  [12010/50000]\n",
      "loss: 3.721531  [13010/50000]\n",
      "loss: 3.688952  [14010/50000]\n",
      "loss: 3.934835  [15010/50000]\n",
      "loss: 3.739821  [16010/50000]\n",
      "loss: 3.693374  [17010/50000]\n",
      "loss: 3.704461  [18010/50000]\n",
      "loss: 3.821395  [19010/50000]\n",
      "loss: 3.709653  [20010/50000]\n",
      "loss: 3.701824  [21010/50000]\n",
      "loss: 3.699672  [22010/50000]\n",
      "loss: 3.821049  [23010/50000]\n",
      "loss: 3.760226  [24010/50000]\n",
      "loss: 3.717427  [25010/50000]\n",
      "loss: 4.011310  [26010/50000]\n",
      "loss: 3.775026  [27010/50000]\n",
      "loss: 3.724965  [28010/50000]\n",
      "loss: 3.765423  [29010/50000]\n",
      "loss: 3.693061  [30010/50000]\n",
      "loss: 3.761774  [31010/50000]\n",
      "loss: 3.713187  [32010/50000]\n",
      "loss: 3.808910  [33010/50000]\n",
      "loss: 3.684915  [34010/50000]\n",
      "loss: 3.680085  [35010/50000]\n",
      "loss: 3.689101  [36010/50000]\n",
      "loss: 3.851489  [37010/50000]\n",
      "loss: 3.745497  [38010/50000]\n",
      "loss: 3.704306  [39010/50000]\n",
      "loss: 3.727089  [40010/50000]\n",
      "loss: 3.691503  [41010/50000]\n",
      "loss: 3.783747  [42010/50000]\n",
      "loss: 3.793132  [43010/50000]\n",
      "loss: 3.780596  [44010/50000]\n",
      "loss: 3.793975  [45010/50000]\n",
      "loss: 3.799553  [46010/50000]\n",
      "loss: 3.707350  [47010/50000]\n",
      "loss: 3.697290  [48010/50000]\n",
      "loss: 3.711117  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 3.953026 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 3.713171  [   10/50000]\n",
      "loss: 3.713226  [ 1010/50000]\n",
      "loss: 3.689606  [ 2010/50000]\n",
      "loss: 3.857537  [ 3010/50000]\n",
      "loss: 3.689613  [ 4010/50000]\n",
      "loss: 3.713449  [ 5010/50000]\n",
      "loss: 3.684591  [ 6010/50000]\n",
      "loss: 3.695723  [ 7010/50000]\n",
      "loss: 3.776475  [ 8010/50000]\n",
      "loss: 3.688550  [ 9010/50000]\n",
      "loss: 3.789128  [10010/50000]\n",
      "loss: 3.800847  [11010/50000]\n",
      "loss: 3.685674  [12010/50000]\n",
      "loss: 3.884287  [13010/50000]\n",
      "loss: 3.805932  [14010/50000]\n",
      "loss: 3.794949  [15010/50000]\n",
      "loss: 3.692449  [16010/50000]\n",
      "loss: 3.715998  [17010/50000]\n",
      "loss: 3.717499  [18010/50000]\n",
      "loss: 3.775084  [19010/50000]\n",
      "loss: 3.748664  [20010/50000]\n",
      "loss: 3.687250  [21010/50000]\n",
      "loss: 3.706168  [22010/50000]\n",
      "loss: 3.703688  [23010/50000]\n",
      "loss: 3.687394  [24010/50000]\n",
      "loss: 3.691246  [25010/50000]\n",
      "loss: 3.725955  [26010/50000]\n",
      "loss: 3.690104  [27010/50000]\n",
      "loss: 3.693160  [28010/50000]\n",
      "loss: 3.769802  [29010/50000]\n",
      "loss: 3.822311  [30010/50000]\n",
      "loss: 3.741261  [31010/50000]\n",
      "loss: 3.690629  [32010/50000]\n",
      "loss: 3.786653  [33010/50000]\n",
      "loss: 3.759137  [34010/50000]\n",
      "loss: 3.688884  [35010/50000]\n",
      "loss: 3.691893  [36010/50000]\n",
      "loss: 3.706217  [37010/50000]\n",
      "loss: 3.807663  [38010/50000]\n",
      "loss: 3.686299  [39010/50000]\n",
      "loss: 3.716365  [40010/50000]\n",
      "loss: 3.690444  [41010/50000]\n",
      "loss: 3.721950  [42010/50000]\n",
      "loss: 3.695420  [43010/50000]\n",
      "loss: 3.794415  [44010/50000]\n",
      "loss: 3.783992  [45010/50000]\n",
      "loss: 3.786512  [46010/50000]\n",
      "loss: 3.708746  [47010/50000]\n",
      "loss: 3.799502  [48010/50000]\n",
      "loss: 3.731342  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 3.948235 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 3.704135  [   10/50000]\n",
      "loss: 3.798020  [ 1010/50000]\n",
      "loss: 3.706696  [ 2010/50000]\n",
      "loss: 3.686567  [ 3010/50000]\n",
      "loss: 3.689188  [ 4010/50000]\n",
      "loss: 3.782923  [ 5010/50000]\n",
      "loss: 3.727253  [ 6010/50000]\n",
      "loss: 3.702903  [ 7010/50000]\n",
      "loss: 3.698909  [ 8010/50000]\n",
      "loss: 3.702159  [ 9010/50000]\n",
      "loss: 3.699907  [10010/50000]\n",
      "loss: 3.688667  [11010/50000]\n",
      "loss: 3.695592  [12010/50000]\n",
      "loss: 3.687674  [13010/50000]\n",
      "loss: 3.687096  [14010/50000]\n",
      "loss: 3.734489  [15010/50000]\n",
      "loss: 3.780566  [16010/50000]\n",
      "loss: 3.700972  [17010/50000]\n",
      "loss: 3.728189  [18010/50000]\n",
      "loss: 3.681162  [19010/50000]\n",
      "loss: 3.685499  [20010/50000]\n",
      "loss: 3.706531  [21010/50000]\n",
      "loss: 3.701025  [22010/50000]\n",
      "loss: 3.740871  [23010/50000]\n",
      "loss: 3.687535  [24010/50000]\n",
      "loss: 3.789406  [25010/50000]\n",
      "loss: 3.689121  [26010/50000]\n",
      "loss: 3.690030  [27010/50000]\n",
      "loss: 3.813662  [28010/50000]\n",
      "loss: 3.719200  [29010/50000]\n",
      "loss: 3.707912  [30010/50000]\n",
      "loss: 3.690488  [31010/50000]\n",
      "loss: 3.739272  [32010/50000]\n",
      "loss: 3.699452  [33010/50000]\n",
      "loss: 3.679928  [34010/50000]\n",
      "loss: 3.770091  [35010/50000]\n",
      "loss: 3.673101  [36010/50000]\n",
      "loss: 3.693075  [37010/50000]\n",
      "loss: 3.687947  [38010/50000]\n",
      "loss: 3.797110  [39010/50000]\n",
      "loss: 3.701457  [40010/50000]\n",
      "loss: 3.676372  [41010/50000]\n",
      "loss: 3.710850  [42010/50000]\n",
      "loss: 3.719846  [43010/50000]\n",
      "loss: 3.683140  [44010/50000]\n",
      "loss: 3.706368  [45010/50000]\n",
      "loss: 3.875844  [46010/50000]\n",
      "loss: 3.740052  [47010/50000]\n",
      "loss: 3.783137  [48010/50000]\n",
      "loss: 3.697014  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 3.956559 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 3.727170  [   10/50000]\n",
      "loss: 3.677611  [ 1010/50000]\n",
      "loss: 3.685312  [ 2010/50000]\n",
      "loss: 3.703199  [ 3010/50000]\n",
      "loss: 3.803022  [ 4010/50000]\n",
      "loss: 3.679034  [ 5010/50000]\n",
      "loss: 3.777460  [ 6010/50000]\n",
      "loss: 3.683980  [ 7010/50000]\n",
      "loss: 3.674622  [ 8010/50000]\n",
      "loss: 3.822446  [ 9010/50000]\n",
      "loss: 3.686516  [10010/50000]\n",
      "loss: 3.677145  [11010/50000]\n",
      "loss: 3.784348  [12010/50000]\n",
      "loss: 3.800146  [13010/50000]\n",
      "loss: 3.880629  [14010/50000]\n",
      "loss: 3.711356  [15010/50000]\n",
      "loss: 3.783564  [16010/50000]\n",
      "loss: 3.695633  [17010/50000]\n",
      "loss: 3.732761  [18010/50000]\n",
      "loss: 3.745268  [19010/50000]\n",
      "loss: 3.691502  [20010/50000]\n",
      "loss: 3.786103  [21010/50000]\n",
      "loss: 3.716571  [22010/50000]\n",
      "loss: 3.782751  [23010/50000]\n",
      "loss: 3.694417  [24010/50000]\n",
      "loss: 3.692093  [25010/50000]\n",
      "loss: 3.679808  [26010/50000]\n",
      "loss: 3.697879  [27010/50000]\n",
      "loss: 3.703199  [28010/50000]\n",
      "loss: 3.691269  [29010/50000]\n",
      "loss: 3.783463  [30010/50000]\n",
      "loss: 3.891480  [31010/50000]\n",
      "loss: 3.787320  [32010/50000]\n",
      "loss: 3.862584  [33010/50000]\n",
      "loss: 3.725925  [34010/50000]\n",
      "loss: 3.699076  [35010/50000]\n",
      "loss: 3.687429  [36010/50000]\n",
      "loss: 3.686063  [37010/50000]\n",
      "loss: 3.822324  [38010/50000]\n",
      "loss: 3.797783  [39010/50000]\n",
      "loss: 3.698354  [40010/50000]\n",
      "loss: 3.795069  [41010/50000]\n",
      "loss: 3.697867  [42010/50000]\n",
      "loss: 3.686842  [43010/50000]\n",
      "loss: 3.797768  [44010/50000]\n",
      "loss: 3.701624  [45010/50000]\n",
      "loss: 3.696882  [46010/50000]\n",
      "loss: 3.713914  [47010/50000]\n",
      "loss: 3.689043  [48010/50000]\n",
      "loss: 3.691922  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 3.955093 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 3.684909  [   10/50000]\n",
      "loss: 3.710876  [ 1010/50000]\n",
      "loss: 3.688460  [ 2010/50000]\n",
      "loss: 3.731534  [ 3010/50000]\n",
      "loss: 3.704442  [ 4010/50000]\n",
      "loss: 3.676263  [ 5010/50000]\n",
      "loss: 3.752059  [ 6010/50000]\n",
      "loss: 3.697479  [ 7010/50000]\n",
      "loss: 3.677742  [ 8010/50000]\n",
      "loss: 3.686868  [ 9010/50000]\n",
      "loss: 3.879899  [10010/50000]\n",
      "loss: 3.689423  [11010/50000]\n",
      "loss: 3.686002  [12010/50000]\n",
      "loss: 3.808138  [13010/50000]\n",
      "loss: 3.693509  [14010/50000]\n",
      "loss: 3.691996  [15010/50000]\n",
      "loss: 3.695637  [16010/50000]\n",
      "loss: 3.789600  [17010/50000]\n",
      "loss: 3.811765  [18010/50000]\n",
      "loss: 3.700261  [19010/50000]\n",
      "loss: 3.702625  [20010/50000]\n",
      "loss: 3.775746  [21010/50000]\n",
      "loss: 3.706012  [22010/50000]\n",
      "loss: 3.780806  [23010/50000]\n",
      "loss: 3.688035  [24010/50000]\n",
      "loss: 3.781185  [25010/50000]\n",
      "loss: 3.800339  [26010/50000]\n",
      "loss: 3.694072  [27010/50000]\n",
      "loss: 3.709597  [28010/50000]\n",
      "loss: 3.776498  [29010/50000]\n",
      "loss: 3.672302  [30010/50000]\n",
      "loss: 3.707371  [31010/50000]\n",
      "loss: 3.680864  [32010/50000]\n",
      "loss: 3.708796  [33010/50000]\n",
      "loss: 3.691263  [34010/50000]\n",
      "loss: 3.695956  [35010/50000]\n",
      "loss: 3.727569  [36010/50000]\n",
      "loss: 3.757125  [37010/50000]\n",
      "loss: 3.685262  [38010/50000]\n",
      "loss: 3.691533  [39010/50000]\n",
      "loss: 3.687722  [40010/50000]\n",
      "loss: 3.720401  [41010/50000]\n",
      "loss: 3.704931  [42010/50000]\n",
      "loss: 3.691682  [43010/50000]\n",
      "loss: 3.685338  [44010/50000]\n",
      "loss: 3.770396  [45010/50000]\n",
      "loss: 3.784164  [46010/50000]\n",
      "loss: 3.694241  [47010/50000]\n",
      "loss: 3.732708  [48010/50000]\n",
      "loss: 3.685489  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 3.957433 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 3.678778  [   10/50000]\n",
      "loss: 3.671612  [ 1010/50000]\n",
      "loss: 3.705787  [ 2010/50000]\n",
      "loss: 3.700130  [ 3010/50000]\n",
      "loss: 3.681108  [ 4010/50000]\n",
      "loss: 3.782922  [ 5010/50000]\n",
      "loss: 3.697510  [ 6010/50000]\n",
      "loss: 3.832010  [ 7010/50000]\n",
      "loss: 3.699516  [ 8010/50000]\n",
      "loss: 3.680996  [ 9010/50000]\n",
      "loss: 3.802856  [10010/50000]\n",
      "loss: 3.712674  [11010/50000]\n",
      "loss: 3.690310  [12010/50000]\n",
      "loss: 3.784091  [13010/50000]\n",
      "loss: 3.707514  [14010/50000]\n",
      "loss: 3.687840  [15010/50000]\n",
      "loss: 3.801892  [16010/50000]\n",
      "loss: 3.683106  [17010/50000]\n",
      "loss: 3.688114  [18010/50000]\n",
      "loss: 3.721757  [19010/50000]\n",
      "loss: 3.787770  [20010/50000]\n",
      "loss: 3.686298  [21010/50000]\n",
      "loss: 3.687290  [22010/50000]\n",
      "loss: 3.714916  [23010/50000]\n",
      "loss: 3.696574  [24010/50000]\n",
      "loss: 3.697919  [25010/50000]\n",
      "loss: 3.686175  [26010/50000]\n",
      "loss: 3.720312  [27010/50000]\n",
      "loss: 3.698938  [28010/50000]\n",
      "loss: 3.700630  [29010/50000]\n",
      "loss: 3.699144  [30010/50000]\n",
      "loss: 3.684216  [31010/50000]\n",
      "loss: 3.687685  [32010/50000]\n",
      "loss: 3.690413  [33010/50000]\n",
      "loss: 3.704591  [34010/50000]\n",
      "loss: 3.796961  [35010/50000]\n",
      "loss: 3.751035  [36010/50000]\n",
      "loss: 3.789131  [37010/50000]\n",
      "loss: 3.691578  [38010/50000]\n",
      "loss: 3.687729  [39010/50000]\n",
      "loss: 3.682053  [40010/50000]\n",
      "loss: 3.802985  [41010/50000]\n",
      "loss: 3.703021  [42010/50000]\n",
      "loss: 3.853519  [43010/50000]\n",
      "loss: 3.787822  [44010/50000]\n",
      "loss: 3.719890  [45010/50000]\n",
      "loss: 3.759628  [46010/50000]\n",
      "loss: 3.687559  [47010/50000]\n",
      "loss: 3.678650  [48010/50000]\n",
      "loss: 3.709055  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 3.959269 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 3.693758  [   10/50000]\n",
      "loss: 3.697999  [ 1010/50000]\n",
      "loss: 3.931020  [ 2010/50000]\n",
      "loss: 3.703465  [ 3010/50000]\n",
      "loss: 3.670110  [ 4010/50000]\n",
      "loss: 3.679006  [ 5010/50000]\n",
      "loss: 3.736641  [ 6010/50000]\n",
      "loss: 3.694607  [ 7010/50000]\n",
      "loss: 3.703503  [ 8010/50000]\n",
      "loss: 3.680225  [ 9010/50000]\n",
      "loss: 3.684465  [10010/50000]\n",
      "loss: 3.782634  [11010/50000]\n",
      "loss: 3.684823  [12010/50000]\n",
      "loss: 3.698488  [13010/50000]\n",
      "loss: 3.684052  [14010/50000]\n",
      "loss: 3.702729  [15010/50000]\n",
      "loss: 3.696390  [16010/50000]\n",
      "loss: 3.673811  [17010/50000]\n",
      "loss: 3.679052  [18010/50000]\n",
      "loss: 3.694516  [19010/50000]\n",
      "loss: 3.688896  [20010/50000]\n",
      "loss: 3.816143  [21010/50000]\n",
      "loss: 3.677224  [22010/50000]\n",
      "loss: 3.689173  [23010/50000]\n",
      "loss: 3.678439  [24010/50000]\n",
      "loss: 3.691026  [25010/50000]\n",
      "loss: 3.804560  [26010/50000]\n",
      "loss: 3.725535  [27010/50000]\n",
      "loss: 3.676431  [28010/50000]\n",
      "loss: 3.677409  [29010/50000]\n",
      "loss: 3.697679  [30010/50000]\n",
      "loss: 3.794335  [31010/50000]\n",
      "loss: 3.679532  [32010/50000]\n",
      "loss: 3.690161  [33010/50000]\n",
      "loss: 3.686543  [34010/50000]\n",
      "loss: 3.856452  [35010/50000]\n",
      "loss: 3.807016  [36010/50000]\n",
      "loss: 3.687569  [37010/50000]\n",
      "loss: 3.735624  [38010/50000]\n",
      "loss: 3.715709  [39010/50000]\n",
      "loss: 3.688666  [40010/50000]\n",
      "loss: 3.692351  [41010/50000]\n",
      "loss: 3.725558  [42010/50000]\n",
      "loss: 3.685579  [43010/50000]\n",
      "loss: 3.702111  [44010/50000]\n",
      "loss: 3.693469  [45010/50000]\n",
      "loss: 3.680020  [46010/50000]\n",
      "loss: 3.807140  [47010/50000]\n",
      "loss: 3.677554  [48010/50000]\n",
      "loss: 3.696756  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 3.953882 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 3.763057  [   10/50000]\n",
      "loss: 3.703881  [ 1010/50000]\n",
      "loss: 3.694032  [ 2010/50000]\n",
      "loss: 3.695774  [ 3010/50000]\n",
      "loss: 3.681690  [ 4010/50000]\n",
      "loss: 3.687976  [ 5010/50000]\n",
      "loss: 3.679916  [ 6010/50000]\n",
      "loss: 3.681091  [ 7010/50000]\n",
      "loss: 3.683952  [ 8010/50000]\n",
      "loss: 3.686362  [ 9010/50000]\n",
      "loss: 3.674706  [10010/50000]\n",
      "loss: 3.706560  [11010/50000]\n",
      "loss: 3.777678  [12010/50000]\n",
      "loss: 3.816856  [13010/50000]\n",
      "loss: 3.698745  [14010/50000]\n",
      "loss: 3.914317  [15010/50000]\n",
      "loss: 3.674891  [16010/50000]\n",
      "loss: 3.694908  [17010/50000]\n",
      "loss: 3.802050  [18010/50000]\n",
      "loss: 3.723623  [19010/50000]\n",
      "loss: 3.689821  [20010/50000]\n",
      "loss: 3.879236  [21010/50000]\n",
      "loss: 3.790199  [22010/50000]\n",
      "loss: 3.666957  [23010/50000]\n",
      "loss: 3.805040  [24010/50000]\n",
      "loss: 3.688107  [25010/50000]\n",
      "loss: 3.719660  [26010/50000]\n",
      "loss: 3.689956  [27010/50000]\n",
      "loss: 3.676917  [28010/50000]\n",
      "loss: 3.709897  [29010/50000]\n",
      "loss: 3.687226  [30010/50000]\n",
      "loss: 3.683502  [31010/50000]\n",
      "loss: 3.776135  [32010/50000]\n",
      "loss: 3.679769  [33010/50000]\n",
      "loss: 3.687569  [34010/50000]\n",
      "loss: 3.680606  [35010/50000]\n",
      "loss: 3.732808  [36010/50000]\n",
      "loss: 3.708398  [37010/50000]\n",
      "loss: 3.678929  [38010/50000]\n",
      "loss: 3.681581  [39010/50000]\n",
      "loss: 3.748240  [40010/50000]\n",
      "loss: 3.686779  [41010/50000]\n",
      "loss: 3.708698  [42010/50000]\n",
      "loss: 3.791209  [43010/50000]\n",
      "loss: 3.775546  [44010/50000]\n",
      "loss: 3.708519  [45010/50000]\n",
      "loss: 3.679152  [46010/50000]\n",
      "loss: 3.709581  [47010/50000]\n",
      "loss: 3.755127  [48010/50000]\n",
      "loss: 3.729458  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 3.967414 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 3.677806  [   10/50000]\n",
      "loss: 3.697208  [ 1010/50000]\n",
      "loss: 3.784513  [ 2010/50000]\n",
      "loss: 3.742069  [ 3010/50000]\n",
      "loss: 3.770861  [ 4010/50000]\n",
      "loss: 3.695525  [ 5010/50000]\n",
      "loss: 3.688954  [ 6010/50000]\n",
      "loss: 3.691347  [ 7010/50000]\n",
      "loss: 3.692619  [ 8010/50000]\n",
      "loss: 3.694074  [ 9010/50000]\n",
      "loss: 3.689769  [10010/50000]\n",
      "loss: 3.688698  [11010/50000]\n",
      "loss: 3.676865  [12010/50000]\n",
      "loss: 3.678469  [13010/50000]\n",
      "loss: 3.679274  [14010/50000]\n",
      "loss: 3.730955  [15010/50000]\n",
      "loss: 3.683858  [16010/50000]\n",
      "loss: 3.907659  [17010/50000]\n",
      "loss: 3.686912  [18010/50000]\n",
      "loss: 3.680008  [19010/50000]\n",
      "loss: 3.723534  [20010/50000]\n",
      "loss: 3.693053  [21010/50000]\n",
      "loss: 3.746356  [22010/50000]\n",
      "loss: 3.705102  [23010/50000]\n",
      "loss: 3.705987  [24010/50000]\n",
      "loss: 3.784491  [25010/50000]\n",
      "loss: 3.727150  [26010/50000]\n",
      "loss: 3.691368  [27010/50000]\n",
      "loss: 3.711554  [28010/50000]\n",
      "loss: 3.685763  [29010/50000]\n",
      "loss: 3.698008  [30010/50000]\n",
      "loss: 3.673422  [31010/50000]\n",
      "loss: 3.670645  [32010/50000]\n",
      "loss: 3.741567  [33010/50000]\n",
      "loss: 3.686103  [34010/50000]\n",
      "loss: 3.840279  [35010/50000]\n",
      "loss: 3.682986  [36010/50000]\n",
      "loss: 3.697507  [37010/50000]\n",
      "loss: 3.686698  [38010/50000]\n",
      "loss: 3.673257  [39010/50000]\n",
      "loss: 3.731061  [40010/50000]\n",
      "loss: 3.696174  [41010/50000]\n",
      "loss: 3.831786  [42010/50000]\n",
      "loss: 3.681035  [43010/50000]\n",
      "loss: 3.770152  [44010/50000]\n",
      "loss: 3.681319  [45010/50000]\n",
      "loss: 3.681111  [46010/50000]\n",
      "loss: 3.887089  [47010/50000]\n",
      "loss: 3.678244  [48010/50000]\n",
      "loss: 3.678390  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 3.955711 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 3.777966  [   10/50000]\n",
      "loss: 3.821963  [ 1010/50000]\n",
      "loss: 3.755597  [ 2010/50000]\n",
      "loss: 3.695771  [ 3010/50000]\n",
      "loss: 3.687540  [ 4010/50000]\n",
      "loss: 3.836934  [ 5010/50000]\n",
      "loss: 3.685308  [ 6010/50000]\n",
      "loss: 3.774336  [ 7010/50000]\n",
      "loss: 3.696153  [ 8010/50000]\n",
      "loss: 3.677668  [ 9010/50000]\n",
      "loss: 3.696647  [10010/50000]\n",
      "loss: 3.695178  [11010/50000]\n",
      "loss: 3.683152  [12010/50000]\n",
      "loss: 3.721764  [13010/50000]\n",
      "loss: 3.724251  [14010/50000]\n",
      "loss: 3.663688  [15010/50000]\n",
      "loss: 3.690866  [16010/50000]\n",
      "loss: 3.687516  [17010/50000]\n",
      "loss: 3.762961  [18010/50000]\n",
      "loss: 3.800875  [19010/50000]\n",
      "loss: 3.701685  [20010/50000]\n",
      "loss: 3.713169  [21010/50000]\n",
      "loss: 3.758286  [22010/50000]\n",
      "loss: 3.685616  [23010/50000]\n",
      "loss: 3.693661  [24010/50000]\n",
      "loss: 3.686008  [25010/50000]\n",
      "loss: 3.677849  [26010/50000]\n",
      "loss: 3.804043  [27010/50000]\n",
      "loss: 3.679257  [28010/50000]\n",
      "loss: 3.675912  [29010/50000]\n",
      "loss: 3.689986  [30010/50000]\n",
      "loss: 3.803353  [31010/50000]\n",
      "loss: 3.679561  [32010/50000]\n",
      "loss: 3.776646  [33010/50000]\n",
      "loss: 3.688567  [34010/50000]\n",
      "loss: 3.678726  [35010/50000]\n",
      "loss: 3.718413  [36010/50000]\n",
      "loss: 3.695684  [37010/50000]\n",
      "loss: 3.761028  [38010/50000]\n",
      "loss: 3.684240  [39010/50000]\n",
      "loss: 3.686249  [40010/50000]\n",
      "loss: 3.717143  [41010/50000]\n",
      "loss: 3.685271  [42010/50000]\n",
      "loss: 3.690451  [43010/50000]\n",
      "loss: 3.673899  [44010/50000]\n",
      "loss: 3.703795  [45010/50000]\n",
      "loss: 3.761901  [46010/50000]\n",
      "loss: 3.717751  [47010/50000]\n",
      "loss: 3.710145  [48010/50000]\n",
      "loss: 3.732443  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 3.964568 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 3.682895  [   10/50000]\n",
      "loss: 3.693369  [ 1010/50000]\n",
      "loss: 3.765201  [ 2010/50000]\n",
      "loss: 3.702006  [ 3010/50000]\n",
      "loss: 3.746096  [ 4010/50000]\n",
      "loss: 3.689114  [ 5010/50000]\n",
      "loss: 3.757783  [ 6010/50000]\n",
      "loss: 3.803326  [ 7010/50000]\n",
      "loss: 3.738041  [ 8010/50000]\n",
      "loss: 3.689468  [ 9010/50000]\n",
      "loss: 3.681715  [10010/50000]\n",
      "loss: 3.692479  [11010/50000]\n",
      "loss: 3.676260  [12010/50000]\n",
      "loss: 3.676261  [13010/50000]\n",
      "loss: 3.688568  [14010/50000]\n",
      "loss: 3.741668  [15010/50000]\n",
      "loss: 3.691983  [16010/50000]\n",
      "loss: 3.722406  [17010/50000]\n",
      "loss: 3.673622  [18010/50000]\n",
      "loss: 3.698292  [19010/50000]\n",
      "loss: 3.862198  [20010/50000]\n",
      "loss: 3.828566  [21010/50000]\n",
      "loss: 3.679182  [22010/50000]\n",
      "loss: 3.736699  [23010/50000]\n",
      "loss: 3.780106  [24010/50000]\n",
      "loss: 3.688613  [25010/50000]\n",
      "loss: 3.772549  [26010/50000]\n",
      "loss: 3.724602  [27010/50000]\n",
      "loss: 3.669023  [28010/50000]\n",
      "loss: 3.693345  [29010/50000]\n",
      "loss: 3.707761  [30010/50000]\n",
      "loss: 3.751740  [31010/50000]\n",
      "loss: 3.680112  [32010/50000]\n",
      "loss: 3.681490  [33010/50000]\n",
      "loss: 3.679995  [34010/50000]\n",
      "loss: 3.828458  [35010/50000]\n",
      "loss: 3.721565  [36010/50000]\n",
      "loss: 3.804501  [37010/50000]\n",
      "loss: 3.772501  [38010/50000]\n",
      "loss: 3.694364  [39010/50000]\n",
      "loss: 3.727998  [40010/50000]\n",
      "loss: 3.705760  [41010/50000]\n",
      "loss: 3.671101  [42010/50000]\n",
      "loss: 3.693971  [43010/50000]\n",
      "loss: 3.679174  [44010/50000]\n",
      "loss: 3.683191  [45010/50000]\n",
      "loss: 3.678331  [46010/50000]\n",
      "loss: 3.717112  [47010/50000]\n",
      "loss: 3.699001  [48010/50000]\n",
      "loss: 3.699489  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 3.956822 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 3.778487  [   10/50000]\n",
      "loss: 3.773343  [ 1010/50000]\n",
      "loss: 3.681420  [ 2010/50000]\n",
      "loss: 3.686705  [ 3010/50000]\n",
      "loss: 3.677774  [ 4010/50000]\n",
      "loss: 3.689272  [ 5010/50000]\n",
      "loss: 3.693494  [ 6010/50000]\n",
      "loss: 3.678783  [ 7010/50000]\n",
      "loss: 3.682112  [ 8010/50000]\n",
      "loss: 3.906107  [ 9010/50000]\n",
      "loss: 3.674491  [10010/50000]\n",
      "loss: 3.674749  [11010/50000]\n",
      "loss: 3.689618  [12010/50000]\n",
      "loss: 3.709640  [13010/50000]\n",
      "loss: 3.702325  [14010/50000]\n",
      "loss: 3.686795  [15010/50000]\n",
      "loss: 3.682119  [16010/50000]\n",
      "loss: 3.671249  [17010/50000]\n",
      "loss: 3.712088  [18010/50000]\n",
      "loss: 3.705115  [19010/50000]\n",
      "loss: 3.683219  [20010/50000]\n",
      "loss: 3.699816  [21010/50000]\n",
      "loss: 3.685904  [22010/50000]\n",
      "loss: 3.678978  [23010/50000]\n",
      "loss: 3.863392  [24010/50000]\n",
      "loss: 3.706319  [25010/50000]\n",
      "loss: 3.717334  [26010/50000]\n",
      "loss: 3.696706  [27010/50000]\n",
      "loss: 3.778690  [28010/50000]\n",
      "loss: 3.673419  [29010/50000]\n",
      "loss: 3.681152  [30010/50000]\n",
      "loss: 3.736209  [31010/50000]\n",
      "loss: 3.723008  [32010/50000]\n",
      "loss: 3.690793  [33010/50000]\n",
      "loss: 3.707886  [34010/50000]\n",
      "loss: 3.678369  [35010/50000]\n",
      "loss: 3.886365  [36010/50000]\n",
      "loss: 3.893133  [37010/50000]\n",
      "loss: 3.704840  [38010/50000]\n",
      "loss: 3.726756  [39010/50000]\n",
      "loss: 3.724416  [40010/50000]\n",
      "loss: 3.776368  [41010/50000]\n",
      "loss: 3.695379  [42010/50000]\n",
      "loss: 3.709513  [43010/50000]\n",
      "loss: 3.671217  [44010/50000]\n",
      "loss: 3.680697  [45010/50000]\n",
      "loss: 3.691418  [46010/50000]\n",
      "loss: 3.691915  [47010/50000]\n",
      "loss: 3.688665  [48010/50000]\n",
      "loss: 3.749544  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 3.977987 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 3.836349  [   10/50000]\n",
      "loss: 3.791512  [ 1010/50000]\n",
      "loss: 3.678360  [ 2010/50000]\n",
      "loss: 3.699590  [ 3010/50000]\n",
      "loss: 3.765445  [ 4010/50000]\n",
      "loss: 3.846247  [ 5010/50000]\n",
      "loss: 3.714658  [ 6010/50000]\n",
      "loss: 3.675389  [ 7010/50000]\n",
      "loss: 3.675963  [ 8010/50000]\n",
      "loss: 3.693436  [ 9010/50000]\n",
      "loss: 3.680119  [10010/50000]\n",
      "loss: 3.673843  [11010/50000]\n",
      "loss: 3.684997  [12010/50000]\n",
      "loss: 3.675611  [13010/50000]\n",
      "loss: 3.678931  [14010/50000]\n",
      "loss: 3.668100  [15010/50000]\n",
      "loss: 3.679841  [16010/50000]\n",
      "loss: 3.756542  [17010/50000]\n",
      "loss: 3.782426  [18010/50000]\n",
      "loss: 3.679300  [19010/50000]\n",
      "loss: 3.672259  [20010/50000]\n",
      "loss: 3.674004  [21010/50000]\n",
      "loss: 3.687637  [22010/50000]\n",
      "loss: 3.752221  [23010/50000]\n",
      "loss: 3.752511  [24010/50000]\n",
      "loss: 3.845468  [25010/50000]\n",
      "loss: 3.676845  [26010/50000]\n",
      "loss: 3.673881  [27010/50000]\n",
      "loss: 3.664862  [28010/50000]\n",
      "loss: 3.674002  [29010/50000]\n",
      "loss: 3.696149  [30010/50000]\n",
      "loss: 3.670417  [31010/50000]\n",
      "loss: 3.689137  [32010/50000]\n",
      "loss: 3.705571  [33010/50000]\n",
      "loss: 3.676555  [34010/50000]\n",
      "loss: 3.669814  [35010/50000]\n",
      "loss: 3.783517  [36010/50000]\n",
      "loss: 3.696180  [37010/50000]\n",
      "loss: 3.756108  [38010/50000]\n",
      "loss: 3.675705  [39010/50000]\n",
      "loss: 3.687220  [40010/50000]\n",
      "loss: 3.776394  [41010/50000]\n",
      "loss: 3.773414  [42010/50000]\n",
      "loss: 3.684593  [43010/50000]\n",
      "loss: 3.713407  [44010/50000]\n",
      "loss: 3.677890  [45010/50000]\n",
      "loss: 3.680331  [46010/50000]\n",
      "loss: 3.778307  [47010/50000]\n",
      "loss: 3.674334  [48010/50000]\n",
      "loss: 3.678900  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 3.965505 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 3.872183  [   10/50000]\n",
      "loss: 3.676610  [ 1010/50000]\n",
      "loss: 3.684374  [ 2010/50000]\n",
      "loss: 3.732810  [ 3010/50000]\n",
      "loss: 3.680296  [ 4010/50000]\n",
      "loss: 3.770380  [ 5010/50000]\n",
      "loss: 3.781601  [ 6010/50000]\n",
      "loss: 3.669739  [ 7010/50000]\n",
      "loss: 3.872892  [ 8010/50000]\n",
      "loss: 3.676184  [ 9010/50000]\n",
      "loss: 3.838973  [10010/50000]\n",
      "loss: 3.777161  [11010/50000]\n",
      "loss: 3.777223  [12010/50000]\n",
      "loss: 3.691825  [13010/50000]\n",
      "loss: 3.702482  [14010/50000]\n",
      "loss: 3.681049  [15010/50000]\n",
      "loss: 3.682636  [16010/50000]\n",
      "loss: 3.866668  [17010/50000]\n",
      "loss: 3.692464  [18010/50000]\n",
      "loss: 3.675294  [19010/50000]\n",
      "loss: 3.693987  [20010/50000]\n",
      "loss: 3.668568  [21010/50000]\n",
      "loss: 3.688293  [22010/50000]\n",
      "loss: 3.702395  [23010/50000]\n",
      "loss: 3.764830  [24010/50000]\n",
      "loss: 3.675704  [25010/50000]\n",
      "loss: 3.743045  [26010/50000]\n",
      "loss: 3.819453  [27010/50000]\n",
      "loss: 3.683337  [28010/50000]\n",
      "loss: 3.673457  [29010/50000]\n",
      "loss: 3.763103  [30010/50000]\n",
      "loss: 3.688745  [31010/50000]\n",
      "loss: 3.713612  [32010/50000]\n",
      "loss: 3.680664  [33010/50000]\n",
      "loss: 3.691148  [34010/50000]\n",
      "loss: 3.681723  [35010/50000]\n",
      "loss: 3.688578  [36010/50000]\n",
      "loss: 3.771936  [37010/50000]\n",
      "loss: 3.780982  [38010/50000]\n",
      "loss: 3.759366  [39010/50000]\n",
      "loss: 3.701077  [40010/50000]\n",
      "loss: 3.684404  [41010/50000]\n",
      "loss: 3.696089  [42010/50000]\n",
      "loss: 3.730675  [43010/50000]\n",
      "loss: 3.688470  [44010/50000]\n",
      "loss: 3.778719  [45010/50000]\n",
      "loss: 3.698854  [46010/50000]\n",
      "loss: 3.680838  [47010/50000]\n",
      "loss: 3.767999  [48010/50000]\n",
      "loss: 3.751884  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 3.966891 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 3.704458  [   10/50000]\n",
      "loss: 3.681735  [ 1010/50000]\n",
      "loss: 3.728848  [ 2010/50000]\n",
      "loss: 3.683608  [ 3010/50000]\n",
      "loss: 3.697634  [ 4010/50000]\n",
      "loss: 3.715512  [ 5010/50000]\n",
      "loss: 3.686030  [ 6010/50000]\n",
      "loss: 3.688960  [ 7010/50000]\n",
      "loss: 3.678460  [ 8010/50000]\n",
      "loss: 3.677873  [ 9010/50000]\n",
      "loss: 3.684957  [10010/50000]\n",
      "loss: 3.669628  [11010/50000]\n",
      "loss: 3.871566  [12010/50000]\n",
      "loss: 3.673316  [13010/50000]\n",
      "loss: 3.700562  [14010/50000]\n",
      "loss: 3.681345  [15010/50000]\n",
      "loss: 3.739720  [16010/50000]\n",
      "loss: 3.805834  [17010/50000]\n",
      "loss: 3.753014  [18010/50000]\n",
      "loss: 3.846832  [19010/50000]\n",
      "loss: 3.686681  [20010/50000]\n",
      "loss: 3.804078  [21010/50000]\n",
      "loss: 3.702742  [22010/50000]\n",
      "loss: 3.693027  [23010/50000]\n",
      "loss: 3.671058  [24010/50000]\n",
      "loss: 3.676603  [25010/50000]\n",
      "loss: 3.684849  [26010/50000]\n",
      "loss: 3.676961  [27010/50000]\n",
      "loss: 3.780723  [28010/50000]\n",
      "loss: 3.684061  [29010/50000]\n",
      "loss: 3.686572  [30010/50000]\n",
      "loss: 3.759611  [31010/50000]\n",
      "loss: 3.726360  [32010/50000]\n",
      "loss: 3.698338  [33010/50000]\n",
      "loss: 3.800994  [34010/50000]\n",
      "loss: 3.781663  [35010/50000]\n",
      "loss: 3.678164  [36010/50000]\n",
      "loss: 3.772652  [37010/50000]\n",
      "loss: 3.700064  [38010/50000]\n",
      "loss: 3.665052  [39010/50000]\n",
      "loss: 3.777900  [40010/50000]\n",
      "loss: 3.669740  [41010/50000]\n",
      "loss: 3.673088  [42010/50000]\n",
      "loss: 3.713767  [43010/50000]\n",
      "loss: 3.702204  [44010/50000]\n",
      "loss: 3.720827  [45010/50000]\n",
      "loss: 3.689067  [46010/50000]\n",
      "loss: 3.681370  [47010/50000]\n",
      "loss: 3.750915  [48010/50000]\n",
      "loss: 3.669585  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 3.965921 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 3.783246  [   10/50000]\n",
      "loss: 3.672881  [ 1010/50000]\n",
      "loss: 3.676950  [ 2010/50000]\n",
      "loss: 3.678502  [ 3010/50000]\n",
      "loss: 3.682059  [ 4010/50000]\n",
      "loss: 3.700515  [ 5010/50000]\n",
      "loss: 3.774898  [ 6010/50000]\n",
      "loss: 3.741603  [ 7010/50000]\n",
      "loss: 3.683369  [ 8010/50000]\n",
      "loss: 3.705447  [ 9010/50000]\n",
      "loss: 3.745864  [10010/50000]\n",
      "loss: 3.675766  [11010/50000]\n",
      "loss: 3.690528  [12010/50000]\n",
      "loss: 3.683024  [13010/50000]\n",
      "loss: 3.766134  [14010/50000]\n",
      "loss: 3.797278  [15010/50000]\n",
      "loss: 3.850085  [16010/50000]\n",
      "loss: 3.676936  [17010/50000]\n",
      "loss: 3.676232  [18010/50000]\n",
      "loss: 3.706123  [19010/50000]\n",
      "loss: 3.688873  [20010/50000]\n",
      "loss: 3.769512  [21010/50000]\n",
      "loss: 3.682667  [22010/50000]\n",
      "loss: 3.665963  [23010/50000]\n",
      "loss: 3.672561  [24010/50000]\n",
      "loss: 3.777854  [25010/50000]\n",
      "loss: 3.785077  [26010/50000]\n",
      "loss: 3.674782  [27010/50000]\n",
      "loss: 3.814251  [28010/50000]\n",
      "loss: 3.676150  [29010/50000]\n",
      "loss: 3.689980  [30010/50000]\n",
      "loss: 3.678457  [31010/50000]\n",
      "loss: 3.702569  [32010/50000]\n",
      "loss: 3.673583  [33010/50000]\n",
      "loss: 3.680822  [34010/50000]\n",
      "loss: 3.702465  [35010/50000]\n",
      "loss: 3.666583  [36010/50000]\n",
      "loss: 3.775661  [37010/50000]\n",
      "loss: 3.677026  [38010/50000]\n",
      "loss: 3.759037  [39010/50000]\n",
      "loss: 3.740165  [40010/50000]\n",
      "loss: 3.700498  [41010/50000]\n",
      "loss: 3.670789  [42010/50000]\n",
      "loss: 3.667565  [43010/50000]\n",
      "loss: 3.771821  [44010/50000]\n",
      "loss: 3.719718  [45010/50000]\n",
      "loss: 3.804242  [46010/50000]\n",
      "loss: 3.786575  [47010/50000]\n",
      "loss: 3.797255  [48010/50000]\n",
      "loss: 3.675635  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 3.974767 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 3.678410  [   10/50000]\n",
      "loss: 3.678996  [ 1010/50000]\n",
      "loss: 3.723464  [ 2010/50000]\n",
      "loss: 3.677968  [ 3010/50000]\n",
      "loss: 3.664248  [ 4010/50000]\n",
      "loss: 3.686189  [ 5010/50000]\n",
      "loss: 3.706923  [ 6010/50000]\n",
      "loss: 3.671717  [ 7010/50000]\n",
      "loss: 3.789855  [ 8010/50000]\n",
      "loss: 3.692136  [ 9010/50000]\n",
      "loss: 3.670233  [10010/50000]\n",
      "loss: 3.693521  [11010/50000]\n",
      "loss: 3.672716  [12010/50000]\n",
      "loss: 3.710386  [13010/50000]\n",
      "loss: 3.773724  [14010/50000]\n",
      "loss: 3.684421  [15010/50000]\n",
      "loss: 3.659390  [16010/50000]\n",
      "loss: 3.787666  [17010/50000]\n",
      "loss: 3.713689  [18010/50000]\n",
      "loss: 3.681004  [19010/50000]\n",
      "loss: 3.676112  [20010/50000]\n",
      "loss: 3.679670  [21010/50000]\n",
      "loss: 3.711990  [22010/50000]\n",
      "loss: 3.674952  [23010/50000]\n",
      "loss: 3.754199  [24010/50000]\n",
      "loss: 3.681711  [25010/50000]\n",
      "loss: 3.812024  [26010/50000]\n",
      "loss: 3.690677  [27010/50000]\n",
      "loss: 3.673497  [28010/50000]\n",
      "loss: 3.697428  [29010/50000]\n",
      "loss: 3.704755  [30010/50000]\n",
      "loss: 3.716844  [31010/50000]\n",
      "loss: 3.835628  [32010/50000]\n",
      "loss: 3.777634  [33010/50000]\n",
      "loss: 3.778160  [34010/50000]\n",
      "loss: 3.677442  [35010/50000]\n",
      "loss: 3.673806  [36010/50000]\n",
      "loss: 3.689161  [37010/50000]\n",
      "loss: 3.679022  [38010/50000]\n",
      "loss: 3.693426  [39010/50000]\n",
      "loss: 3.691086  [40010/50000]\n",
      "loss: 3.757793  [41010/50000]\n",
      "loss: 3.687394  [42010/50000]\n",
      "loss: 3.750093  [43010/50000]\n",
      "loss: 3.694743  [44010/50000]\n",
      "loss: 3.684910  [45010/50000]\n",
      "loss: 3.678256  [46010/50000]\n",
      "loss: 3.702196  [47010/50000]\n",
      "loss: 3.788463  [48010/50000]\n",
      "loss: 3.698029  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 3.966558 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 3.757862  [   10/50000]\n",
      "loss: 3.679291  [ 1010/50000]\n",
      "loss: 3.664652  [ 2010/50000]\n",
      "loss: 3.677593  [ 3010/50000]\n",
      "loss: 3.776729  [ 4010/50000]\n",
      "loss: 3.685984  [ 5010/50000]\n",
      "loss: 3.679748  [ 6010/50000]\n",
      "loss: 3.673487  [ 7010/50000]\n",
      "loss: 3.687060  [ 8010/50000]\n",
      "loss: 3.669823  [ 9010/50000]\n",
      "loss: 3.772656  [10010/50000]\n",
      "loss: 3.667641  [11010/50000]\n",
      "loss: 3.859308  [12010/50000]\n",
      "loss: 3.677289  [13010/50000]\n",
      "loss: 3.700188  [14010/50000]\n",
      "loss: 3.698106  [15010/50000]\n",
      "loss: 3.685834  [16010/50000]\n",
      "loss: 3.751345  [17010/50000]\n",
      "loss: 3.698573  [18010/50000]\n",
      "loss: 3.687167  [19010/50000]\n",
      "loss: 3.692775  [20010/50000]\n",
      "loss: 3.675428  [21010/50000]\n",
      "loss: 3.702457  [22010/50000]\n",
      "loss: 3.778373  [23010/50000]\n",
      "loss: 3.674886  [24010/50000]\n",
      "loss: 3.669800  [25010/50000]\n",
      "loss: 3.693138  [26010/50000]\n",
      "loss: 3.755305  [27010/50000]\n",
      "loss: 3.687365  [28010/50000]\n",
      "loss: 3.711713  [29010/50000]\n",
      "loss: 3.680855  [30010/50000]\n",
      "loss: 3.698272  [31010/50000]\n",
      "loss: 3.686734  [32010/50000]\n",
      "loss: 3.773415  [33010/50000]\n",
      "loss: 3.708262  [34010/50000]\n",
      "loss: 3.679747  [35010/50000]\n",
      "loss: 3.786489  [36010/50000]\n",
      "loss: 3.703049  [37010/50000]\n",
      "loss: 3.681037  [38010/50000]\n",
      "loss: 3.673159  [39010/50000]\n",
      "loss: 3.706103  [40010/50000]\n",
      "loss: 3.778557  [41010/50000]\n",
      "loss: 3.675237  [42010/50000]\n",
      "loss: 3.776464  [43010/50000]\n",
      "loss: 3.688146  [44010/50000]\n",
      "loss: 3.672257  [45010/50000]\n",
      "loss: 3.863002  [46010/50000]\n",
      "loss: 3.680142  [47010/50000]\n",
      "loss: 3.662376  [48010/50000]\n",
      "loss: 3.678650  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.7%, Avg loss: 3.972753 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 3.689931  [   10/50000]\n",
      "loss: 3.674318  [ 1010/50000]\n",
      "loss: 3.683732  [ 2010/50000]\n",
      "loss: 3.674362  [ 3010/50000]\n",
      "loss: 3.706818  [ 4010/50000]\n",
      "loss: 3.681852  [ 5010/50000]\n",
      "loss: 3.675960  [ 6010/50000]\n",
      "loss: 3.679835  [ 7010/50000]\n",
      "loss: 3.683673  [ 8010/50000]\n",
      "loss: 3.670736  [ 9010/50000]\n",
      "loss: 3.672211  [10010/50000]\n",
      "loss: 3.713459  [11010/50000]\n",
      "loss: 3.667357  [12010/50000]\n",
      "loss: 3.776644  [13010/50000]\n",
      "loss: 3.748955  [14010/50000]\n",
      "loss: 3.662727  [15010/50000]\n",
      "loss: 3.682839  [16010/50000]\n",
      "loss: 3.668885  [17010/50000]\n",
      "loss: 3.689381  [18010/50000]\n",
      "loss: 3.762518  [19010/50000]\n",
      "loss: 3.682886  [20010/50000]\n",
      "loss: 3.728287  [21010/50000]\n",
      "loss: 3.866352  [22010/50000]\n",
      "loss: 3.787527  [23010/50000]\n",
      "loss: 3.691806  [24010/50000]\n",
      "loss: 3.673490  [25010/50000]\n",
      "loss: 3.704323  [26010/50000]\n",
      "loss: 3.665113  [27010/50000]\n",
      "loss: 3.678935  [28010/50000]\n",
      "loss: 3.769414  [29010/50000]\n",
      "loss: 3.730365  [30010/50000]\n",
      "loss: 3.667426  [31010/50000]\n",
      "loss: 3.692735  [32010/50000]\n",
      "loss: 3.785175  [33010/50000]\n",
      "loss: 3.779994  [34010/50000]\n",
      "loss: 3.778936  [35010/50000]\n",
      "loss: 3.674885  [36010/50000]\n",
      "loss: 3.674351  [37010/50000]\n",
      "loss: 3.749143  [38010/50000]\n",
      "loss: 3.705070  [39010/50000]\n",
      "loss: 3.699772  [40010/50000]\n",
      "loss: 3.674985  [41010/50000]\n",
      "loss: 3.669080  [42010/50000]\n",
      "loss: 3.679547  [43010/50000]\n",
      "loss: 3.682173  [44010/50000]\n",
      "loss: 3.778985  [45010/50000]\n",
      "loss: 3.783515  [46010/50000]\n",
      "loss: 3.866035  [47010/50000]\n",
      "loss: 3.678889  [48010/50000]\n",
      "loss: 3.677923  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 3.968432 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 3.676502  [   10/50000]\n",
      "loss: 3.676702  [ 1010/50000]\n",
      "loss: 3.881375  [ 2010/50000]\n",
      "loss: 3.677248  [ 3010/50000]\n",
      "loss: 3.680283  [ 4010/50000]\n",
      "loss: 3.685375  [ 5010/50000]\n",
      "loss: 3.661021  [ 6010/50000]\n",
      "loss: 3.721905  [ 7010/50000]\n",
      "loss: 3.719158  [ 8010/50000]\n",
      "loss: 3.678097  [ 9010/50000]\n",
      "loss: 3.673408  [10010/50000]\n",
      "loss: 3.667228  [11010/50000]\n",
      "loss: 3.666907  [12010/50000]\n",
      "loss: 3.684188  [13010/50000]\n",
      "loss: 3.667077  [14010/50000]\n",
      "loss: 3.685525  [15010/50000]\n",
      "loss: 3.758599  [16010/50000]\n",
      "loss: 3.700053  [17010/50000]\n",
      "loss: 3.670873  [18010/50000]\n",
      "loss: 3.688652  [19010/50000]\n",
      "loss: 3.681938  [20010/50000]\n",
      "loss: 3.772931  [21010/50000]\n",
      "loss: 3.677068  [22010/50000]\n",
      "loss: 3.675339  [23010/50000]\n",
      "loss: 3.781551  [24010/50000]\n",
      "loss: 3.764125  [25010/50000]\n",
      "loss: 3.766320  [26010/50000]\n",
      "loss: 3.855918  [27010/50000]\n",
      "loss: 3.754036  [28010/50000]\n",
      "loss: 3.663193  [29010/50000]\n",
      "loss: 3.664616  [30010/50000]\n",
      "loss: 3.679649  [31010/50000]\n",
      "loss: 3.724061  [32010/50000]\n",
      "loss: 3.715970  [33010/50000]\n",
      "loss: 3.672693  [34010/50000]\n",
      "loss: 3.671432  [35010/50000]\n",
      "loss: 3.672756  [36010/50000]\n",
      "loss: 3.676601  [37010/50000]\n",
      "loss: 3.777101  [38010/50000]\n",
      "loss: 3.704935  [39010/50000]\n",
      "loss: 3.679955  [40010/50000]\n",
      "loss: 3.686368  [41010/50000]\n",
      "loss: 3.691086  [42010/50000]\n",
      "loss: 3.676443  [43010/50000]\n",
      "loss: 3.731995  [44010/50000]\n",
      "loss: 3.755119  [45010/50000]\n",
      "loss: 3.726382  [46010/50000]\n",
      "loss: 3.722755  [47010/50000]\n",
      "loss: 3.674332  [48010/50000]\n",
      "loss: 3.703728  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 3.975183 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 3.680832  [   10/50000]\n",
      "loss: 3.857903  [ 1010/50000]\n",
      "loss: 3.773934  [ 2010/50000]\n",
      "loss: 3.752424  [ 3010/50000]\n",
      "loss: 3.669170  [ 4010/50000]\n",
      "loss: 3.669173  [ 5010/50000]\n",
      "loss: 3.665852  [ 6010/50000]\n",
      "loss: 3.661853  [ 7010/50000]\n",
      "loss: 3.702309  [ 8010/50000]\n",
      "loss: 3.674739  [ 9010/50000]\n",
      "loss: 3.675412  [10010/50000]\n",
      "loss: 3.672119  [11010/50000]\n",
      "loss: 3.691338  [12010/50000]\n",
      "loss: 3.688409  [13010/50000]\n",
      "loss: 3.772926  [14010/50000]\n",
      "loss: 3.667665  [15010/50000]\n",
      "loss: 3.688597  [16010/50000]\n",
      "loss: 3.704423  [17010/50000]\n",
      "loss: 3.680053  [18010/50000]\n",
      "loss: 3.669795  [19010/50000]\n",
      "loss: 3.865319  [20010/50000]\n",
      "loss: 3.688309  [21010/50000]\n",
      "loss: 3.676546  [22010/50000]\n",
      "loss: 3.678962  [23010/50000]\n",
      "loss: 3.673351  [24010/50000]\n",
      "loss: 3.661969  [25010/50000]\n",
      "loss: 3.720479  [26010/50000]\n",
      "loss: 3.779963  [27010/50000]\n",
      "loss: 3.679568  [28010/50000]\n",
      "loss: 3.680738  [29010/50000]\n",
      "loss: 3.666535  [30010/50000]\n",
      "loss: 3.792269  [31010/50000]\n",
      "loss: 3.720424  [32010/50000]\n",
      "loss: 3.673302  [33010/50000]\n",
      "loss: 3.682297  [34010/50000]\n",
      "loss: 3.669218  [35010/50000]\n",
      "loss: 3.673976  [36010/50000]\n",
      "loss: 3.690423  [37010/50000]\n",
      "loss: 3.728658  [38010/50000]\n",
      "loss: 3.671207  [39010/50000]\n",
      "loss: 3.754937  [40010/50000]\n",
      "loss: 3.691786  [41010/50000]\n",
      "loss: 3.879860  [42010/50000]\n",
      "loss: 3.697939  [43010/50000]\n",
      "loss: 3.675070  [44010/50000]\n",
      "loss: 3.686583  [45010/50000]\n",
      "loss: 3.701928  [46010/50000]\n",
      "loss: 3.678170  [47010/50000]\n",
      "loss: 3.788241  [48010/50000]\n",
      "loss: 3.683427  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 3.973616 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 3.703516  [   10/50000]\n",
      "loss: 3.742138  [ 1010/50000]\n",
      "loss: 3.668370  [ 2010/50000]\n",
      "loss: 3.667795  [ 3010/50000]\n",
      "loss: 3.848766  [ 4010/50000]\n",
      "loss: 3.704565  [ 5010/50000]\n",
      "loss: 3.689262  [ 6010/50000]\n",
      "loss: 3.668941  [ 7010/50000]\n",
      "loss: 3.674860  [ 8010/50000]\n",
      "loss: 3.662779  [ 9010/50000]\n",
      "loss: 3.685698  [10010/50000]\n",
      "loss: 3.693059  [11010/50000]\n",
      "loss: 3.667336  [12010/50000]\n",
      "loss: 3.700848  [13010/50000]\n",
      "loss: 3.678743  [14010/50000]\n",
      "loss: 3.679551  [15010/50000]\n",
      "loss: 3.680976  [16010/50000]\n",
      "loss: 3.670928  [17010/50000]\n",
      "loss: 3.676498  [18010/50000]\n",
      "loss: 3.677515  [19010/50000]\n",
      "loss: 3.676288  [20010/50000]\n",
      "loss: 3.776101  [21010/50000]\n",
      "loss: 3.681668  [22010/50000]\n",
      "loss: 3.666404  [23010/50000]\n",
      "loss: 3.679018  [24010/50000]\n",
      "loss: 3.769475  [25010/50000]\n",
      "loss: 3.688565  [26010/50000]\n",
      "loss: 3.694442  [27010/50000]\n",
      "loss: 3.665124  [28010/50000]\n",
      "loss: 3.683917  [29010/50000]\n",
      "loss: 3.670497  [30010/50000]\n",
      "loss: 3.673606  [31010/50000]\n",
      "loss: 3.762621  [32010/50000]\n",
      "loss: 3.694721  [33010/50000]\n",
      "loss: 3.675267  [34010/50000]\n",
      "loss: 3.673674  [35010/50000]\n",
      "loss: 3.741241  [36010/50000]\n",
      "loss: 3.769999  [37010/50000]\n",
      "loss: 3.655028  [38010/50000]\n",
      "loss: 3.669694  [39010/50000]\n",
      "loss: 3.686907  [40010/50000]\n",
      "loss: 3.718070  [41010/50000]\n",
      "loss: 3.684792  [42010/50000]\n",
      "loss: 3.689746  [43010/50000]\n",
      "loss: 3.743587  [44010/50000]\n",
      "loss: 3.707312  [45010/50000]\n",
      "loss: 3.687758  [46010/50000]\n",
      "loss: 3.690847  [47010/50000]\n",
      "loss: 3.737752  [48010/50000]\n",
      "loss: 3.688894  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 3.976572 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 3.670082  [   10/50000]\n",
      "loss: 3.673543  [ 1010/50000]\n",
      "loss: 3.782700  [ 2010/50000]\n",
      "loss: 3.725000  [ 3010/50000]\n",
      "loss: 3.672847  [ 4010/50000]\n",
      "loss: 3.780476  [ 5010/50000]\n",
      "loss: 3.664001  [ 6010/50000]\n",
      "loss: 3.690457  [ 7010/50000]\n",
      "loss: 3.683809  [ 8010/50000]\n",
      "loss: 3.669529  [ 9010/50000]\n",
      "loss: 3.667762  [10010/50000]\n",
      "loss: 3.674454  [11010/50000]\n",
      "loss: 3.678545  [12010/50000]\n",
      "loss: 3.683358  [13010/50000]\n",
      "loss: 3.658515  [14010/50000]\n",
      "loss: 3.761053  [15010/50000]\n",
      "loss: 3.676754  [16010/50000]\n",
      "loss: 3.772079  [17010/50000]\n",
      "loss: 3.670141  [18010/50000]\n",
      "loss: 3.774860  [19010/50000]\n",
      "loss: 3.670970  [20010/50000]\n",
      "loss: 3.757661  [21010/50000]\n",
      "loss: 3.675887  [22010/50000]\n",
      "loss: 3.751734  [23010/50000]\n",
      "loss: 3.700437  [24010/50000]\n",
      "loss: 3.786391  [25010/50000]\n",
      "loss: 3.678491  [26010/50000]\n",
      "loss: 3.721164  [27010/50000]\n",
      "loss: 3.761311  [28010/50000]\n",
      "loss: 3.686641  [29010/50000]\n",
      "loss: 3.665462  [30010/50000]\n",
      "loss: 3.691458  [31010/50000]\n",
      "loss: 3.680539  [32010/50000]\n",
      "loss: 3.667484  [33010/50000]\n",
      "loss: 3.697982  [34010/50000]\n",
      "loss: 3.681014  [35010/50000]\n",
      "loss: 3.668329  [36010/50000]\n",
      "loss: 3.783672  [37010/50000]\n",
      "loss: 3.677213  [38010/50000]\n",
      "loss: 3.877131  [39010/50000]\n",
      "loss: 3.670557  [40010/50000]\n",
      "loss: 3.767962  [41010/50000]\n",
      "loss: 3.719915  [42010/50000]\n",
      "loss: 3.769210  [43010/50000]\n",
      "loss: 3.681200  [44010/50000]\n",
      "loss: 3.683731  [45010/50000]\n",
      "loss: 3.708565  [46010/50000]\n",
      "loss: 3.695587  [47010/50000]\n",
      "loss: 3.807828  [48010/50000]\n",
      "loss: 3.673644  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 3.977777 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 3.717744  [   10/50000]\n",
      "loss: 3.668383  [ 1010/50000]\n",
      "loss: 3.693238  [ 2010/50000]\n",
      "loss: 3.664249  [ 3010/50000]\n",
      "loss: 3.671859  [ 4010/50000]\n",
      "loss: 3.674383  [ 5010/50000]\n",
      "loss: 3.665850  [ 6010/50000]\n",
      "loss: 3.672149  [ 7010/50000]\n",
      "loss: 3.665831  [ 8010/50000]\n",
      "loss: 3.692799  [ 9010/50000]\n",
      "loss: 3.674996  [10010/50000]\n",
      "loss: 3.746274  [11010/50000]\n",
      "loss: 3.666913  [12010/50000]\n",
      "loss: 3.671355  [13010/50000]\n",
      "loss: 3.669391  [14010/50000]\n",
      "loss: 3.672290  [15010/50000]\n",
      "loss: 3.733740  [16010/50000]\n",
      "loss: 3.820001  [17010/50000]\n",
      "loss: 3.770813  [18010/50000]\n",
      "loss: 3.681587  [19010/50000]\n",
      "loss: 3.669433  [20010/50000]\n",
      "loss: 3.676293  [21010/50000]\n",
      "loss: 3.692509  [22010/50000]\n",
      "loss: 3.661362  [23010/50000]\n",
      "loss: 3.668339  [24010/50000]\n",
      "loss: 3.671708  [25010/50000]\n",
      "loss: 3.675973  [26010/50000]\n",
      "loss: 3.679018  [27010/50000]\n",
      "loss: 3.716473  [28010/50000]\n",
      "loss: 3.684928  [29010/50000]\n",
      "loss: 3.664134  [30010/50000]\n",
      "loss: 3.675460  [31010/50000]\n",
      "loss: 3.873305  [32010/50000]\n",
      "loss: 3.667991  [33010/50000]\n",
      "loss: 3.668975  [34010/50000]\n",
      "loss: 3.671883  [35010/50000]\n",
      "loss: 3.685719  [36010/50000]\n",
      "loss: 3.663428  [37010/50000]\n",
      "loss: 3.675515  [38010/50000]\n",
      "loss: 3.695824  [39010/50000]\n",
      "loss: 3.667493  [40010/50000]\n",
      "loss: 3.770288  [41010/50000]\n",
      "loss: 3.684412  [42010/50000]\n",
      "loss: 3.742344  [43010/50000]\n",
      "loss: 3.670379  [44010/50000]\n",
      "loss: 3.678244  [45010/50000]\n",
      "loss: 3.784960  [46010/50000]\n",
      "loss: 3.684561  [47010/50000]\n",
      "loss: 3.665349  [48010/50000]\n",
      "loss: 3.674234  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 3.985797 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 3.693813  [   10/50000]\n",
      "loss: 3.676062  [ 1010/50000]\n",
      "loss: 3.674521  [ 2010/50000]\n",
      "loss: 3.763918  [ 3010/50000]\n",
      "loss: 3.660340  [ 4010/50000]\n",
      "loss: 3.771700  [ 5010/50000]\n",
      "loss: 3.768541  [ 6010/50000]\n",
      "loss: 3.662070  [ 7010/50000]\n",
      "loss: 3.665286  [ 8010/50000]\n",
      "loss: 3.717485  [ 9010/50000]\n",
      "loss: 3.687302  [10010/50000]\n",
      "loss: 3.675711  [11010/50000]\n",
      "loss: 3.672910  [12010/50000]\n",
      "loss: 3.791286  [13010/50000]\n",
      "loss: 3.692591  [14010/50000]\n",
      "loss: 3.671649  [15010/50000]\n",
      "loss: 3.677196  [16010/50000]\n",
      "loss: 3.760867  [17010/50000]\n",
      "loss: 3.663692  [18010/50000]\n",
      "loss: 3.765512  [19010/50000]\n",
      "loss: 3.665555  [20010/50000]\n",
      "loss: 3.668012  [21010/50000]\n",
      "loss: 3.666618  [22010/50000]\n",
      "loss: 3.658229  [23010/50000]\n",
      "loss: 3.663132  [24010/50000]\n",
      "loss: 3.663950  [25010/50000]\n",
      "loss: 3.828875  [26010/50000]\n",
      "loss: 3.671761  [27010/50000]\n",
      "loss: 3.666233  [28010/50000]\n",
      "loss: 3.670378  [29010/50000]\n",
      "loss: 3.704161  [30010/50000]\n",
      "loss: 3.670889  [31010/50000]\n",
      "loss: 3.673072  [32010/50000]\n",
      "loss: 3.670150  [33010/50000]\n",
      "loss: 3.673761  [34010/50000]\n",
      "loss: 3.683370  [35010/50000]\n",
      "loss: 3.658259  [36010/50000]\n",
      "loss: 3.668236  [37010/50000]\n",
      "loss: 3.670886  [38010/50000]\n",
      "loss: 3.740388  [39010/50000]\n",
      "loss: 3.714359  [40010/50000]\n",
      "loss: 3.686766  [41010/50000]\n",
      "loss: 3.677829  [42010/50000]\n",
      "loss: 3.666143  [43010/50000]\n",
      "loss: 3.691407  [44010/50000]\n",
      "loss: 3.671007  [45010/50000]\n",
      "loss: 3.719463  [46010/50000]\n",
      "loss: 3.667525  [47010/50000]\n",
      "loss: 3.673466  [48010/50000]\n",
      "loss: 3.681661  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 3.978214 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 3.692059  [   10/50000]\n",
      "loss: 3.671272  [ 1010/50000]\n",
      "loss: 3.739381  [ 2010/50000]\n",
      "loss: 3.700230  [ 3010/50000]\n",
      "loss: 3.702452  [ 4010/50000]\n",
      "loss: 3.672124  [ 5010/50000]\n",
      "loss: 3.705670  [ 6010/50000]\n",
      "loss: 3.673894  [ 7010/50000]\n",
      "loss: 3.686174  [ 8010/50000]\n",
      "loss: 3.761497  [ 9010/50000]\n",
      "loss: 3.740931  [10010/50000]\n",
      "loss: 3.673978  [11010/50000]\n",
      "loss: 3.679409  [12010/50000]\n",
      "loss: 3.679488  [13010/50000]\n",
      "loss: 3.685671  [14010/50000]\n",
      "loss: 3.683441  [15010/50000]\n",
      "loss: 3.769368  [16010/50000]\n",
      "loss: 3.767071  [17010/50000]\n",
      "loss: 3.768789  [18010/50000]\n",
      "loss: 3.680435  [19010/50000]\n",
      "loss: 3.676590  [20010/50000]\n",
      "loss: 3.675285  [21010/50000]\n",
      "loss: 3.770769  [22010/50000]\n",
      "loss: 3.664877  [23010/50000]\n",
      "loss: 3.674103  [24010/50000]\n",
      "loss: 3.672532  [25010/50000]\n",
      "loss: 3.668210  [26010/50000]\n",
      "loss: 3.674474  [27010/50000]\n",
      "loss: 3.668597  [28010/50000]\n",
      "loss: 3.778732  [29010/50000]\n",
      "loss: 3.702179  [30010/50000]\n",
      "loss: 3.789160  [31010/50000]\n",
      "loss: 3.685369  [32010/50000]\n",
      "loss: 3.720703  [33010/50000]\n",
      "loss: 3.666632  [34010/50000]\n",
      "loss: 3.662600  [35010/50000]\n",
      "loss: 3.662359  [36010/50000]\n",
      "loss: 3.673632  [37010/50000]\n",
      "loss: 3.677898  [38010/50000]\n",
      "loss: 3.674393  [39010/50000]\n",
      "loss: 3.669576  [40010/50000]\n",
      "loss: 3.726604  [41010/50000]\n",
      "loss: 3.687728  [42010/50000]\n",
      "loss: 3.792192  [43010/50000]\n",
      "loss: 3.670714  [44010/50000]\n",
      "loss: 3.683371  [45010/50000]\n",
      "loss: 3.666272  [46010/50000]\n",
      "loss: 3.764543  [47010/50000]\n",
      "loss: 3.702588  [48010/50000]\n",
      "loss: 3.678242  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 3.983977 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 3.672292  [   10/50000]\n",
      "loss: 3.670978  [ 1010/50000]\n",
      "loss: 3.748950  [ 2010/50000]\n",
      "loss: 3.689723  [ 3010/50000]\n",
      "loss: 3.669825  [ 4010/50000]\n",
      "loss: 3.667842  [ 5010/50000]\n",
      "loss: 3.711380  [ 6010/50000]\n",
      "loss: 3.675935  [ 7010/50000]\n",
      "loss: 3.783324  [ 8010/50000]\n",
      "loss: 3.671068  [ 9010/50000]\n",
      "loss: 3.662152  [10010/50000]\n",
      "loss: 3.673085  [11010/50000]\n",
      "loss: 3.766109  [12010/50000]\n",
      "loss: 3.666515  [13010/50000]\n",
      "loss: 3.675878  [14010/50000]\n",
      "loss: 3.676222  [15010/50000]\n",
      "loss: 3.662952  [16010/50000]\n",
      "loss: 3.840460  [17010/50000]\n",
      "loss: 3.703222  [18010/50000]\n",
      "loss: 3.754645  [19010/50000]\n",
      "loss: 3.678576  [20010/50000]\n",
      "loss: 3.791124  [21010/50000]\n",
      "loss: 3.663655  [22010/50000]\n",
      "loss: 3.666348  [23010/50000]\n",
      "loss: 3.665651  [24010/50000]\n",
      "loss: 3.674554  [25010/50000]\n",
      "loss: 3.671895  [26010/50000]\n",
      "loss: 3.664206  [27010/50000]\n",
      "loss: 3.677821  [28010/50000]\n",
      "loss: 3.673871  [29010/50000]\n",
      "loss: 3.724718  [30010/50000]\n",
      "loss: 3.680732  [31010/50000]\n",
      "loss: 3.700504  [32010/50000]\n",
      "loss: 3.761787  [33010/50000]\n",
      "loss: 3.670200  [34010/50000]\n",
      "loss: 3.660584  [35010/50000]\n",
      "loss: 3.664468  [36010/50000]\n",
      "loss: 3.669010  [37010/50000]\n",
      "loss: 3.665328  [38010/50000]\n",
      "loss: 3.671436  [39010/50000]\n",
      "loss: 3.682066  [40010/50000]\n",
      "loss: 3.679587  [41010/50000]\n",
      "loss: 3.657788  [42010/50000]\n",
      "loss: 3.685516  [43010/50000]\n",
      "loss: 3.774662  [44010/50000]\n",
      "loss: 3.668403  [45010/50000]\n",
      "loss: 3.721090  [46010/50000]\n",
      "loss: 3.665953  [47010/50000]\n",
      "loss: 3.780906  [48010/50000]\n",
      "loss: 3.667929  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 3.981435 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 3.666798  [   10/50000]\n",
      "loss: 3.661093  [ 1010/50000]\n",
      "loss: 3.666625  [ 2010/50000]\n",
      "loss: 3.683445  [ 3010/50000]\n",
      "loss: 3.698644  [ 4010/50000]\n",
      "loss: 3.699811  [ 5010/50000]\n",
      "loss: 3.782983  [ 6010/50000]\n",
      "loss: 3.674410  [ 7010/50000]\n",
      "loss: 3.764874  [ 8010/50000]\n",
      "loss: 3.673349  [ 9010/50000]\n",
      "loss: 3.688529  [10010/50000]\n",
      "loss: 3.667948  [11010/50000]\n",
      "loss: 3.687141  [12010/50000]\n",
      "loss: 3.722882  [13010/50000]\n",
      "loss: 3.667043  [14010/50000]\n",
      "loss: 3.665581  [15010/50000]\n",
      "loss: 3.673210  [16010/50000]\n",
      "loss: 3.681611  [17010/50000]\n",
      "loss: 3.667915  [18010/50000]\n",
      "loss: 3.762307  [19010/50000]\n",
      "loss: 3.668859  [20010/50000]\n",
      "loss: 3.672300  [21010/50000]\n",
      "loss: 3.671532  [22010/50000]\n",
      "loss: 3.769513  [23010/50000]\n",
      "loss: 3.692270  [24010/50000]\n",
      "loss: 3.685468  [25010/50000]\n",
      "loss: 3.670547  [26010/50000]\n",
      "loss: 3.688230  [27010/50000]\n",
      "loss: 3.798993  [28010/50000]\n",
      "loss: 3.780641  [29010/50000]\n",
      "loss: 3.782350  [30010/50000]\n",
      "loss: 3.673655  [31010/50000]\n",
      "loss: 3.673417  [32010/50000]\n",
      "loss: 3.675058  [33010/50000]\n",
      "loss: 3.711718  [34010/50000]\n",
      "loss: 3.673321  [35010/50000]\n",
      "loss: 3.677352  [36010/50000]\n",
      "loss: 3.695140  [37010/50000]\n",
      "loss: 3.678239  [38010/50000]\n",
      "loss: 3.676863  [39010/50000]\n",
      "loss: 3.688688  [40010/50000]\n",
      "loss: 3.675654  [41010/50000]\n",
      "loss: 3.681327  [42010/50000]\n",
      "loss: 3.666060  [43010/50000]\n",
      "loss: 3.708265  [44010/50000]\n",
      "loss: 3.751393  [45010/50000]\n",
      "loss: 3.678566  [46010/50000]\n",
      "loss: 3.682491  [47010/50000]\n",
      "loss: 3.681654  [48010/50000]\n",
      "loss: 3.713034  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 3.979853 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 3.701156  [   10/50000]\n",
      "loss: 3.763988  [ 1010/50000]\n",
      "loss: 3.682008  [ 2010/50000]\n",
      "loss: 3.766199  [ 3010/50000]\n",
      "loss: 3.822345  [ 4010/50000]\n",
      "loss: 3.661346  [ 5010/50000]\n",
      "loss: 3.760686  [ 6010/50000]\n",
      "loss: 3.678771  [ 7010/50000]\n",
      "loss: 3.682818  [ 8010/50000]\n",
      "loss: 3.664806  [ 9010/50000]\n",
      "loss: 3.702260  [10010/50000]\n",
      "loss: 3.676781  [11010/50000]\n",
      "loss: 3.677302  [12010/50000]\n",
      "loss: 3.666662  [13010/50000]\n",
      "loss: 3.672103  [14010/50000]\n",
      "loss: 3.664065  [15010/50000]\n",
      "loss: 3.810080  [16010/50000]\n",
      "loss: 3.662782  [17010/50000]\n",
      "loss: 3.661567  [18010/50000]\n",
      "loss: 3.659983  [19010/50000]\n",
      "loss: 3.668944  [20010/50000]\n",
      "loss: 3.867951  [21010/50000]\n",
      "loss: 3.685395  [22010/50000]\n",
      "loss: 3.700275  [23010/50000]\n",
      "loss: 3.676519  [24010/50000]\n",
      "loss: 3.857386  [25010/50000]\n",
      "loss: 3.673859  [26010/50000]\n",
      "loss: 3.671254  [27010/50000]\n",
      "loss: 3.668627  [28010/50000]\n",
      "loss: 3.662814  [29010/50000]\n",
      "loss: 3.666840  [30010/50000]\n",
      "loss: 3.753084  [31010/50000]\n",
      "loss: 3.871491  [32010/50000]\n",
      "loss: 3.768381  [33010/50000]\n",
      "loss: 3.664723  [34010/50000]\n",
      "loss: 3.722036  [35010/50000]\n",
      "loss: 3.868634  [36010/50000]\n",
      "loss: 3.675797  [37010/50000]\n",
      "loss: 3.668410  [38010/50000]\n",
      "loss: 3.663963  [39010/50000]\n",
      "loss: 3.817759  [40010/50000]\n",
      "loss: 3.760139  [41010/50000]\n",
      "loss: 3.679169  [42010/50000]\n",
      "loss: 3.679325  [43010/50000]\n",
      "loss: 3.669128  [44010/50000]\n",
      "loss: 3.674527  [45010/50000]\n",
      "loss: 3.961433  [46010/50000]\n",
      "loss: 3.669188  [47010/50000]\n",
      "loss: 3.671860  [48010/50000]\n",
      "loss: 3.659861  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 3.976519 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 3.677408  [   10/50000]\n",
      "loss: 3.665599  [ 1010/50000]\n",
      "loss: 3.802603  [ 2010/50000]\n",
      "loss: 3.705311  [ 3010/50000]\n",
      "loss: 3.665440  [ 4010/50000]\n",
      "loss: 3.663078  [ 5010/50000]\n",
      "loss: 3.680241  [ 6010/50000]\n",
      "loss: 3.665514  [ 7010/50000]\n",
      "loss: 3.666969  [ 8010/50000]\n",
      "loss: 3.655935  [ 9010/50000]\n",
      "loss: 3.734575  [10010/50000]\n",
      "loss: 3.701383  [11010/50000]\n",
      "loss: 3.667994  [12010/50000]\n",
      "loss: 3.750053  [13010/50000]\n",
      "loss: 3.660550  [14010/50000]\n",
      "loss: 3.675545  [15010/50000]\n",
      "loss: 3.676004  [16010/50000]\n",
      "loss: 3.663128  [17010/50000]\n",
      "loss: 3.668397  [18010/50000]\n",
      "loss: 3.759382  [19010/50000]\n",
      "loss: 3.672064  [20010/50000]\n",
      "loss: 3.685909  [21010/50000]\n",
      "loss: 3.673951  [22010/50000]\n",
      "loss: 3.655817  [23010/50000]\n",
      "loss: 3.739793  [24010/50000]\n",
      "loss: 3.678450  [25010/50000]\n",
      "loss: 3.678712  [26010/50000]\n",
      "loss: 3.770692  [27010/50000]\n",
      "loss: 3.767508  [28010/50000]\n",
      "loss: 3.708599  [29010/50000]\n",
      "loss: 3.674116  [30010/50000]\n",
      "loss: 3.704678  [31010/50000]\n",
      "loss: 3.665250  [32010/50000]\n",
      "loss: 3.670178  [33010/50000]\n",
      "loss: 3.672099  [34010/50000]\n",
      "loss: 3.664635  [35010/50000]\n",
      "loss: 3.672331  [36010/50000]\n",
      "loss: 3.672675  [37010/50000]\n",
      "loss: 3.673958  [38010/50000]\n",
      "loss: 3.663990  [39010/50000]\n",
      "loss: 3.753619  [40010/50000]\n",
      "loss: 3.802448  [41010/50000]\n",
      "loss: 3.666313  [42010/50000]\n",
      "loss: 3.683607  [43010/50000]\n",
      "loss: 3.659310  [44010/50000]\n",
      "loss: 3.663531  [45010/50000]\n",
      "loss: 3.681927  [46010/50000]\n",
      "loss: 3.664885  [47010/50000]\n",
      "loss: 3.713445  [48010/50000]\n",
      "loss: 3.685163  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 3.980534 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 3.665494  [   10/50000]\n",
      "loss: 3.667964  [ 1010/50000]\n",
      "loss: 3.667309  [ 2010/50000]\n",
      "loss: 3.759542  [ 3010/50000]\n",
      "loss: 3.690079  [ 4010/50000]\n",
      "loss: 3.669580  [ 5010/50000]\n",
      "loss: 3.680833  [ 6010/50000]\n",
      "loss: 3.675410  [ 7010/50000]\n",
      "loss: 3.688164  [ 8010/50000]\n",
      "loss: 3.733994  [ 9010/50000]\n",
      "loss: 3.667516  [10010/50000]\n",
      "loss: 3.750629  [11010/50000]\n",
      "loss: 3.677662  [12010/50000]\n",
      "loss: 3.678493  [13010/50000]\n",
      "loss: 3.706330  [14010/50000]\n",
      "loss: 3.811669  [15010/50000]\n",
      "loss: 3.677504  [16010/50000]\n",
      "loss: 3.773967  [17010/50000]\n",
      "loss: 3.667148  [18010/50000]\n",
      "loss: 3.649325  [19010/50000]\n",
      "loss: 3.663935  [20010/50000]\n",
      "loss: 3.768337  [21010/50000]\n",
      "loss: 3.678592  [22010/50000]\n",
      "loss: 3.707610  [23010/50000]\n",
      "loss: 3.672211  [24010/50000]\n",
      "loss: 3.660696  [25010/50000]\n",
      "loss: 3.704124  [26010/50000]\n",
      "loss: 3.667982  [27010/50000]\n",
      "loss: 3.690528  [28010/50000]\n",
      "loss: 3.723227  [29010/50000]\n",
      "loss: 3.860570  [30010/50000]\n",
      "loss: 3.675086  [31010/50000]\n",
      "loss: 3.672029  [32010/50000]\n",
      "loss: 3.670465  [33010/50000]\n",
      "loss: 3.662894  [34010/50000]\n",
      "loss: 3.669488  [35010/50000]\n",
      "loss: 3.697671  [36010/50000]\n",
      "loss: 3.665209  [37010/50000]\n",
      "loss: 3.682424  [38010/50000]\n",
      "loss: 3.673943  [39010/50000]\n",
      "loss: 3.662098  [40010/50000]\n",
      "loss: 3.661641  [41010/50000]\n",
      "loss: 3.660600  [42010/50000]\n",
      "loss: 3.691846  [43010/50000]\n",
      "loss: 3.696998  [44010/50000]\n",
      "loss: 3.749861  [45010/50000]\n",
      "loss: 3.672560  [46010/50000]\n",
      "loss: 3.691302  [47010/50000]\n",
      "loss: 3.659065  [48010/50000]\n",
      "loss: 3.674892  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 3.990924 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 3.668311  [   10/50000]\n",
      "loss: 3.661739  [ 1010/50000]\n",
      "loss: 3.664166  [ 2010/50000]\n",
      "loss: 3.665452  [ 3010/50000]\n",
      "loss: 3.677217  [ 4010/50000]\n",
      "loss: 3.756087  [ 5010/50000]\n",
      "loss: 3.688855  [ 6010/50000]\n",
      "loss: 3.659520  [ 7010/50000]\n",
      "loss: 3.655694  [ 8010/50000]\n",
      "loss: 3.660029  [ 9010/50000]\n",
      "loss: 3.698090  [10010/50000]\n",
      "loss: 3.669006  [11010/50000]\n",
      "loss: 3.660116  [12010/50000]\n",
      "loss: 3.688722  [13010/50000]\n",
      "loss: 3.680979  [14010/50000]\n",
      "loss: 3.684359  [15010/50000]\n",
      "loss: 3.664822  [16010/50000]\n",
      "loss: 3.654501  [17010/50000]\n",
      "loss: 3.668990  [18010/50000]\n",
      "loss: 3.755500  [19010/50000]\n",
      "loss: 3.674461  [20010/50000]\n",
      "loss: 3.722171  [21010/50000]\n",
      "loss: 3.665024  [22010/50000]\n",
      "loss: 3.862224  [23010/50000]\n",
      "loss: 3.666801  [24010/50000]\n",
      "loss: 3.672444  [25010/50000]\n",
      "loss: 3.660478  [26010/50000]\n",
      "loss: 3.732889  [27010/50000]\n",
      "loss: 3.672415  [28010/50000]\n",
      "loss: 3.685248  [29010/50000]\n",
      "loss: 3.667009  [30010/50000]\n",
      "loss: 3.669559  [31010/50000]\n",
      "loss: 3.707842  [32010/50000]\n",
      "loss: 3.676195  [33010/50000]\n",
      "loss: 3.667023  [34010/50000]\n",
      "loss: 3.663548  [35010/50000]\n",
      "loss: 3.698856  [36010/50000]\n",
      "loss: 3.750104  [37010/50000]\n",
      "loss: 3.675923  [38010/50000]\n",
      "loss: 3.670552  [39010/50000]\n",
      "loss: 3.779824  [40010/50000]\n",
      "loss: 3.673997  [41010/50000]\n",
      "loss: 3.665410  [42010/50000]\n",
      "loss: 3.691415  [43010/50000]\n",
      "loss: 3.705368  [44010/50000]\n",
      "loss: 3.717149  [45010/50000]\n",
      "loss: 3.668375  [46010/50000]\n",
      "loss: 3.656990  [47010/50000]\n",
      "loss: 3.669179  [48010/50000]\n",
      "loss: 3.695510  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.9%, Avg loss: 3.983960 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 3.668784  [   10/50000]\n",
      "loss: 3.660537  [ 1010/50000]\n",
      "loss: 3.674995  [ 2010/50000]\n",
      "loss: 3.759567  [ 3010/50000]\n",
      "loss: 3.776366  [ 4010/50000]\n",
      "loss: 3.828070  [ 5010/50000]\n",
      "loss: 3.681152  [ 6010/50000]\n",
      "loss: 3.690989  [ 7010/50000]\n",
      "loss: 3.661639  [ 8010/50000]\n",
      "loss: 3.670104  [ 9010/50000]\n",
      "loss: 3.666737  [10010/50000]\n",
      "loss: 3.683173  [11010/50000]\n",
      "loss: 3.673723  [12010/50000]\n",
      "loss: 3.670726  [13010/50000]\n",
      "loss: 3.677781  [14010/50000]\n",
      "loss: 3.679471  [15010/50000]\n",
      "loss: 3.666636  [16010/50000]\n",
      "loss: 3.672159  [17010/50000]\n",
      "loss: 3.669358  [18010/50000]\n",
      "loss: 3.669538  [19010/50000]\n",
      "loss: 3.669494  [20010/50000]\n",
      "loss: 3.774549  [21010/50000]\n",
      "loss: 3.667458  [22010/50000]\n",
      "loss: 3.669310  [23010/50000]\n",
      "loss: 3.664767  [24010/50000]\n",
      "loss: 3.949817  [25010/50000]\n",
      "loss: 3.685006  [26010/50000]\n",
      "loss: 3.664886  [27010/50000]\n",
      "loss: 3.668418  [28010/50000]\n",
      "loss: 3.680080  [29010/50000]\n",
      "loss: 3.677099  [30010/50000]\n",
      "loss: 3.675027  [31010/50000]\n",
      "loss: 3.677512  [32010/50000]\n",
      "loss: 3.670012  [33010/50000]\n",
      "loss: 3.666314  [34010/50000]\n",
      "loss: 3.667242  [35010/50000]\n",
      "loss: 3.674150  [36010/50000]\n",
      "loss: 3.663224  [37010/50000]\n",
      "loss: 3.679286  [38010/50000]\n",
      "loss: 3.675707  [39010/50000]\n",
      "loss: 3.665084  [40010/50000]\n",
      "loss: 3.699481  [41010/50000]\n",
      "loss: 3.662621  [42010/50000]\n",
      "loss: 3.758205  [43010/50000]\n",
      "loss: 3.717619  [44010/50000]\n",
      "loss: 3.847739  [45010/50000]\n",
      "loss: 3.661824  [46010/50000]\n",
      "loss: 3.665948  [47010/50000]\n",
      "loss: 3.672465  [48010/50000]\n",
      "loss: 3.736198  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 3.986927 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 3.768657  [   10/50000]\n",
      "loss: 3.658463  [ 1010/50000]\n",
      "loss: 3.651694  [ 2010/50000]\n",
      "loss: 3.676938  [ 3010/50000]\n",
      "loss: 3.673459  [ 4010/50000]\n",
      "loss: 3.669890  [ 5010/50000]\n",
      "loss: 3.669131  [ 6010/50000]\n",
      "loss: 3.680000  [ 7010/50000]\n",
      "loss: 3.654977  [ 8010/50000]\n",
      "loss: 3.663633  [ 9010/50000]\n",
      "loss: 3.683685  [10010/50000]\n",
      "loss: 3.760363  [11010/50000]\n",
      "loss: 3.764070  [12010/50000]\n",
      "loss: 3.825499  [13010/50000]\n",
      "loss: 3.672575  [14010/50000]\n",
      "loss: 3.660294  [15010/50000]\n",
      "loss: 3.729588  [16010/50000]\n",
      "loss: 3.749905  [17010/50000]\n",
      "loss: 3.685148  [18010/50000]\n",
      "loss: 3.675948  [19010/50000]\n",
      "loss: 3.671546  [20010/50000]\n",
      "loss: 3.673028  [21010/50000]\n",
      "loss: 3.663436  [22010/50000]\n",
      "loss: 3.658290  [23010/50000]\n",
      "loss: 3.708946  [24010/50000]\n",
      "loss: 3.662736  [25010/50000]\n",
      "loss: 3.659826  [26010/50000]\n",
      "loss: 3.672015  [27010/50000]\n",
      "loss: 3.655420  [28010/50000]\n",
      "loss: 3.700300  [29010/50000]\n",
      "loss: 3.667302  [30010/50000]\n",
      "loss: 3.769658  [31010/50000]\n",
      "loss: 3.754418  [32010/50000]\n",
      "loss: 3.743036  [33010/50000]\n",
      "loss: 3.675693  [34010/50000]\n",
      "loss: 3.661671  [35010/50000]\n",
      "loss: 3.705060  [36010/50000]\n",
      "loss: 3.703496  [37010/50000]\n",
      "loss: 3.658554  [38010/50000]\n",
      "loss: 3.711597  [39010/50000]\n",
      "loss: 3.672772  [40010/50000]\n",
      "loss: 3.753270  [41010/50000]\n",
      "loss: 3.783343  [42010/50000]\n",
      "loss: 3.670566  [43010/50000]\n",
      "loss: 3.703890  [44010/50000]\n",
      "loss: 3.670861  [45010/50000]\n",
      "loss: 3.665383  [46010/50000]\n",
      "loss: 3.677364  [47010/50000]\n",
      "loss: 3.687110  [48010/50000]\n",
      "loss: 3.658567  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 3.987005 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 3.663485  [   10/50000]\n",
      "loss: 3.662041  [ 1010/50000]\n",
      "loss: 3.660621  [ 2010/50000]\n",
      "loss: 3.652162  [ 3010/50000]\n",
      "loss: 3.678586  [ 4010/50000]\n",
      "loss: 3.668034  [ 5010/50000]\n",
      "loss: 3.655715  [ 6010/50000]\n",
      "loss: 3.679757  [ 7010/50000]\n",
      "loss: 3.674498  [ 8010/50000]\n",
      "loss: 3.661815  [ 9010/50000]\n",
      "loss: 3.723325  [10010/50000]\n",
      "loss: 3.664120  [11010/50000]\n",
      "loss: 3.683529  [12010/50000]\n",
      "loss: 3.660470  [13010/50000]\n",
      "loss: 3.666775  [14010/50000]\n",
      "loss: 3.664906  [15010/50000]\n",
      "loss: 3.656040  [16010/50000]\n",
      "loss: 3.786807  [17010/50000]\n",
      "loss: 3.697526  [18010/50000]\n",
      "loss: 3.659614  [19010/50000]\n",
      "loss: 3.710086  [20010/50000]\n",
      "loss: 3.664871  [21010/50000]\n",
      "loss: 3.657216  [22010/50000]\n",
      "loss: 3.658732  [23010/50000]\n",
      "loss: 3.656720  [24010/50000]\n",
      "loss: 3.669388  [25010/50000]\n",
      "loss: 3.665695  [26010/50000]\n",
      "loss: 3.669544  [27010/50000]\n",
      "loss: 3.664234  [28010/50000]\n",
      "loss: 3.660384  [29010/50000]\n",
      "loss: 3.674422  [30010/50000]\n",
      "loss: 3.671083  [31010/50000]\n",
      "loss: 3.712690  [32010/50000]\n",
      "loss: 3.701449  [33010/50000]\n",
      "loss: 3.671161  [34010/50000]\n",
      "loss: 3.665804  [35010/50000]\n",
      "loss: 3.670619  [36010/50000]\n",
      "loss: 3.748981  [37010/50000]\n",
      "loss: 3.661138  [38010/50000]\n",
      "loss: 3.657889  [39010/50000]\n",
      "loss: 3.669360  [40010/50000]\n",
      "loss: 3.765612  [41010/50000]\n",
      "loss: 3.665265  [42010/50000]\n",
      "loss: 3.788482  [43010/50000]\n",
      "loss: 3.669204  [44010/50000]\n",
      "loss: 3.666679  [45010/50000]\n",
      "loss: 3.685115  [46010/50000]\n",
      "loss: 3.687375  [47010/50000]\n",
      "loss: 3.662865  [48010/50000]\n",
      "loss: 3.653458  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 3.985425 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 3.686982  [   10/50000]\n",
      "loss: 3.662607  [ 1010/50000]\n",
      "loss: 3.667085  [ 2010/50000]\n",
      "loss: 3.651054  [ 3010/50000]\n",
      "loss: 3.665431  [ 4010/50000]\n",
      "loss: 3.661283  [ 5010/50000]\n",
      "loss: 3.689930  [ 6010/50000]\n",
      "loss: 3.658184  [ 7010/50000]\n",
      "loss: 3.665809  [ 8010/50000]\n",
      "loss: 3.671064  [ 9010/50000]\n",
      "loss: 3.662204  [10010/50000]\n",
      "loss: 3.668455  [11010/50000]\n",
      "loss: 3.658867  [12010/50000]\n",
      "loss: 3.657797  [13010/50000]\n",
      "loss: 3.665683  [14010/50000]\n",
      "loss: 3.669515  [15010/50000]\n",
      "loss: 3.682690  [16010/50000]\n",
      "loss: 3.670692  [17010/50000]\n",
      "loss: 3.668924  [18010/50000]\n",
      "loss: 3.669795  [19010/50000]\n",
      "loss: 3.659780  [20010/50000]\n",
      "loss: 3.674648  [21010/50000]\n",
      "loss: 3.668517  [22010/50000]\n",
      "loss: 3.657607  [23010/50000]\n",
      "loss: 3.677938  [24010/50000]\n",
      "loss: 3.772738  [25010/50000]\n",
      "loss: 3.662549  [26010/50000]\n",
      "loss: 3.659447  [27010/50000]\n",
      "loss: 3.654305  [28010/50000]\n",
      "loss: 3.664660  [29010/50000]\n",
      "loss: 3.678102  [30010/50000]\n",
      "loss: 3.775707  [31010/50000]\n",
      "loss: 3.665657  [32010/50000]\n",
      "loss: 3.675891  [33010/50000]\n",
      "loss: 3.734375  [34010/50000]\n",
      "loss: 3.724155  [35010/50000]\n",
      "loss: 3.727384  [36010/50000]\n",
      "loss: 3.678322  [37010/50000]\n",
      "loss: 3.704669  [38010/50000]\n",
      "loss: 3.678104  [39010/50000]\n",
      "loss: 3.710536  [40010/50000]\n",
      "loss: 3.715271  [41010/50000]\n",
      "loss: 3.808637  [42010/50000]\n",
      "loss: 3.666523  [43010/50000]\n",
      "loss: 3.675632  [44010/50000]\n",
      "loss: 3.659174  [45010/50000]\n",
      "loss: 3.717276  [46010/50000]\n",
      "loss: 3.672120  [47010/50000]\n",
      "loss: 3.672411  [48010/50000]\n",
      "loss: 3.767134  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 3.985067 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 3.672837  [   10/50000]\n",
      "loss: 3.662887  [ 1010/50000]\n",
      "loss: 3.658114  [ 2010/50000]\n",
      "loss: 3.660463  [ 3010/50000]\n",
      "loss: 3.651577  [ 4010/50000]\n",
      "loss: 3.659126  [ 5010/50000]\n",
      "loss: 3.662968  [ 6010/50000]\n",
      "loss: 3.664699  [ 7010/50000]\n",
      "loss: 3.666422  [ 8010/50000]\n",
      "loss: 3.660644  [ 9010/50000]\n",
      "loss: 3.716423  [10010/50000]\n",
      "loss: 3.697729  [11010/50000]\n",
      "loss: 3.658738  [12010/50000]\n",
      "loss: 3.759356  [13010/50000]\n",
      "loss: 3.694446  [14010/50000]\n",
      "loss: 3.760404  [15010/50000]\n",
      "loss: 3.758593  [16010/50000]\n",
      "loss: 3.660433  [17010/50000]\n",
      "loss: 3.664256  [18010/50000]\n",
      "loss: 3.724773  [19010/50000]\n",
      "loss: 3.799801  [20010/50000]\n",
      "loss: 3.868211  [21010/50000]\n",
      "loss: 3.665397  [22010/50000]\n",
      "loss: 3.670113  [23010/50000]\n",
      "loss: 3.666202  [24010/50000]\n",
      "loss: 3.749342  [25010/50000]\n",
      "loss: 3.772107  [26010/50000]\n",
      "loss: 3.671998  [27010/50000]\n",
      "loss: 3.670665  [28010/50000]\n",
      "loss: 3.763051  [29010/50000]\n",
      "loss: 3.673541  [30010/50000]\n",
      "loss: 3.659822  [31010/50000]\n",
      "loss: 3.776714  [32010/50000]\n",
      "loss: 3.667056  [33010/50000]\n",
      "loss: 3.668360  [34010/50000]\n",
      "loss: 3.678837  [35010/50000]\n",
      "loss: 3.772680  [36010/50000]\n",
      "loss: 3.658799  [37010/50000]\n",
      "loss: 3.767747  [38010/50000]\n",
      "loss: 3.651906  [39010/50000]\n",
      "loss: 3.653756  [40010/50000]\n",
      "loss: 3.663003  [41010/50000]\n",
      "loss: 3.661583  [42010/50000]\n",
      "loss: 3.728476  [43010/50000]\n",
      "loss: 3.664542  [44010/50000]\n",
      "loss: 3.867441  [45010/50000]\n",
      "loss: 3.676233  [46010/50000]\n",
      "loss: 3.683421  [47010/50000]\n",
      "loss: 3.659541  [48010/50000]\n",
      "loss: 3.765633  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 3.987681 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 3.662697  [   10/50000]\n",
      "loss: 3.764432  [ 1010/50000]\n",
      "loss: 3.672482  [ 2010/50000]\n",
      "loss: 3.663306  [ 3010/50000]\n",
      "loss: 3.659131  [ 4010/50000]\n",
      "loss: 3.686185  [ 5010/50000]\n",
      "loss: 3.660889  [ 6010/50000]\n",
      "loss: 3.651350  [ 7010/50000]\n",
      "loss: 3.659209  [ 8010/50000]\n",
      "loss: 3.737384  [ 9010/50000]\n",
      "loss: 3.661585  [10010/50000]\n",
      "loss: 3.710552  [11010/50000]\n",
      "loss: 3.750972  [12010/50000]\n",
      "loss: 3.666351  [13010/50000]\n",
      "loss: 3.670759  [14010/50000]\n",
      "loss: 3.662207  [15010/50000]\n",
      "loss: 3.665393  [16010/50000]\n",
      "loss: 3.665912  [17010/50000]\n",
      "loss: 3.666729  [18010/50000]\n",
      "loss: 3.708900  [19010/50000]\n",
      "loss: 3.677406  [20010/50000]\n",
      "loss: 3.762805  [21010/50000]\n",
      "loss: 3.659546  [22010/50000]\n",
      "loss: 3.664951  [23010/50000]\n",
      "loss: 3.766927  [24010/50000]\n",
      "loss: 3.664225  [25010/50000]\n",
      "loss: 3.659963  [26010/50000]\n",
      "loss: 3.675173  [27010/50000]\n",
      "loss: 3.657337  [28010/50000]\n",
      "loss: 3.668730  [29010/50000]\n",
      "loss: 3.677051  [30010/50000]\n",
      "loss: 3.664841  [31010/50000]\n",
      "loss: 3.659587  [32010/50000]\n",
      "loss: 3.662511  [33010/50000]\n",
      "loss: 3.655866  [34010/50000]\n",
      "loss: 3.660839  [35010/50000]\n",
      "loss: 3.652793  [36010/50000]\n",
      "loss: 3.662080  [37010/50000]\n",
      "loss: 3.662493  [38010/50000]\n",
      "loss: 3.755037  [39010/50000]\n",
      "loss: 3.759823  [40010/50000]\n",
      "loss: 3.667643  [41010/50000]\n",
      "loss: 3.665630  [42010/50000]\n",
      "loss: 3.704951  [43010/50000]\n",
      "loss: 3.658529  [44010/50000]\n",
      "loss: 3.676920  [45010/50000]\n",
      "loss: 3.752622  [46010/50000]\n",
      "loss: 3.666509  [47010/50000]\n",
      "loss: 3.672965  [48010/50000]\n",
      "loss: 3.710884  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 3.988598 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 3.667488  [   10/50000]\n",
      "loss: 3.697917  [ 1010/50000]\n",
      "loss: 3.669610  [ 2010/50000]\n",
      "loss: 3.656993  [ 3010/50000]\n",
      "loss: 3.654530  [ 4010/50000]\n",
      "loss: 3.675784  [ 5010/50000]\n",
      "loss: 3.667684  [ 6010/50000]\n",
      "loss: 3.726041  [ 7010/50000]\n",
      "loss: 3.649171  [ 8010/50000]\n",
      "loss: 3.662281  [ 9010/50000]\n",
      "loss: 3.649291  [10010/50000]\n",
      "loss: 3.657685  [11010/50000]\n",
      "loss: 3.732437  [12010/50000]\n",
      "loss: 3.674976  [13010/50000]\n",
      "loss: 3.668092  [14010/50000]\n",
      "loss: 3.668759  [15010/50000]\n",
      "loss: 3.657315  [16010/50000]\n",
      "loss: 3.656393  [17010/50000]\n",
      "loss: 3.664646  [18010/50000]\n",
      "loss: 3.690334  [19010/50000]\n",
      "loss: 3.667397  [20010/50000]\n",
      "loss: 3.750928  [21010/50000]\n",
      "loss: 3.673315  [22010/50000]\n",
      "loss: 3.659425  [23010/50000]\n",
      "loss: 3.669098  [24010/50000]\n",
      "loss: 3.674229  [25010/50000]\n",
      "loss: 3.664933  [26010/50000]\n",
      "loss: 3.652683  [27010/50000]\n",
      "loss: 3.687538  [28010/50000]\n",
      "loss: 3.665392  [29010/50000]\n",
      "loss: 3.665379  [30010/50000]\n",
      "loss: 3.768805  [31010/50000]\n",
      "loss: 3.655409  [32010/50000]\n",
      "loss: 3.670342  [33010/50000]\n",
      "loss: 3.666448  [34010/50000]\n",
      "loss: 3.685662  [35010/50000]\n",
      "loss: 3.671270  [36010/50000]\n",
      "loss: 3.675058  [37010/50000]\n",
      "loss: 3.664699  [38010/50000]\n",
      "loss: 3.772516  [39010/50000]\n",
      "loss: 3.647089  [40010/50000]\n",
      "loss: 3.774582  [41010/50000]\n",
      "loss: 3.664943  [42010/50000]\n",
      "loss: 3.667998  [43010/50000]\n",
      "loss: 3.663805  [44010/50000]\n",
      "loss: 3.660954  [45010/50000]\n",
      "loss: 3.667988  [46010/50000]\n",
      "loss: 3.661732  [47010/50000]\n",
      "loss: 3.683966  [48010/50000]\n",
      "loss: 3.667553  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 3.988352 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 3.668335  [   10/50000]\n",
      "loss: 3.663723  [ 1010/50000]\n",
      "loss: 3.671677  [ 2010/50000]\n",
      "loss: 3.744209  [ 3010/50000]\n",
      "loss: 3.659489  [ 4010/50000]\n",
      "loss: 3.662990  [ 5010/50000]\n",
      "loss: 3.670913  [ 6010/50000]\n",
      "loss: 3.679230  [ 7010/50000]\n",
      "loss: 3.664066  [ 8010/50000]\n",
      "loss: 3.665222  [ 9010/50000]\n",
      "loss: 3.812878  [10010/50000]\n",
      "loss: 3.660344  [11010/50000]\n",
      "loss: 3.780674  [12010/50000]\n",
      "loss: 3.651655  [13010/50000]\n",
      "loss: 3.661409  [14010/50000]\n",
      "loss: 3.669284  [15010/50000]\n",
      "loss: 3.663245  [16010/50000]\n",
      "loss: 3.669458  [17010/50000]\n",
      "loss: 3.704280  [18010/50000]\n",
      "loss: 3.669738  [19010/50000]\n",
      "loss: 3.664220  [20010/50000]\n",
      "loss: 3.654927  [21010/50000]\n",
      "loss: 3.664300  [22010/50000]\n",
      "loss: 3.756351  [23010/50000]\n",
      "loss: 3.670928  [24010/50000]\n",
      "loss: 3.674471  [25010/50000]\n",
      "loss: 3.665193  [26010/50000]\n",
      "loss: 3.653206  [27010/50000]\n",
      "loss: 3.669955  [28010/50000]\n",
      "loss: 3.657954  [29010/50000]\n",
      "loss: 3.659878  [30010/50000]\n",
      "loss: 3.667796  [31010/50000]\n",
      "loss: 3.752992  [32010/50000]\n",
      "loss: 3.654697  [33010/50000]\n",
      "loss: 3.766563  [34010/50000]\n",
      "loss: 3.751726  [35010/50000]\n",
      "loss: 3.664457  [36010/50000]\n",
      "loss: 3.662651  [37010/50000]\n",
      "loss: 3.654528  [38010/50000]\n",
      "loss: 3.656301  [39010/50000]\n",
      "loss: 3.660182  [40010/50000]\n",
      "loss: 3.684005  [41010/50000]\n",
      "loss: 3.673090  [42010/50000]\n",
      "loss: 3.656286  [43010/50000]\n",
      "loss: 3.698846  [44010/50000]\n",
      "loss: 3.763480  [45010/50000]\n",
      "loss: 3.685828  [46010/50000]\n",
      "loss: 3.664334  [47010/50000]\n",
      "loss: 3.656056  [48010/50000]\n",
      "loss: 3.673584  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 3.990705 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 3.742309  [   10/50000]\n",
      "loss: 3.654041  [ 1010/50000]\n",
      "loss: 3.799217  [ 2010/50000]\n",
      "loss: 3.665993  [ 3010/50000]\n",
      "loss: 3.666232  [ 4010/50000]\n",
      "loss: 3.671781  [ 5010/50000]\n",
      "loss: 3.667108  [ 6010/50000]\n",
      "loss: 3.667004  [ 7010/50000]\n",
      "loss: 3.741061  [ 8010/50000]\n",
      "loss: 3.850494  [ 9010/50000]\n",
      "loss: 3.764093  [10010/50000]\n",
      "loss: 3.669486  [11010/50000]\n",
      "loss: 3.661361  [12010/50000]\n",
      "loss: 3.655141  [13010/50000]\n",
      "loss: 3.672380  [14010/50000]\n",
      "loss: 3.723592  [15010/50000]\n",
      "loss: 3.681963  [16010/50000]\n",
      "loss: 3.668500  [17010/50000]\n",
      "loss: 3.664471  [18010/50000]\n",
      "loss: 3.666316  [19010/50000]\n",
      "loss: 3.712419  [20010/50000]\n",
      "loss: 3.660814  [21010/50000]\n",
      "loss: 3.650687  [22010/50000]\n",
      "loss: 3.712968  [23010/50000]\n",
      "loss: 3.657067  [24010/50000]\n",
      "loss: 3.661060  [25010/50000]\n",
      "loss: 3.656902  [26010/50000]\n",
      "loss: 3.663252  [27010/50000]\n",
      "loss: 3.658448  [28010/50000]\n",
      "loss: 3.658433  [29010/50000]\n",
      "loss: 3.656953  [30010/50000]\n",
      "loss: 3.722185  [31010/50000]\n",
      "loss: 3.699633  [32010/50000]\n",
      "loss: 3.657027  [33010/50000]\n",
      "loss: 3.667859  [34010/50000]\n",
      "loss: 3.659234  [35010/50000]\n",
      "loss: 3.658041  [36010/50000]\n",
      "loss: 3.741477  [37010/50000]\n",
      "loss: 3.659880  [38010/50000]\n",
      "loss: 3.695382  [39010/50000]\n",
      "loss: 3.669282  [40010/50000]\n",
      "loss: 3.657773  [41010/50000]\n",
      "loss: 3.681803  [42010/50000]\n",
      "loss: 3.769222  [43010/50000]\n",
      "loss: 3.757854  [44010/50000]\n",
      "loss: 3.661451  [45010/50000]\n",
      "loss: 3.737998  [46010/50000]\n",
      "loss: 3.661778  [47010/50000]\n",
      "loss: 3.664014  [48010/50000]\n",
      "loss: 3.678554  [49010/50000]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 3.996574 \n",
      "\n",
      "Done!\n",
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(datagen, model, loss_fn, optimizer)\n",
    "    test(datatestgen, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af02ffc",
   "metadata": {
    "papermill": {
     "duration": 0.499438,
     "end_time": "2024-07-20T22:56:35.570912",
     "exception": false,
     "start_time": "2024-07-20T22:56:35.071474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29801.119091,
   "end_time": "2024-07-20T22:56:37.573617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-20T14:39:56.454526",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
